{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "boston = load_boston()\n",
    "boston.keys()\n",
    "\n",
    "data = DataFrame(boston['data'])\n",
    "labels = DataFrame(boston['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2    3      4      5     6     7    8      9     10  \\\n",
      "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.09  1.0  296.0  15.3   \n",
      "\n",
      "      11    12  \n",
      "0  396.9  4.98  \n",
      "[-0.41526932 -0.48772236 -0.59338101 -0.27259857 -0.74026221  0.19427445\n",
      "  0.36716642  0.55715988 -0.8678825  -0.98732948 -0.30309415  0.44105193\n",
      " -0.49243937]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler().fit(data)\n",
    "dataS = scaler.transform(data)\n",
    "print(data.head(1))\n",
    "print(dataS[1,:])\n",
    "dataS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add bias \n",
    "dataB = np.hstack(( np.ones((dataS.shape[0], 1)), dataS))\n",
    "dataB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init vars for ease of use later on\n",
    "rows, cols = dataB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one:  Create the TF CG\n",
    "\n",
    "# Place holders for the X and Y data, to be fed into the CG at run time\n",
    "x = tf.placeholder(tf.float32, [None, cols], name = 'x')\n",
    "y = tf.placeholder(tf.float32, [None, 1], name = 'y')\n",
    "\n",
    "# Create a TF variable we can store values in for the weights, and init with ones\n",
    "w = tf.Variable( tf.ones([rows, 1], name = 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
