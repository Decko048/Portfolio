{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#IMDB-Movie-Review-Sentiment-Classification\" data-toc-modified-id=\"IMDB-Movie-Review-Sentiment-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IMDB Movie Review Sentiment Classification</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Process\" data-toc-modified-id=\"Process-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Process</a></span></li><li><span><a href=\"#Configure-notebook,-import-libraries,-and-import-dataset\" data-toc-modified-id=\"Configure-notebook,-import-libraries,-and-import-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configure notebook, import libraries, and import dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Define-global-variables\" data-toc-modified-id=\"Define-global-variables-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Define global variables</a></span></li><li><span><a href=\"#Import-labeled-data\" data-toc-modified-id=\"Import-labeled-data-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Import labeled data</a></span></li></ul></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#Examine-the-data\" data-toc-modified-id=\"Examine-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Examine the data</a></span></li><li><span><a href=\"#Cleaning-and-preprocessing\" data-toc-modified-id=\"Cleaning-and-preprocessing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cleaning and preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-training-data\" data-toc-modified-id=\"Load-training-data-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Load training data</a></span></li><li><span><a href=\"#Write-helper-functions\" data-toc-modified-id=\"Write-helper-functions-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Write helper functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-cleaner\" data-toc-modified-id=\"Sentence-cleaner-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Sentence cleaner</a></span></li></ul></li><li><span><a href=\"#Create-list-of-Doc2Vec-TaggedDocument-objects\" data-toc-modified-id=\"Create-list-of-Doc2Vec-TaggedDocument-objects-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Create list of Doc2Vec TaggedDocument objects</a></span></li></ul></li><li><span><a href=\"#Train-Doc2Vec-model\" data-toc-modified-id=\"Train-Doc2Vec-model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Train Doc2Vec model</a></span></li><li><span><a href=\"#Classification-model-training-and-evaluation\" data-toc-modified-id=\"Classification-model-training-and-evaluation-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Classification model training and evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kaggle-model\" data-toc-modified-id=\"Kaggle-model-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Kaggle model</a></span></li><li><span><a href=\"#Standard-write-up-models\" data-toc-modified-id=\"Standard-write-up-models-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Standard write-up models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-model-comments\" data-toc-modified-id=\"Standard-model-comments-9.2.1\"><span class=\"toc-item-num\">9.2.1&nbsp;&nbsp;</span>Standard model comments</a></span></li></ul></li></ul></li><li><span><a href=\"#Tuning-Doc3Vec\" data-toc-modified-id=\"Tuning-Doc3Vec-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Tuning Doc3Vec</a></span></li><li><span><a href=\"#Combining-Doc2Vec-models\" data-toc-modified-id=\"Combining-Doc2Vec-models-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Combining Doc2Vec models</a></span></li><li><span><a href=\"#Increased-vocabulary-and-combined-Doc2Vec-models\" data-toc-modified-id=\"Increased-vocabulary-and-combined-Doc2Vec-models-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Increased vocabulary and combined Doc2Vec models</a></span></li><li><span><a href=\"#Manual-training-of-combined-Doc2Vec-model-with-increased-vocab-and-diminishing-alpha\" data-toc-modified-id=\"Manual-training-of-combined-Doc2Vec-model-with-increased-vocab-and-diminishing-alpha-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Manual training of combined Doc2Vec model with increased vocab and diminishing alpha</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Movie Review Sentiment Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 30%; height: 30%;\" src=\"images/imdb.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The overall goal of this set of write-ups is to explore a number of machine learning algorithms utilizing natural language processing (NLP) to classify sentiment IMDB movie reviews.\n",
    "\n",
    "The specific goals of this write-up include:\n",
    "1. Create a set of word embeddings from the IMDb movie review text utilizing [Word2vec](https://en.wikipedia.org/wiki/Word2vec)\n",
    "2. Cluster the embeddings utilizing a K-nearest neighbors algorithm into a set of centroids\n",
    "2. Run the models from the [last write-up](./Model-06.ipynb) against the centroid feature set\n",
    "3. Determine if the centroid feature set improves our ability to correctly classify movie review sentiment\n",
    "\n",
    "References:\n",
    "* This series of write-ups is inspired by the Kaggle [\n",
    "Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial) competition.\n",
    "* [Gensim Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "* [smart_open](https://pypi.org/project/smart_open/)\n",
    "\n",
    "Dataset source:  [IMDB Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure notebook, import libraries, and import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T15:16:22.416553Z",
     "start_time": "2018-10-16T15:16:22.413553Z"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:21.685850Z",
     "start_time": "2018-11-06T23:44:21.122850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import smart_open\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# http://www.nltk.org/index.html\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Creating function implementing punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Only need this the first time...\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# https://pypi.org/project/gensim/\n",
    "# pip install gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:22.150850Z",
     "start_time": "2018-11-06T23:44:21.687850Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert(gensim.models.doc2vec.FAST_VERSION > -1, \"Going to be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:22.641850Z",
     "start_time": "2018-11-06T23:44:22.151850Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Opens a GUI that allows us to download the NLTK data\n",
    "# nltk.download()\n",
    "\n",
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:23.530850Z",
     "start_time": "2018-11-06T23:44:22.642850Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:24.028850Z",
     "start_time": "2018-11-06T23:44:23.531850Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModels(xTrain, yTrain, modelsToRun = ['LR', 'LDA', 'SVM']):\n",
    "    # Init vars\n",
    "    folds = 10\n",
    "    seed = 10\n",
    "    models = []\n",
    "    results = {}\n",
    "\n",
    "    # Use accuracy since this is a classification\n",
    "    score = 'accuracy'\n",
    "    \n",
    "    # Instantiate model objects\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC()))\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    _df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "    # Run the models\n",
    "    for modelName, model in models:\n",
    "        if (modelName in modelsToRun) or (modelsToRun == 'all'):\n",
    "            print(\"Training\", modelName, \"....\")\n",
    "            # Implement K-fold cross validation where K = 10\n",
    "            kFold = KFold(n_splits = folds, random_state = seed)\n",
    "            results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "            _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "    # Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "    return(results, _df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:00:41.938974Z",
     "start_time": "2018-11-07T00:00:41.475982Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeWhisker(results):\n",
    "    figure = plt.figure(figsize = (8,6))\n",
    "    figure.suptitle(\"Model Results\")\n",
    "    axis = figure.add_subplot(111)\n",
    "    plt.boxplot(results.values())\n",
    "    axis.set_xticklabels(results.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Examine-the-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Previous process justification and methodology also previously covered [here](./Model-06.ipynb#Cleaning-and-preprocessing).)\n",
    "\n",
    "First, read in the labeled training data (which we've done before) as well as the unlabeled training data (which is new to this write-up).  The more data we can feed to Word2Vec the better, and this will help the algorithm associate related words more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:29.104850Z",
     "start_time": "2018-11-06T23:44:28.209850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in the labeled data\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')\n",
    "df = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "\n",
    "# Pull in the unlabeled data since it can also be utilized by Word2Vec\n",
    "# unlabeledTrainData = os.path.join(dataPath, 'unlabeledTrainData.tsv')\n",
    "# dfUn = pd.read_csv(unlabeledTrainData, sep = '\\t', header = 0, quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:29.550850Z",
     "start_time": "2018-11-06T23:44:29.105850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape : (25000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print('df.shape :', df.shape)\n",
    "#print('dfUn.shape :', dfUn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write helper functions\n",
    "\n",
    "Word2Vec expects single sentences as inputs, and each sentence formated as a list of words (i.e. a list of lists).  Let's write two functions to achieve this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence cleaner\n",
    "\n",
    "Take a given sentence and process/clean it (i.e. remove HTML and other cruft, lower case the text, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:30.012850Z",
     "start_time": "2018-11-06T23:44:29.552850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update stop word helper function to output a list of words\n",
    "\n",
    "# Clean IMDB review text\n",
    "def cleanReview(review, removeStopWords = False):\n",
    "    # Convert the stop words to a set\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Remove HTML\n",
    "    clean = BeautifulSoup(review)\n",
    "    \n",
    "    # Remove non-alpha chars\n",
    "    clean = re.sub(\"[^a-zA-Z]\", ' ', clean.get_text())\n",
    "    \n",
    "    # Convert to lower case and \"tokenize\"\n",
    "    clean = clean.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    if removeStopWords:\n",
    "        clean = [x for x in clean if not x in stopWords]\n",
    "    \n",
    "    # Return results\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick examination of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:32.741850Z",
     "start_time": "2018-11-06T23:44:32.275850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looking',\n",
       " 'for',\n",
       " 'quo',\n",
       " 'vadis',\n",
       " 'at',\n",
       " 'my',\n",
       " 'local',\n",
       " 'video',\n",
       " 'store',\n",
       " 'i',\n",
       " 'found',\n",
       " 'this']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine\n",
    "cleanReview(df.iloc[25,2])[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:44:33.219850Z",
     "start_time": "2018-11-06T23:44:32.743850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine\n",
    "#cleanReview(dfUn.iloc[0,1])[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of Doc2Vec TaggedDocument objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:45:17.473820Z",
     "start_time": "2018-11-06T23:44:33.220850Z"
    }
   },
   "outputs": [],
   "source": [
    "taggedDocs = []\n",
    "\n",
    "for i, s in enumerate(df.iloc[:,2]):\n",
    "    clean = cleanReview(s)\n",
    "    taggedDocs.append(TaggedDocument(clean, [i]))\n",
    "    #if (i > 20):\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:45:17.969820Z",
     "start_time": "2018-11-06T23:45:17.474820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taggedDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:45:18.473820Z",
     "start_time": "2018-11-06T23:45:17.971820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:45:18,455 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel = Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:45:21.274820Z",
     "start_time": "2018-11-06T23:45:18.475820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:45:18,986 : INFO : collecting all words and their counts\n",
      "2018-11-06 16:45:18,987 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 16:45:19,425 : INFO : PROGRESS: at example #10000, processed 2385574 words (5457085/s), 51527 word types, 10000 tags\n",
      "2018-11-06 16:45:19,899 : INFO : PROGRESS: at example #20000, processed 4747503 words (4990659/s), 67813 word types, 20000 tags\n",
      "2018-11-06 16:45:20,139 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-06 16:45:20,140 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 16:45:20,237 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-06 16:45:20,239 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-06 16:45:20,374 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-06 16:45:20,376 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-06 16:45:20,377 : INFO : downsampling leaves estimated 4416048 word corpus (74.9% of prior 5892845)\n",
      "2018-11-06 16:45:20,530 : INFO : estimated required memory for 46350 words and 50 dimensions: 46715000 bytes\n",
      "2018-11-06 16:45:20,531 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel.build_vocab(taggedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:48:30.195802Z",
     "start_time": "2018-11-06T23:45:21.275820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:45:21,740 : INFO : training model with 3 workers on 46350 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-06 16:45:22,750 : INFO : EPOCH 1 - PROGRESS: at 20.86% examples, 938389 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:23,753 : INFO : EPOCH 1 - PROGRESS: at 41.17% examples, 918002 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:24,763 : INFO : EPOCH 1 - PROGRESS: at 62.62% examples, 928145 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:25,771 : INFO : EPOCH 1 - PROGRESS: at 81.88% examples, 906147 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:26,604 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:26,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:26,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:26,616 : INFO : EPOCH - 1 : training on 5920713 raw words (4441554 effective words) took 4.9s, 911851 effective words/s\n",
      "2018-11-06 16:45:27,631 : INFO : EPOCH 2 - PROGRESS: at 21.18% examples, 950902 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:28,633 : INFO : EPOCH 2 - PROGRESS: at 43.12% examples, 961257 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:29,635 : INFO : EPOCH 2 - PROGRESS: at 65.40% examples, 969184 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:30,640 : INFO : EPOCH 2 - PROGRESS: at 86.43% examples, 959701 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:31,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:31,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:31,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:31,215 : INFO : EPOCH - 2 : training on 5920713 raw words (4440157 effective words) took 4.6s, 967225 effective words/s\n",
      "2018-11-06 16:45:32,234 : INFO : EPOCH 3 - PROGRESS: at 21.95% examples, 980759 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:33,234 : INFO : EPOCH 3 - PROGRESS: at 44.51% examples, 988237 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:34,239 : INFO : EPOCH 3 - PROGRESS: at 67.01% examples, 991143 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:35,241 : INFO : EPOCH 3 - PROGRESS: at 86.71% examples, 962426 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:35,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:35,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:35,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:35,842 : INFO : EPOCH - 3 : training on 5920713 raw words (4441388 effective words) took 4.6s, 960958 effective words/s\n",
      "2018-11-06 16:45:36,859 : INFO : EPOCH 4 - PROGRESS: at 20.07% examples, 895573 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:37,860 : INFO : EPOCH 4 - PROGRESS: at 42.62% examples, 949125 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:38,862 : INFO : EPOCH 4 - PROGRESS: at 65.07% examples, 963368 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:39,873 : INFO : EPOCH 4 - PROGRESS: at 87.01% examples, 965158 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:40,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:40,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:40,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:40,429 : INFO : EPOCH - 4 : training on 5920713 raw words (4442029 effective words) took 4.6s, 969464 effective words/s\n",
      "2018-11-06 16:45:41,437 : INFO : EPOCH 5 - PROGRESS: at 22.17% examples, 999303 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:42,445 : INFO : EPOCH 5 - PROGRESS: at 44.51% examples, 989598 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:43,449 : INFO : EPOCH 5 - PROGRESS: at 66.02% examples, 977806 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:44,449 : INFO : EPOCH 5 - PROGRESS: at 88.18% examples, 980224 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:44,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:44,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:44,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:44,963 : INFO : EPOCH - 5 : training on 5920713 raw words (4441449 effective words) took 4.5s, 980592 effective words/s\n",
      "2018-11-06 16:45:45,975 : INFO : EPOCH 6 - PROGRESS: at 20.69% examples, 929004 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:46,992 : INFO : EPOCH 6 - PROGRESS: at 43.12% examples, 954679 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:47,995 : INFO : EPOCH 6 - PROGRESS: at 65.40% examples, 964497 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:48,997 : INFO : EPOCH 6 - PROGRESS: at 87.67% examples, 971628 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:49,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:49,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:49,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:49,529 : INFO : EPOCH - 6 : training on 5920713 raw words (4441235 effective words) took 4.6s, 973770 effective words/s\n",
      "2018-11-06 16:45:50,538 : INFO : EPOCH 7 - PROGRESS: at 22.33% examples, 1004778 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:51,539 : INFO : EPOCH 7 - PROGRESS: at 44.16% examples, 985421 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:52,540 : INFO : EPOCH 7 - PROGRESS: at 66.02% examples, 980778 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:45:53,544 : INFO : EPOCH 7 - PROGRESS: at 88.01% examples, 979791 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:54,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:54,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:54,060 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:54,061 : INFO : EPOCH - 7 : training on 5920713 raw words (4441279 effective words) took 4.5s, 980979 effective words/s\n",
      "2018-11-06 16:45:55,069 : INFO : EPOCH 8 - PROGRESS: at 21.80% examples, 984300 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:56,077 : INFO : EPOCH 8 - PROGRESS: at 43.75% examples, 975187 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:57,079 : INFO : EPOCH 8 - PROGRESS: at 65.69% examples, 973485 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:58,080 : INFO : EPOCH 8 - PROGRESS: at 87.85% examples, 976816 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:45:58,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:45:58,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:45:58,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:45:58,628 : INFO : EPOCH - 8 : training on 5920713 raw words (4441763 effective words) took 4.6s, 973570 effective words/s\n",
      "2018-11-06 16:45:59,642 : INFO : EPOCH 9 - PROGRESS: at 23.02% examples, 1029434 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:00,643 : INFO : EPOCH 9 - PROGRESS: at 45.49% examples, 1012186 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:01,645 : INFO : EPOCH 9 - PROGRESS: at 66.18% examples, 981082 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:02,658 : INFO : EPOCH 9 - PROGRESS: at 89.13% examples, 987015 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:03,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:03,166 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:03,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:03,175 : INFO : EPOCH - 9 : training on 5920713 raw words (4441299 effective words) took 4.5s, 977959 effective words/s\n",
      "2018-11-06 16:46:04,190 : INFO : EPOCH 10 - PROGRESS: at 22.90% examples, 1022725 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:05,201 : INFO : EPOCH 10 - PROGRESS: at 43.75% examples, 971010 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:06,201 : INFO : EPOCH 10 - PROGRESS: at 66.02% examples, 976215 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:46:07,204 : INFO : EPOCH 10 - PROGRESS: at 88.96% examples, 985573 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:07,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:07,716 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:07,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:07,722 : INFO : EPOCH - 10 : training on 5920713 raw words (4439432 effective words) took 4.5s, 977876 effective words/s\n",
      "2018-11-06 16:46:08,737 : INFO : EPOCH 11 - PROGRESS: at 21.51% examples, 962562 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:09,761 : INFO : EPOCH 11 - PROGRESS: at 41.48% examples, 913179 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:10,769 : INFO : EPOCH 11 - PROGRESS: at 55.39% examples, 815769 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:11,801 : INFO : EPOCH 11 - PROGRESS: at 65.23% examples, 714163 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:12,802 : INFO : EPOCH 11 - PROGRESS: at 77.98% examples, 685136 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:13,816 : INFO : EPOCH 11 - PROGRESS: at 98.47% examples, 718667 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:13,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:13,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:13,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:13,883 : INFO : EPOCH - 11 : training on 5920713 raw words (4440054 effective words) took 6.2s, 721214 effective words/s\n",
      "2018-11-06 16:46:14,896 : INFO : EPOCH 12 - PROGRESS: at 20.21% examples, 906787 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:15,899 : INFO : EPOCH 12 - PROGRESS: at 41.64% examples, 928098 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:16,901 : INFO : EPOCH 12 - PROGRESS: at 62.32% examples, 924789 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:17,920 : INFO : EPOCH 12 - PROGRESS: at 83.00% examples, 917821 words/s, in_qsize 3, out_qsize 2\n",
      "2018-11-06 16:46:18,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:18,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:18,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:18,849 : INFO : EPOCH - 12 : training on 5920713 raw words (4440454 effective words) took 5.0s, 895186 effective words/s\n",
      "2018-11-06 16:46:19,857 : INFO : EPOCH 13 - PROGRESS: at 20.86% examples, 939938 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:20,873 : INFO : EPOCH 13 - PROGRESS: at 40.70% examples, 901471 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:21,873 : INFO : EPOCH 13 - PROGRESS: at 61.60% examples, 912689 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:22,892 : INFO : EPOCH 13 - PROGRESS: at 83.16% examples, 918072 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:23,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:23,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:23,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:23,616 : INFO : EPOCH - 13 : training on 5920713 raw words (4441870 effective words) took 4.8s, 932644 effective words/s\n",
      "2018-11-06 16:46:24,623 : INFO : EPOCH 14 - PROGRESS: at 20.69% examples, 933666 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:25,626 : INFO : EPOCH 14 - PROGRESS: at 41.48% examples, 926439 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:26,635 : INFO : EPOCH 14 - PROGRESS: at 62.98% examples, 933874 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:27,639 : INFO : EPOCH 14 - PROGRESS: at 84.12% examples, 933437 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:28,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:28,333 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:28,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:28,337 : INFO : EPOCH - 14 : training on 5920713 raw words (4440129 effective words) took 4.7s, 941602 effective words/s\n",
      "2018-11-06 16:46:29,349 : INFO : EPOCH 15 - PROGRESS: at 21.51% examples, 964792 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:30,354 : INFO : EPOCH 15 - PROGRESS: at 43.94% examples, 978260 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:31,370 : INFO : EPOCH 15 - PROGRESS: at 66.48% examples, 980512 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:32,377 : INFO : EPOCH 15 - PROGRESS: at 88.55% examples, 978759 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:32,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:32,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:32,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:32,876 : INFO : EPOCH - 15 : training on 5920713 raw words (4440950 effective words) took 4.5s, 979153 effective words/s\n",
      "2018-11-06 16:46:33,882 : INFO : EPOCH 16 - PROGRESS: at 17.60% examples, 795457 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:34,882 : INFO : EPOCH 16 - PROGRESS: at 40.53% examples, 906170 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:35,884 : INFO : EPOCH 16 - PROGRESS: at 62.47% examples, 929968 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:36,884 : INFO : EPOCH 16 - PROGRESS: at 85.29% examples, 950022 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:37,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:37,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:37,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:37,556 : INFO : EPOCH - 16 : training on 5920713 raw words (4441229 effective words) took 4.7s, 949833 effective words/s\n",
      "2018-11-06 16:46:38,564 : INFO : EPOCH 17 - PROGRESS: at 22.54% examples, 1013478 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:39,571 : INFO : EPOCH 17 - PROGRESS: at 45.49% examples, 1012729 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:40,572 : INFO : EPOCH 17 - PROGRESS: at 67.01% examples, 994102 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:41,582 : INFO : EPOCH 17 - PROGRESS: at 89.68% examples, 993919 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:42,033 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:42,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:42,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:42,038 : INFO : EPOCH - 17 : training on 5920713 raw words (4443110 effective words) took 4.5s, 992440 effective words/s\n",
      "2018-11-06 16:46:43,042 : INFO : EPOCH 18 - PROGRESS: at 22.54% examples, 1016110 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:44,043 : INFO : EPOCH 18 - PROGRESS: at 44.88% examples, 1002371 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:45,056 : INFO : EPOCH 18 - PROGRESS: at 67.50% examples, 1000423 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:46,061 : INFO : EPOCH 18 - PROGRESS: at 90.02% examples, 997915 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:46,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:46,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:46,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:46,518 : INFO : EPOCH - 18 : training on 5920713 raw words (4442560 effective words) took 4.5s, 992431 effective words/s\n",
      "2018-11-06 16:46:47,522 : INFO : EPOCH 19 - PROGRESS: at 22.90% examples, 1031484 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:48,524 : INFO : EPOCH 19 - PROGRESS: at 44.49% examples, 994413 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:49,530 : INFO : EPOCH 19 - PROGRESS: at 66.64% examples, 989931 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:50,537 : INFO : EPOCH 19 - PROGRESS: at 89.47% examples, 993239 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:50,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:46:50,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:50,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:50,995 : INFO : EPOCH - 19 : training on 5920713 raw words (4441143 effective words) took 4.5s, 992836 effective words/s\n",
      "2018-11-06 16:46:52,014 : INFO : EPOCH 20 - PROGRESS: at 22.54% examples, 1003268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:53,018 : INFO : EPOCH 20 - PROGRESS: at 44.32% examples, 983242 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:54,023 : INFO : EPOCH 20 - PROGRESS: at 67.33% examples, 995010 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:55,031 : INFO : EPOCH 20 - PROGRESS: at 90.16% examples, 996532 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:55,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:55,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:46:55,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:46:55,479 : INFO : EPOCH - 20 : training on 5920713 raw words (4440948 effective words) took 4.5s, 991746 effective words/s\n",
      "2018-11-06 16:46:56,491 : INFO : EPOCH 21 - PROGRESS: at 21.80% examples, 981611 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:57,497 : INFO : EPOCH 21 - PROGRESS: at 44.10% examples, 982613 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:46:58,499 : INFO : EPOCH 21 - PROGRESS: at 66.66% examples, 988371 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:59,504 : INFO : EPOCH 21 - PROGRESS: at 88.55% examples, 983317 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:46:59,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:46:59,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:00,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:00,004 : INFO : EPOCH - 21 : training on 5920713 raw words (4441395 effective words) took 4.5s, 983107 effective words/s\n",
      "2018-11-06 16:47:01,007 : INFO : EPOCH 22 - PROGRESS: at 21.34% examples, 964773 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:02,013 : INFO : EPOCH 22 - PROGRESS: at 43.44% examples, 970426 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:03,023 : INFO : EPOCH 22 - PROGRESS: at 66.02% examples, 977763 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:04,028 : INFO : EPOCH 22 - PROGRESS: at 88.01% examples, 976997 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:04,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:04,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:04,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:04,530 : INFO : EPOCH - 22 : training on 5920713 raw words (4440818 effective words) took 4.5s, 981822 effective words/s\n",
      "2018-11-06 16:47:05,541 : INFO : EPOCH 23 - PROGRESS: at 21.80% examples, 981322 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:06,547 : INFO : EPOCH 23 - PROGRESS: at 44.32% examples, 985509 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:07,548 : INFO : EPOCH 23 - PROGRESS: at 57.57% examples, 855800 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:08,552 : INFO : EPOCH 23 - PROGRESS: at 72.63% examples, 806958 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:09,553 : INFO : EPOCH 23 - PROGRESS: at 83.31% examples, 740205 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:10,566 : INFO : EPOCH 23 - PROGRESS: at 93.50% examples, 689245 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:11,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:11,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:11,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:11,085 : INFO : EPOCH - 23 : training on 5920713 raw words (4440227 effective words) took 6.5s, 677992 effective words/s\n",
      "2018-11-06 16:47:12,137 : INFO : EPOCH 24 - PROGRESS: at 14.87% examples, 669913 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:13,155 : INFO : EPOCH 24 - PROGRESS: at 27.43% examples, 609936 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:14,163 : INFO : EPOCH 24 - PROGRESS: at 38.42% examples, 569605 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:15,165 : INFO : EPOCH 24 - PROGRESS: at 52.35% examples, 581844 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:16,170 : INFO : EPOCH 24 - PROGRESS: at 72.79% examples, 645468 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:17,175 : INFO : EPOCH 24 - PROGRESS: at 94.97% examples, 699461 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:17,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:17,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:17,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:17,399 : INFO : EPOCH - 24 : training on 5920713 raw words (4440709 effective words) took 6.3s, 709049 effective words/s\n",
      "2018-11-06 16:47:18,406 : INFO : EPOCH 25 - PROGRESS: at 21.34% examples, 963406 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:19,408 : INFO : EPOCH 25 - PROGRESS: at 42.30% examples, 945789 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-06 16:47:20,410 : INFO : EPOCH 25 - PROGRESS: at 64.74% examples, 961491 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:21,412 : INFO : EPOCH 25 - PROGRESS: at 87.01% examples, 969478 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:21,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:21,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:21,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:21,950 : INFO : EPOCH - 25 : training on 5920713 raw words (4441494 effective words) took 4.5s, 977125 effective words/s\n",
      "2018-11-06 16:47:22,958 : INFO : EPOCH 26 - PROGRESS: at 22.33% examples, 1005774 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:23,960 : INFO : EPOCH 26 - PROGRESS: at 44.32% examples, 988525 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:24,963 : INFO : EPOCH 26 - PROGRESS: at 66.82% examples, 991877 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:25,966 : INFO : EPOCH 26 - PROGRESS: at 88.18% examples, 980950 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:26,457 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:26,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:26,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:26,462 : INFO : EPOCH - 26 : training on 5920713 raw words (4440624 effective words) took 4.5s, 985111 effective words/s\n",
      "2018-11-06 16:47:27,475 : INFO : EPOCH 27 - PROGRESS: at 21.18% examples, 950197 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:28,483 : INFO : EPOCH 27 - PROGRESS: at 44.49% examples, 987520 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:29,486 : INFO : EPOCH 27 - PROGRESS: at 67.01% examples, 990946 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-06 16:47:30,500 : INFO : EPOCH 27 - PROGRESS: at 88.36% examples, 977612 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:30,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:30,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:30,992 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:30,993 : INFO : EPOCH - 27 : training on 5920713 raw words (4440628 effective words) took 4.5s, 981276 effective words/s\n",
      "2018-11-06 16:47:31,999 : INFO : EPOCH 28 - PROGRESS: at 22.50% examples, 1016245 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:33,004 : INFO : EPOCH 28 - PROGRESS: at 45.66% examples, 1018868 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:34,004 : INFO : EPOCH 28 - PROGRESS: at 68.17% examples, 1012818 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:35,018 : INFO : EPOCH 28 - PROGRESS: at 89.68% examples, 993995 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:35,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:47:35,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:35,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:35,510 : INFO : EPOCH - 28 : training on 5920713 raw words (4442440 effective words) took 4.5s, 984641 effective words/s\n",
      "2018-11-06 16:47:36,516 : INFO : EPOCH 29 - PROGRESS: at 21.80% examples, 986392 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:37,521 : INFO : EPOCH 29 - PROGRESS: at 43.94% examples, 981481 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:38,529 : INFO : EPOCH 29 - PROGRESS: at 66.02% examples, 977885 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:39,533 : INFO : EPOCH 29 - PROGRESS: at 88.96% examples, 986445 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:40,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:40,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:40,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:40,029 : INFO : EPOCH - 29 : training on 5920713 raw words (4439646 effective words) took 4.5s, 983446 effective words/s\n",
      "2018-11-06 16:47:41,042 : INFO : EPOCH 30 - PROGRESS: at 22.33% examples, 1000285 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:42,045 : INFO : EPOCH 30 - PROGRESS: at 44.49% examples, 989642 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:43,055 : INFO : EPOCH 30 - PROGRESS: at 66.02% examples, 975784 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:44,056 : INFO : EPOCH 30 - PROGRESS: at 89.13% examples, 987813 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:44,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:44,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:44,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:44,530 : INFO : EPOCH - 30 : training on 5920713 raw words (4441835 effective words) took 4.5s, 987744 effective words/s\n",
      "2018-11-06 16:47:45,536 : INFO : EPOCH 31 - PROGRESS: at 22.50% examples, 1015563 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:46,543 : INFO : EPOCH 31 - PROGRESS: at 45.18% examples, 1005924 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:47,544 : INFO : EPOCH 31 - PROGRESS: at 67.68% examples, 1004191 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:48,552 : INFO : EPOCH 31 - PROGRESS: at 90.32% examples, 1001953 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:48,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:48,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:48,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:48,958 : INFO : EPOCH - 31 : training on 5920713 raw words (4440979 effective words) took 4.4s, 1004157 effective words/s\n",
      "2018-11-06 16:47:49,972 : INFO : EPOCH 32 - PROGRESS: at 21.18% examples, 949911 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:50,982 : INFO : EPOCH 32 - PROGRESS: at 43.94% examples, 975459 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:51,994 : INFO : EPOCH 32 - PROGRESS: at 67.01% examples, 987510 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:52,995 : INFO : EPOCH 32 - PROGRESS: at 89.13% examples, 985576 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:53,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:53,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:53,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:53,459 : INFO : EPOCH - 32 : training on 5920713 raw words (4440697 effective words) took 4.5s, 987962 effective words/s\n",
      "2018-11-06 16:47:54,474 : INFO : EPOCH 33 - PROGRESS: at 22.50% examples, 1006319 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:55,476 : INFO : EPOCH 33 - PROGRESS: at 44.32% examples, 985455 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:56,477 : INFO : EPOCH 33 - PROGRESS: at 65.23% examples, 966353 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:47:57,479 : INFO : EPOCH 33 - PROGRESS: at 86.56% examples, 961896 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:47:58,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:47:58,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:47:58,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:47:58,077 : INFO : EPOCH - 33 : training on 5920713 raw words (4441819 effective words) took 4.6s, 962699 effective words/s\n",
      "2018-11-06 16:47:59,091 : INFO : EPOCH 34 - PROGRESS: at 22.54% examples, 1007571 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:00,099 : INFO : EPOCH 34 - PROGRESS: at 45.97% examples, 1019094 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:01,109 : INFO : EPOCH 34 - PROGRESS: at 68.47% examples, 1009993 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:02,114 : INFO : EPOCH 34 - PROGRESS: at 89.84% examples, 992247 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:02,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:02,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:02,546 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:02,547 : INFO : EPOCH - 34 : training on 5920713 raw words (4440305 effective words) took 4.5s, 994502 effective words/s\n",
      "2018-11-06 16:48:03,557 : INFO : EPOCH 35 - PROGRESS: at 22.71% examples, 1018523 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:04,568 : INFO : EPOCH 35 - PROGRESS: at 45.66% examples, 1012754 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:05,569 : INFO : EPOCH 35 - PROGRESS: at 66.18% examples, 979521 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:06,574 : INFO : EPOCH 35 - PROGRESS: at 88.91% examples, 985820 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:07,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:07,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:07,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:07,073 : INFO : EPOCH - 35 : training on 5920713 raw words (4441302 effective words) took 4.5s, 982198 effective words/s\n",
      "2018-11-06 16:48:08,080 : INFO : EPOCH 36 - PROGRESS: at 21.66% examples, 976443 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:09,080 : INFO : EPOCH 36 - PROGRESS: at 44.49% examples, 993664 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:10,095 : INFO : EPOCH 36 - PROGRESS: at 65.84% examples, 974380 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:11,096 : INFO : EPOCH 36 - PROGRESS: at 87.85% examples, 975466 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:11,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:11,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:11,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:11,717 : INFO : EPOCH - 36 : training on 5920713 raw words (4441061 effective words) took 4.6s, 956975 effective words/s\n",
      "2018-11-06 16:48:12,725 : INFO : EPOCH 37 - PROGRESS: at 22.54% examples, 1013827 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:13,727 : INFO : EPOCH 37 - PROGRESS: at 43.26% examples, 966913 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:14,731 : INFO : EPOCH 37 - PROGRESS: at 63.47% examples, 943063 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:15,749 : INFO : EPOCH 37 - PROGRESS: at 86.09% examples, 953496 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-06 16:48:16,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:16,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:16,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:16,393 : INFO : EPOCH - 37 : training on 5920713 raw words (4440509 effective words) took 4.7s, 950548 effective words/s\n",
      "2018-11-06 16:48:17,403 : INFO : EPOCH 38 - PROGRESS: at 22.71% examples, 1018597 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:48:18,411 : INFO : EPOCH 38 - PROGRESS: at 44.49% examples, 988711 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:19,414 : INFO : EPOCH 38 - PROGRESS: at 63.99% examples, 948012 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:20,417 : INFO : EPOCH 38 - PROGRESS: at 85.93% examples, 953594 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:21,095 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:21,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:21,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:21,109 : INFO : EPOCH - 38 : training on 5920713 raw words (4441823 effective words) took 4.7s, 942786 effective words/s\n",
      "2018-11-06 16:48:22,114 : INFO : EPOCH 39 - PROGRESS: at 22.03% examples, 994059 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:23,128 : INFO : EPOCH 39 - PROGRESS: at 43.94% examples, 977275 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:24,128 : INFO : EPOCH 39 - PROGRESS: at 66.66% examples, 987607 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:25,140 : INFO : EPOCH 39 - PROGRESS: at 89.30% examples, 988449 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:25,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:25,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:25,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:25,642 : INFO : EPOCH - 39 : training on 5920713 raw words (4441203 effective words) took 4.5s, 980621 effective words/s\n",
      "2018-11-06 16:48:26,648 : INFO : EPOCH 40 - PROGRESS: at 21.95% examples, 993740 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 16:48:27,656 : INFO : EPOCH 40 - PROGRESS: at 42.80% examples, 953963 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:28,663 : INFO : EPOCH 40 - PROGRESS: at 65.54% examples, 970466 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:29,668 : INFO : EPOCH 40 - PROGRESS: at 87.85% examples, 975097 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 16:48:30,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:48:30,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:48:30,189 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:48:30,190 : INFO : EPOCH - 40 : training on 5920713 raw words (4441756 effective words) took 4.5s, 977777 effective words/s\n",
      "2018-11-06 16:48:30,191 : INFO : training on a 236828520 raw words (177645302 effective words) took 188.4s, 942680 effective words/s\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:48:30.682802Z",
     "start_time": "2018-11-06T23:48:30.197802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6505469e-01,  7.4312961e-01, -2.9754534e-01,  6.5974897e-01,\n",
       "       -1.3289150e+00, -2.4452431e-02,  6.7683077e-01,  1.5952986e+00,\n",
       "       -1.1640645e+00,  5.0207961e-01,  1.2432387e+00,  2.8135589e-01,\n",
       "        2.1586819e+00,  1.2339395e+00,  1.8095058e-01,  3.0222520e-01,\n",
       "        8.5317671e-02,  3.7294289e-01, -1.5953681e+00, -2.1257722e-03,\n",
       "       -7.2604078e-01,  1.8573532e-01, -2.2056878e+00,  2.7045938e-01,\n",
       "        3.6956193e+00, -6.3102871e-02, -8.3222842e-01, -1.4880967e+00,\n",
       "       -1.3236006e+00, -6.3074905e-01,  1.8948115e+00, -8.4367520e-01,\n",
       "       -1.3538743e+00,  1.4831817e+00,  9.4101602e-01,  2.8586612e+00,\n",
       "        8.4283400e-01, -8.7171745e-01, -2.7161121e+00, -1.8785887e+00,\n",
       "       -2.2841017e+00,  6.5578687e-01, -2.2028844e+00,  7.1371353e-01,\n",
       "       -3.2800531e-01, -2.0589201e+00,  1.1632628e+00,  2.0860660e+00,\n",
       "        6.1708719e-01,  4.9301285e-01], dtype=float32)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vecModel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:48:31.133802Z",
     "start_time": "2018-11-06T23:48:30.684802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vecModel.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:48:31.590802Z",
     "start_time": "2018-11-06T23:48:31.134802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6505469e-01,  7.4312961e-01, -2.9754534e-01,  6.5974897e-01,\n",
       "       -1.3289150e+00, -2.4452431e-02,  6.7683077e-01,  1.5952986e+00,\n",
       "       -1.1640645e+00,  5.0207961e-01,  1.2432387e+00,  2.8135589e-01,\n",
       "        2.1586819e+00,  1.2339395e+00,  1.8095058e-01,  3.0222520e-01,\n",
       "        8.5317671e-02,  3.7294289e-01, -1.5953681e+00, -2.1257722e-03,\n",
       "       -7.2604078e-01,  1.8573532e-01, -2.2056878e+00,  2.7045938e-01,\n",
       "        3.6956193e+00, -6.3102871e-02, -8.3222842e-01, -1.4880967e+00,\n",
       "       -1.3236006e+00, -6.3074905e-01,  1.8948115e+00, -8.4367520e-01,\n",
       "       -1.3538743e+00,  1.4831817e+00,  9.4101602e-01,  2.8586612e+00,\n",
       "        8.4283400e-01, -8.7171745e-01, -2.7161121e+00, -1.8785887e+00,\n",
       "       -2.2841017e+00,  6.5578687e-01, -2.2028844e+00,  7.1371353e-01,\n",
       "       -3.2800531e-01, -2.0589201e+00,  1.1632628e+00,  2.0860660e+00,\n",
       "        6.1708719e-01,  4.9301285e-01], dtype=float32)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vecModel.docvecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle model\n",
    "\n",
    "First we'll evalute the Kaggle model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:50:51.992802Z",
     "start_time": "2018-11-06T23:48:31.591802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.81956</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  StdDev\n",
       "0  RandomForestClassifier   0.81956  0.0086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init vars and params\n",
    "eFolds = 10\n",
    "eSeed = 10\n",
    "\n",
    "# Use accuracy since this is a classification problem\n",
    "eScore = 'accuracy'\n",
    "\n",
    "modelName = 'RandomForestClassifier'\n",
    "RandomForestClassifier(n_estimators = 100)\n",
    "xTrain = doc2vecModel.docvecs\n",
    "yTrain = df.iloc[:, 1]\n",
    "\n",
    "_DF = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "_Results = {}\n",
    "_model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "kFold = KFold(n_splits = eFolds, random_state = eSeed)\n",
    "_Results[modelName] = cross_val_score(_model, xTrain, yTrain, cv = kFold, scoring = eScore)\n",
    "\n",
    "_DF.loc[len(_DF)] = list(['RandomForestClassifier', _Results[modelName].mean(), _Results[modelName].std()])\n",
    "display(_DF.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard write-up models\n",
    "\n",
    "Next we'll train the standard set of models (LR, LDA, etc.) we use in the majority of our write-ups for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:00:41.474982Z",
     "start_time": "2018-11-06T23:51:19.312802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training KNN ....\n",
      "Training CART ....\n",
      "Training NB ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "5   SVM   0.84856  0.007906\n",
      "1   LDA   0.84464  0.008518\n",
      "0    LR   0.84448  0.008363\n",
      "4    NB   0.80132  0.009583\n",
      "2   KNN   0.78440  0.010916\n",
      "3  CART   0.69164  0.008531\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, _df = trainModels(doc2vecModel.docvecs, df.iloc[:, 1], modelsToRun = 'all')\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard model comments\n",
    "\n",
    "The first thing I noticed right away is how much faster training the set of models was.  Training wrapped up in about 9 mins compared to the sometimes hours required in previous write-ups.  Accuracy was also high being only two percentage points less then the baseline model:\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|-------------------|--------|-----------------------------------|\n",
    "|LR (baseline)      |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid       |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec        |84.48%  |Scikit-learn defaults              |\n",
    "\n",
    "\n",
    "Clearly for very large data sets the small drop in accuracy might be more than offset by the greatly reduced training time required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T20:45:14.229341Z",
     "start_time": "2018-11-06T20:44:06.438590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 13:44:06,922 : INFO : collecting all words and their counts\n",
      "2018-11-06 13:44:06,922 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 13:44:07,306 : INFO : PROGRESS: at example #10000, processed 2385574 words (6121096/s), 51527 word types, 10000 tags\n",
      "2018-11-06 13:44:07,705 : INFO : PROGRESS: at example #20000, processed 4747503 words (6001379/s), 67813 word types, 20000 tags\n",
      "2018-11-06 13:44:07,893 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-06 13:44:07,893 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 13:44:07,973 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-06 13:44:07,973 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-06 13:44:08,083 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-06 13:44:08,093 : INFO : sample=0 downsamples 0 most-common words\n",
      "2018-11-06 13:44:08,093 : INFO : downsampling leaves estimated 5892845 word corpus (100.0% of prior 5892845)\n",
      "2018-11-06 13:44:08,234 : INFO : estimated required memory for 46350 words and 100 dimensions: 70255000 bytes\n",
      "2018-11-06 13:44:08,234 : INFO : resetting layer weights\n",
      "2018-11-06 13:44:08,970 : INFO : training model with 4 workers on 46350 vocabulary and 100 features, using sg=1 hs=0 sample=0 negative=5 window=5\n",
      "2018-11-06 13:44:09,985 : INFO : EPOCH 1 - PROGRESS: at 31.55% examples, 1879560 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:10,990 : INFO : EPOCH 1 - PROGRESS: at 63.64% examples, 1879690 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:11,998 : INFO : EPOCH 1 - PROGRESS: at 90.16% examples, 1770868 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 13:44:12,389 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:12,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:12,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:12,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:12,419 : INFO : EPOCH - 1 : training on 5920713 raw words (5917845 effective words) took 3.4s, 1721456 effective words/s\n",
      "2018-11-06 13:44:13,427 : INFO : EPOCH 2 - PROGRESS: at 30.20% examples, 1801019 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:14,426 : INFO : EPOCH 2 - PROGRESS: at 59.41% examples, 1767377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:15,440 : INFO : EPOCH 2 - PROGRESS: at 89.51% examples, 1763323 words/s, in_qsize 7, out_qsize 2\n",
      "2018-11-06 13:44:15,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:15,752 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:15,752 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:15,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:15,752 : INFO : EPOCH - 2 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1778720 effective words/s\n",
      "2018-11-06 13:44:16,767 : INFO : EPOCH 3 - PROGRESS: at 28.88% examples, 1717272 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:17,762 : INFO : EPOCH 3 - PROGRESS: at 61.79% examples, 1833264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:18,768 : INFO : EPOCH 3 - PROGRESS: at 92.24% examples, 1813340 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:18,978 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:18,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:18,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:18,998 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:18,998 : INFO : EPOCH - 3 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1828115 effective words/s\n",
      "2018-11-06 13:44:20,002 : INFO : EPOCH 4 - PROGRESS: at 30.37% examples, 1813499 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:21,008 : INFO : EPOCH 4 - PROGRESS: at 61.28% examples, 1822917 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:22,005 : INFO : EPOCH 4 - PROGRESS: at 91.01% examples, 1798378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:22,265 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:22,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:22,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:22,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:22,266 : INFO : EPOCH - 4 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1806702 effective words/s\n",
      "2018-11-06 13:44:23,286 : INFO : EPOCH 5 - PROGRESS: at 29.37% examples, 1743820 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-06 13:44:24,283 : INFO : EPOCH 5 - PROGRESS: at 63.16% examples, 1864365 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:25,300 : INFO : EPOCH 5 - PROGRESS: at 93.50% examples, 1832102 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:25,472 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:25,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:25,479 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:25,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:25,481 : INFO : EPOCH - 5 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1840615 effective words/s\n",
      "2018-11-06 13:44:26,489 : INFO : EPOCH 6 - PROGRESS: at 31.00% examples, 1852803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:27,493 : INFO : EPOCH 6 - PROGRESS: at 62.32% examples, 1850161 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:28,495 : INFO : EPOCH 6 - PROGRESS: at 92.41% examples, 1822373 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:28,713 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:28,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:28,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:28,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:28,724 : INFO : EPOCH - 6 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1832158 effective words/s\n",
      "2018-11-06 13:44:29,729 : INFO : EPOCH 7 - PROGRESS: at 31.74% examples, 1891036 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:30,745 : INFO : EPOCH 7 - PROGRESS: at 63.99% examples, 1896287 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:31,750 : INFO : EPOCH 7 - PROGRESS: at 93.14% examples, 1832002 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:31,950 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:31,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:31,950 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:31,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:31,960 : INFO : EPOCH - 7 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1834971 effective words/s\n",
      "2018-11-06 13:44:32,975 : INFO : EPOCH 8 - PROGRESS: at 31.00% examples, 1846888 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:33,978 : INFO : EPOCH 8 - PROGRESS: at 60.05% examples, 1781638 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:34,982 : INFO : EPOCH 8 - PROGRESS: at 90.34% examples, 1779974 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:35,252 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:35,252 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:35,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:35,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:35,262 : INFO : EPOCH - 8 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1794825 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 13:44:36,269 : INFO : EPOCH 9 - PROGRESS: at 29.41% examples, 1751189 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 13:44:37,262 : INFO : EPOCH 9 - PROGRESS: at 60.95% examples, 1812582 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 13:44:38,264 : INFO : EPOCH 9 - PROGRESS: at 91.00% examples, 1795138 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:38,526 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:38,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:38,536 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:38,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:38,536 : INFO : EPOCH - 9 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1807650 effective words/s\n",
      "2018-11-06 13:44:39,549 : INFO : EPOCH 10 - PROGRESS: at 31.74% examples, 1891650 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:40,551 : INFO : EPOCH 10 - PROGRESS: at 62.47% examples, 1859097 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:41,550 : INFO : EPOCH 10 - PROGRESS: at 92.06% examples, 1819126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:41,772 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:41,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:41,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:41,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:41,782 : INFO : EPOCH - 10 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1828147 effective words/s\n",
      "2018-11-06 13:44:42,790 : INFO : EPOCH 11 - PROGRESS: at 30.19% examples, 1798871 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:43,797 : INFO : EPOCH 11 - PROGRESS: at 59.57% examples, 1769236 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:44,787 : INFO : EPOCH 11 - PROGRESS: at 88.01% examples, 1736503 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:45,137 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:45,147 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:45,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:45,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:45,147 : INFO : EPOCH - 11 : training on 5920713 raw words (5917845 effective words) took 3.4s, 1759218 effective words/s\n",
      "2018-11-06 13:44:46,159 : INFO : EPOCH 12 - PROGRESS: at 30.67% examples, 1823381 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 13:44:47,165 : INFO : EPOCH 12 - PROGRESS: at 61.45% examples, 1822594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:48,175 : INFO : EPOCH 12 - PROGRESS: at 91.71% examples, 1802951 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:48,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:48,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:48,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:48,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:48,406 : INFO : EPOCH - 12 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1818156 effective words/s\n",
      "2018-11-06 13:44:49,423 : INFO : EPOCH 13 - PROGRESS: at 30.52% examples, 1819919 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:50,427 : INFO : EPOCH 13 - PROGRESS: at 63.99% examples, 1896435 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:51,431 : INFO : EPOCH 13 - PROGRESS: at 94.47% examples, 1858834 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:51,576 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:51,576 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:51,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:51,586 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:51,586 : INFO : EPOCH - 13 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1865592 effective words/s\n",
      "2018-11-06 13:44:52,591 : INFO : EPOCH 14 - PROGRESS: at 31.40% examples, 1866345 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:53,596 : INFO : EPOCH 14 - PROGRESS: at 62.62% examples, 1858474 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:44:54,604 : INFO : EPOCH 14 - PROGRESS: at 93.14% examples, 1830355 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:54,786 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:54,796 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:54,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:54,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:54,796 : INFO : EPOCH - 14 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1844912 effective words/s\n",
      "2018-11-06 13:44:55,808 : INFO : EPOCH 15 - PROGRESS: at 31.38% examples, 1864138 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 13:44:56,816 : INFO : EPOCH 15 - PROGRESS: at 64.36% examples, 1901890 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:57,827 : INFO : EPOCH 15 - PROGRESS: at 95.13% examples, 1864653 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:57,947 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:44:57,957 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:44:57,967 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:44:57,967 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:44:57,967 : INFO : EPOCH - 15 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1870568 effective words/s\n",
      "2018-11-06 13:44:58,989 : INFO : EPOCH 16 - PROGRESS: at 32.34% examples, 1912204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:44:59,992 : INFO : EPOCH 16 - PROGRESS: at 62.62% examples, 1852118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:00,990 : INFO : EPOCH 16 - PROGRESS: at 92.58% examples, 1820736 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:45:01,190 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:45:01,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:45:01,200 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:45:01,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:45:01,200 : INFO : EPOCH - 16 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1835567 effective words/s\n",
      "2018-11-06 13:45:02,215 : INFO : EPOCH 17 - PROGRESS: at 32.36% examples, 1903480 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:03,223 : INFO : EPOCH 17 - PROGRESS: at 64.74% examples, 1907116 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:04,218 : INFO : EPOCH 17 - PROGRESS: at 94.82% examples, 1860554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:04,370 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:45:04,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:45:04,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:45:04,380 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:45:04,380 : INFO : EPOCH - 17 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1863470 effective words/s\n",
      "2018-11-06 13:45:05,390 : INFO : EPOCH 18 - PROGRESS: at 33.50% examples, 1992092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:06,392 : INFO : EPOCH 18 - PROGRESS: at 63.16% examples, 1871745 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:45:07,397 : INFO : EPOCH 18 - PROGRESS: at 94.47% examples, 1854735 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:45:07,571 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:45:07,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:45:07,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 13:45:07,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:45:07,581 : INFO : EPOCH - 18 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1849947 effective words/s\n",
      "2018-11-06 13:45:08,602 : INFO : EPOCH 19 - PROGRESS: at 33.86% examples, 1987592 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:09,612 : INFO : EPOCH 19 - PROGRESS: at 64.90% examples, 1906330 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:45:10,615 : INFO : EPOCH 19 - PROGRESS: at 96.44% examples, 1884295 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:10,726 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:45:10,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:45:10,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:45:10,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:45:10,732 : INFO : EPOCH - 19 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1872695 effective words/s\n",
      "2018-11-06 13:45:11,763 : INFO : EPOCH 20 - PROGRESS: at 34.51% examples, 2032376 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 13:45:12,759 : INFO : EPOCH 20 - PROGRESS: at 59.24% examples, 1748932 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 13:45:13,779 : INFO : EPOCH 20 - PROGRESS: at 87.67% examples, 1725397 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 13:45:14,199 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 13:45:14,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 13:45:14,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 13:45:14,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 13:45:14,209 : INFO : EPOCH - 20 : training on 5920713 raw words (5917845 effective words) took 3.5s, 1709856 effective words/s\n",
      "2018-11-06 13:45:14,209 : INFO : training on a 118414260 raw words (118356900 effective words) took 65.2s, 1814161 effective words/s\n"
     ]
    }
   ],
   "source": [
    "#doc2vecModel = Doc2Vec(vector_size = 100, min_count = 5, epochs = 60)\n",
    "doc2vecModel = Doc2Vec(dm = 0, vector_size = 100, negative = 5, hs = 0, min_count = 2, sample = 0, epochs = 20, workers = cores)\n",
    "doc2vecModel.build_vocab(taggedDocs)\n",
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T20:55:43.272410Z",
     "start_time": "2018-11-06T20:46:07.272331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training KNN ....\n",
      "Training CART ....\n",
      "Training NB ....\n",
      "Training SVM ....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.88664</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.88428</td>\n",
       "      <td>0.007810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.88384</td>\n",
       "      <td>0.007757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.85288</td>\n",
       "      <td>0.006137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.81456</td>\n",
       "      <td>0.008471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.68624</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy    StdDev\n",
       "5   SVM   0.88664  0.007875\n",
       "0    LR   0.88428  0.007810\n",
       "1   LDA   0.88384  0.007757\n",
       "4    NB   0.85288  0.006137\n",
       "2   KNN   0.81456  0.008471\n",
       "3  CART   0.68624  0.004013"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init vars\n",
    "folds = 10\n",
    "seed = 10\n",
    "models = []\n",
    "results = {}\n",
    "\n",
    "# Use accuracy since this is a classification\n",
    "score = 'accuracy'\n",
    "\n",
    "# Assign training features and labels\n",
    "xTrain = doc2vecModel.docvecs\n",
    "yTrain = df.iloc[:, 1]\n",
    "\n",
    "# Instantiate model objects\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "# Run the models\n",
    "for modelName, model in models:\n",
    "    print(\"Training\", modelName, \"....\")\n",
    "    # Implement K-fold cross validation where K = 10\n",
    "    kFold = KFold(n_splits = folds, random_state = seed)\n",
    "    results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "    _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "# Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:00:50.914583Z",
     "start_time": "2018-11-06T21:00:50.322594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = (8,6))\n",
    "figure.suptitle(\"Model Results\")\n",
    "axis = figure.add_subplot(111)\n",
    "plt.boxplot(results.values())\n",
    "axis.set_xticklabels(results.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Doc2Vec models\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/doc2vec-IMDB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:01:29.068861Z",
     "start_time": "2018-11-06T21:01:24.386950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:01:24,850 : INFO : collecting all words and their counts\n",
      "2018-11-06 14:01:24,850 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 14:01:25,220 : INFO : PROGRESS: at example #10000, processed 2385574 words (6585509/s), 51527 word types, 10000 tags\n",
      "2018-11-06 14:01:25,623 : INFO : PROGRESS: at example #20000, processed 4747503 words (5787172/s), 67813 word types, 20000 tags\n",
      "2018-11-06 14:01:25,821 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-06 14:01:25,821 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 14:01:26,041 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-06 14:01:26,041 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-06 14:01:26,161 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-06 14:01:26,171 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-06 14:01:26,171 : INFO : downsampling leaves estimated 4416048 word corpus (74.9% of prior 5892845)\n",
      "2018-11-06 14:01:26,304 : INFO : estimated required memory for 46350 words and 100 dimensions: 70255000 bytes\n",
      "2018-11-06 14:01:26,304 : INFO : resetting layer weights\n",
      "2018-11-06 14:01:27,044 : INFO : collecting all words and their counts\n",
      "2018-11-06 14:01:27,044 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 14:01:27,435 : INFO : PROGRESS: at example #10000, processed 2385574 words (6139536/s), 51527 word types, 10000 tags\n",
      "2018-11-06 14:01:27,788 : INFO : PROGRESS: at example #20000, processed 4747503 words (6615294/s), 67813 word types, 20000 tags\n",
      "2018-11-06 14:01:27,967 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-06 14:01:27,967 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 14:01:28,047 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-06 14:01:28,057 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-06 14:01:28,168 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-06 14:01:28,168 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-06 14:01:28,168 : INFO : downsampling leaves estimated 4416048 word corpus (74.9% of prior 5892845)\n",
      "2018-11-06 14:01:28,312 : INFO : estimated required memory for 46350 words and 100 dimensions: 70255000 bytes\n",
      "2018-11-06 14:01:28,312 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "m1 = Doc2Vec(dm = 0, size = 100, negative = 5, hs = 0, min_count = 2, workers = cores)\n",
    "m2 = Doc2Vec(dm = 1, dm_mean = 1, size = 100, window = 10, negative = 5, hs = 0, min_count = 2, workers = cores)\n",
    "\n",
    "m1.build_vocab(taggedDocs)\n",
    "m2.build_vocab(taggedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:04:33.204359Z",
     "start_time": "2018-11-06T21:01:41.180631Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:01:41,613 : INFO : training model with 4 workers on 46350 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-06 14:01:42,614 : INFO : EPOCH 1 - PROGRESS: at 29.54% examples, 1323352 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:43,631 : INFO : EPOCH 1 - PROGRESS: at 60.24% examples, 1340001 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:44,630 : INFO : EPOCH 1 - PROGRESS: at 90.32% examples, 1335165 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 14:01:44,903 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:01:44,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:01:44,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:01:44,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:01:44,923 : INFO : EPOCH - 1 : training on 5920713 raw words (4440794 effective words) took 3.3s, 1343096 effective words/s\n",
      "2018-11-06 14:01:45,931 : INFO : EPOCH 2 - PROGRESS: at 28.72% examples, 1278746 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:01:46,939 : INFO : EPOCH 2 - PROGRESS: at 60.95% examples, 1354270 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:47,939 : INFO : EPOCH 2 - PROGRESS: at 90.83% examples, 1340851 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:48,199 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:01:48,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:01:48,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:01:48,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:01:48,209 : INFO : EPOCH - 2 : training on 5920713 raw words (4441777 effective words) took 3.3s, 1351844 effective words/s\n",
      "2018-11-06 14:01:49,214 : INFO : EPOCH 3 - PROGRESS: at 28.22% examples, 1267627 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:01:50,220 : INFO : EPOCH 3 - PROGRESS: at 60.95% examples, 1358638 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:01:51,218 : INFO : EPOCH 3 - PROGRESS: at 91.01% examples, 1348092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:51,478 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:01:51,479 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:01:51,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:01:51,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:01:51,487 : INFO : EPOCH - 3 : training on 5920713 raw words (4441484 effective words) took 3.3s, 1352208 effective words/s\n",
      "2018-11-06 14:01:52,495 : INFO : EPOCH 4 - PROGRESS: at 28.72% examples, 1284884 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:53,496 : INFO : EPOCH 4 - PROGRESS: at 60.92% examples, 1359808 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:01:54,505 : INFO : EPOCH 4 - PROGRESS: at 91.53% examples, 1352622 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:54,758 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:01:54,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:01:54,768 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:01:54,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:01:54,768 : INFO : EPOCH - 4 : training on 5920713 raw words (4441114 effective words) took 3.3s, 1359683 effective words/s\n",
      "2018-11-06 14:01:55,778 : INFO : EPOCH 5 - PROGRESS: at 28.22% examples, 1267579 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:56,790 : INFO : EPOCH 5 - PROGRESS: at 59.89% examples, 1334681 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-06 14:01:57,798 : INFO : EPOCH 5 - PROGRESS: at 90.16% examples, 1329885 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:01:58,068 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:01:58,078 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:01:58,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:01:58,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:01:58,088 : INFO : EPOCH - 5 : training on 5920713 raw words (4440899 effective words) took 3.3s, 1342086 effective words/s\n",
      "2018-11-06 14:01:59,090 : INFO : EPOCH 6 - PROGRESS: at 28.72% examples, 1286907 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 14:02:00,090 : INFO : EPOCH 6 - PROGRESS: at 60.24% examples, 1346619 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:01,095 : INFO : EPOCH 6 - PROGRESS: at 91.53% examples, 1355997 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:01,345 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:01,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:01,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:01,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:01,346 : INFO : EPOCH - 6 : training on 5920713 raw words (4441008 effective words) took 3.3s, 1359189 effective words/s\n",
      "2018-11-06 14:02:02,372 : INFO : EPOCH 7 - PROGRESS: at 28.22% examples, 1257998 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:03,374 : INFO : EPOCH 7 - PROGRESS: at 59.40% examples, 1325037 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:04,374 : INFO : EPOCH 7 - PROGRESS: at 91.01% examples, 1345886 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:04,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:04,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:04,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:04,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:04,639 : INFO : EPOCH - 7 : training on 5920713 raw words (4441905 effective words) took 3.3s, 1353910 effective words/s\n",
      "2018-11-06 14:02:05,650 : INFO : EPOCH 8 - PROGRESS: at 29.86% examples, 1334884 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:06,668 : INFO : EPOCH 8 - PROGRESS: at 60.92% examples, 1349444 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 14:02:07,667 : INFO : EPOCH 8 - PROGRESS: at 93.33% examples, 1372687 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:07,869 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:07,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:07,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:07,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:07,879 : INFO : EPOCH - 8 : training on 5920713 raw words (4441367 effective words) took 3.2s, 1376237 effective words/s\n",
      "2018-11-06 14:02:08,882 : INFO : EPOCH 9 - PROGRESS: at 27.72% examples, 1244444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:09,888 : INFO : EPOCH 9 - PROGRESS: at 58.67% examples, 1308876 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:10,888 : INFO : EPOCH 9 - PROGRESS: at 89.13% examples, 1318535 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:11,237 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:11,247 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:11,247 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:11,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:11,247 : INFO : EPOCH - 9 : training on 5920713 raw words (4440355 effective words) took 3.4s, 1317496 effective words/s\n",
      "2018-11-06 14:02:12,262 : INFO : EPOCH 10 - PROGRESS: at 30.67% examples, 1363629 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:13,271 : INFO : EPOCH 10 - PROGRESS: at 60.62% examples, 1348697 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 14:02:14,269 : INFO : EPOCH 10 - PROGRESS: at 91.71% examples, 1352471 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 14:02:14,541 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:14,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:02:14,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:14,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:14,561 : INFO : EPOCH - 10 : training on 5920713 raw words (4441128 effective words) took 3.3s, 1342528 effective words/s\n",
      "2018-11-06 14:02:15,575 : INFO : EPOCH 11 - PROGRESS: at 29.68% examples, 1333362 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:16,581 : INFO : EPOCH 11 - PROGRESS: at 59.24% examples, 1322759 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:17,591 : INFO : EPOCH 11 - PROGRESS: at 91.53% examples, 1350661 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:17,888 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:17,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:17,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:17,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:17,898 : INFO : EPOCH - 11 : training on 5920713 raw words (4441969 effective words) took 3.3s, 1335522 effective words/s\n",
      "2018-11-06 14:02:18,910 : INFO : EPOCH 12 - PROGRESS: at 28.91% examples, 1292585 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:19,918 : INFO : EPOCH 12 - PROGRESS: at 57.24% examples, 1277188 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:20,919 : INFO : EPOCH 12 - PROGRESS: at 89.68% examples, 1325443 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 14:02:21,317 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:21,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:21,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:21,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:21,347 : INFO : EPOCH - 12 : training on 5920713 raw words (4440888 effective words) took 3.4s, 1291976 effective words/s\n",
      "2018-11-06 14:02:22,355 : INFO : EPOCH 13 - PROGRESS: at 32.68% examples, 1457667 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:23,365 : INFO : EPOCH 13 - PROGRESS: at 62.62% examples, 1387356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:24,363 : INFO : EPOCH 13 - PROGRESS: at 91.53% examples, 1349910 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:24,636 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:24,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:24,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:24,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:24,646 : INFO : EPOCH - 13 : training on 5920713 raw words (4440750 effective words) took 3.3s, 1345850 effective words/s\n",
      "2018-11-06 14:02:25,657 : INFO : EPOCH 14 - PROGRESS: at 32.52% examples, 1451633 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 14:02:26,661 : INFO : EPOCH 14 - PROGRESS: at 63.16% examples, 1405547 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:27,676 : INFO : EPOCH 14 - PROGRESS: at 93.82% examples, 1381664 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:27,839 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:27,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:27,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:27,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:27,859 : INFO : EPOCH - 14 : training on 5920713 raw words (4441662 effective words) took 3.2s, 1385513 effective words/s\n",
      "2018-11-06 14:02:28,858 : INFO : EPOCH 15 - PROGRESS: at 31.00% examples, 1391895 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:29,864 : INFO : EPOCH 15 - PROGRESS: at 61.60% examples, 1376934 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:30,866 : INFO : EPOCH 15 - PROGRESS: at 91.53% examples, 1356645 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:31,106 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:31,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:31,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:31,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:31,116 : INFO : EPOCH - 15 : training on 5920713 raw words (4440551 effective words) took 3.3s, 1363887 effective words/s\n",
      "2018-11-06 14:02:32,134 : INFO : EPOCH 16 - PROGRESS: at 32.01% examples, 1426897 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:33,134 : INFO : EPOCH 16 - PROGRESS: at 62.78% examples, 1398754 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:34,130 : INFO : EPOCH 16 - PROGRESS: at 92.76% examples, 1372421 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:34,336 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:34,336 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:34,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:34,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:34,346 : INFO : EPOCH - 16 : training on 5920713 raw words (4442060 effective words) took 3.2s, 1377405 effective words/s\n",
      "2018-11-06 14:02:35,369 : INFO : EPOCH 17 - PROGRESS: at 30.37% examples, 1342040 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:36,378 : INFO : EPOCH 17 - PROGRESS: at 61.79% examples, 1367145 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:37,373 : INFO : EPOCH 17 - PROGRESS: at 91.53% examples, 1347904 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:37,613 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:37,623 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:37,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:37,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:37,633 : INFO : EPOCH - 17 : training on 5920713 raw words (4439959 effective words) took 3.3s, 1353927 effective words/s\n",
      "2018-11-06 14:02:38,635 : INFO : EPOCH 18 - PROGRESS: at 30.81% examples, 1380025 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:39,643 : INFO : EPOCH 18 - PROGRESS: at 62.47% examples, 1390228 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:40,651 : INFO : EPOCH 18 - PROGRESS: at 92.58% examples, 1367253 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:40,854 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:40,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:40,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:40,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:40,864 : INFO : EPOCH - 18 : training on 5920713 raw words (4439750 effective words) took 3.2s, 1374390 effective words/s\n",
      "2018-11-06 14:02:41,878 : INFO : EPOCH 19 - PROGRESS: at 29.41% examples, 1317523 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:42,875 : INFO : EPOCH 19 - PROGRESS: at 61.10% examples, 1362027 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:43,886 : INFO : EPOCH 19 - PROGRESS: at 90.83% examples, 1344329 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:44,136 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:44,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:44,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:44,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:44,156 : INFO : EPOCH - 19 : training on 5920713 raw words (4441579 effective words) took 3.3s, 1354269 effective words/s\n",
      "2018-11-06 14:02:45,160 : INFO : EPOCH 20 - PROGRESS: at 29.89% examples, 1334727 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-06 14:02:46,168 : INFO : EPOCH 20 - PROGRESS: at 60.78% examples, 1351737 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:47,171 : INFO : EPOCH 20 - PROGRESS: at 90.83% examples, 1343569 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:02:47,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:47,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:47,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:47,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:47,446 : INFO : EPOCH - 20 : training on 5920713 raw words (4441051 effective words) took 3.3s, 1350671 effective words/s\n",
      "2018-11-06 14:02:47,446 : INFO : training on a 118414260 raw words (88822050 effective words) took 65.8s, 1349152 effective words/s\n",
      "2018-11-06 14:02:47,446 : INFO : training model with 4 workers on 46350 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-06 14:02:48,450 : INFO : EPOCH 1 - PROGRESS: at 20.36% examples, 920226 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:49,452 : INFO : EPOCH 1 - PROGRESS: at 44.88% examples, 1001529 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:02:50,449 : INFO : EPOCH 1 - PROGRESS: at 66.18% examples, 984178 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:51,466 : INFO : EPOCH 1 - PROGRESS: at 88.18% examples, 981380 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:51,964 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:51,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:51,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:51,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:51,974 : INFO : EPOCH - 1 : training on 5920713 raw words (4440774 effective words) took 4.5s, 980951 effective words/s\n",
      "2018-11-06 14:02:52,985 : INFO : EPOCH 2 - PROGRESS: at 21.95% examples, 979270 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:53,985 : INFO : EPOCH 2 - PROGRESS: at 42.01% examples, 932153 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:54,985 : INFO : EPOCH 2 - PROGRESS: at 62.62% examples, 928400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:56,003 : INFO : EPOCH 2 - PROGRESS: at 85.29% examples, 946399 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:56,734 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:02:56,734 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:02:56,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:02:56,756 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:02:56,756 : INFO : EPOCH - 2 : training on 5920713 raw words (4440668 effective words) took 4.8s, 930860 effective words/s\n",
      "2018-11-06 14:02:57,745 : INFO : EPOCH 3 - PROGRESS: at 23.02% examples, 1037946 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:58,768 : INFO : EPOCH 3 - PROGRESS: at 44.88% examples, 998248 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:02:59,768 : INFO : EPOCH 3 - PROGRESS: at 67.34% examples, 998359 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:00,779 : INFO : EPOCH 3 - PROGRESS: at 89.84% examples, 995680 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:01,238 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:01,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:01,248 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:01,252 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:01,253 : INFO : EPOCH - 3 : training on 5920713 raw words (4440640 effective words) took 4.5s, 984785 effective words/s\n",
      "2018-11-06 14:03:02,272 : INFO : EPOCH 4 - PROGRESS: at 20.36% examples, 913015 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:03,285 : INFO : EPOCH 4 - PROGRESS: at 40.37% examples, 893807 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:04,289 : INFO : EPOCH 4 - PROGRESS: at 61.60% examples, 911369 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:05,303 : INFO : EPOCH 4 - PROGRESS: at 80.65% examples, 888504 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:06,184 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:06,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:06,200 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:06,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:06,204 : INFO : EPOCH - 4 : training on 5920713 raw words (4441097 effective words) took 4.9s, 899074 effective words/s\n",
      "2018-11-06 14:03:07,213 : INFO : EPOCH 5 - PROGRESS: at 20.21% examples, 911021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:08,214 : INFO : EPOCH 5 - PROGRESS: at 42.36% examples, 945492 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:09,214 : INFO : EPOCH 5 - PROGRESS: at 64.90% examples, 964266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:10,215 : INFO : EPOCH 5 - PROGRESS: at 86.11% examples, 958865 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:10,782 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:10,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:10,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:10,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:10,794 : INFO : EPOCH - 5 : training on 5920713 raw words (4441026 effective words) took 4.6s, 968926 effective words/s\n",
      "2018-11-06 14:03:11,815 : INFO : EPOCH 6 - PROGRESS: at 21.18% examples, 943115 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:12,817 : INFO : EPOCH 6 - PROGRESS: at 45.16% examples, 1001135 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:13,831 : INFO : EPOCH 6 - PROGRESS: at 64.74% examples, 952991 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:14,832 : INFO : EPOCH 6 - PROGRESS: at 85.62% examples, 947012 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:15,516 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:15,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:15,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:15,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:15,524 : INFO : EPOCH - 6 : training on 5920713 raw words (4442795 effective words) took 4.7s, 940254 effective words/s\n",
      "2018-11-06 14:03:16,547 : INFO : EPOCH 7 - PROGRESS: at 22.50% examples, 999083 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:17,549 : INFO : EPOCH 7 - PROGRESS: at 43.12% examples, 956481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:18,554 : INFO : EPOCH 7 - PROGRESS: at 63.16% examples, 932850 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:19,566 : INFO : EPOCH 7 - PROGRESS: at 82.19% examples, 907300 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:20,460 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:20,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:20,470 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:20,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:20,470 : INFO : EPOCH - 7 : training on 5920713 raw words (4441171 effective words) took 4.9s, 901692 effective words/s\n",
      "2018-11-06 14:03:21,465 : INFO : EPOCH 8 - PROGRESS: at 19.55% examples, 878199 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:22,467 : INFO : EPOCH 8 - PROGRESS: at 38.97% examples, 870242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:23,494 : INFO : EPOCH 8 - PROGRESS: at 57.04% examples, 842824 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 14:03:24,498 : INFO : EPOCH 8 - PROGRESS: at 71.56% examples, 791850 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:25,518 : INFO : EPOCH 8 - PROGRESS: at 84.26% examples, 743124 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 14:03:26,522 : INFO : EPOCH 8 - PROGRESS: at 93.68% examples, 687060 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:26,911 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:03:26,915 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:26,917 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:26,925 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:26,926 : INFO : EPOCH - 8 : training on 5920713 raw words (4442129 effective words) took 6.5s, 686836 effective words/s\n",
      "2018-11-06 14:03:28,015 : INFO : EPOCH 9 - PROGRESS: at 16.79% examples, 752422 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:29,049 : INFO : EPOCH 9 - PROGRESS: at 26.29% examples, 577492 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:30,054 : INFO : EPOCH 9 - PROGRESS: at 34.68% examples, 510265 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:31,071 : INFO : EPOCH 9 - PROGRESS: at 48.12% examples, 529483 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:32,079 : INFO : EPOCH 9 - PROGRESS: at 64.58% examples, 567882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:33,106 : INFO : EPOCH 9 - PROGRESS: at 79.21% examples, 580223 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:34,107 : INFO : EPOCH 9 - PROGRESS: at 88.60% examples, 556309 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:35,108 : INFO : EPOCH 9 - PROGRESS: at 98.28% examples, 539252 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 14:03:35,225 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:35,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:35,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:35,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:35,241 : INFO : EPOCH - 9 : training on 5920713 raw words (4440102 effective words) took 8.2s, 539187 effective words/s\n",
      "2018-11-06 14:03:36,278 : INFO : EPOCH 10 - PROGRESS: at 12.08% examples, 529290 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:37,296 : INFO : EPOCH 10 - PROGRESS: at 26.29% examples, 578730 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:38,325 : INFO : EPOCH 10 - PROGRESS: at 41.64% examples, 611133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:39,319 : INFO : EPOCH 10 - PROGRESS: at 55.38% examples, 611394 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:40,349 : INFO : EPOCH 10 - PROGRESS: at 69.44% examples, 611204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:41,372 : INFO : EPOCH 10 - PROGRESS: at 84.26% examples, 616314 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 14:03:42,373 : INFO : EPOCH 10 - PROGRESS: at 99.21% examples, 619400 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-06 14:03:42,386 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:42,409 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:42,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:42,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:42,419 : INFO : EPOCH - 10 : training on 5920713 raw words (4441355 effective words) took 7.2s, 620139 effective words/s\n",
      "2018-11-06 14:03:43,445 : INFO : EPOCH 11 - PROGRESS: at 14.23% examples, 629916 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:44,456 : INFO : EPOCH 11 - PROGRESS: at 29.06% examples, 645937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:45,459 : INFO : EPOCH 11 - PROGRESS: at 42.98% examples, 634296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:46,480 : INFO : EPOCH 11 - PROGRESS: at 56.85% examples, 630845 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:47,491 : INFO : EPOCH 11 - PROGRESS: at 72.41% examples, 640711 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:48,497 : INFO : EPOCH 11 - PROGRESS: at 86.71% examples, 638552 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:49,308 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:49,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:49,332 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:49,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:49,339 : INFO : EPOCH - 11 : training on 5920713 raw words (4441739 effective words) took 6.9s, 642561 effective words/s\n",
      "2018-11-06 14:03:50,365 : INFO : EPOCH 12 - PROGRESS: at 13.94% examples, 623963 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:51,372 : INFO : EPOCH 12 - PROGRESS: at 29.06% examples, 650860 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:52,357 : INFO : EPOCH 12 - PROGRESS: at 42.00% examples, 625092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:53,361 : INFO : EPOCH 12 - PROGRESS: at 55.38% examples, 618958 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:54,384 : INFO : EPOCH 12 - PROGRESS: at 69.14% examples, 614907 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:55,426 : INFO : EPOCH 12 - PROGRESS: at 85.45% examples, 627129 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:56,379 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:03:56,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:03:56,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:03:56,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:03:56,400 : INFO : EPOCH - 12 : training on 5920713 raw words (4441384 effective words) took 7.1s, 629909 effective words/s\n",
      "2018-11-06 14:03:57,412 : INFO : EPOCH 13 - PROGRESS: at 17.44% examples, 786189 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:03:58,424 : INFO : EPOCH 13 - PROGRESS: at 33.52% examples, 746070 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:03:59,424 : INFO : EPOCH 13 - PROGRESS: at 52.48% examples, 779807 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:00,451 : INFO : EPOCH 13 - PROGRESS: at 71.41% examples, 792587 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:04:01,452 : INFO : EPOCH 13 - PROGRESS: at 95.29% examples, 842258 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:01,670 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:01,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:01,680 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:01,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:01,680 : INFO : EPOCH - 13 : training on 5920713 raw words (4441798 effective words) took 5.3s, 844129 effective words/s\n",
      "2018-11-06 14:04:02,701 : INFO : EPOCH 14 - PROGRESS: at 23.82% examples, 1056448 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:03,699 : INFO : EPOCH 14 - PROGRESS: at 45.47% examples, 1009250 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:04,713 : INFO : EPOCH 14 - PROGRESS: at 68.01% examples, 1004600 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:04:05,719 : INFO : EPOCH 14 - PROGRESS: at 90.83% examples, 1003529 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:06,063 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:06,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:06,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:06,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:06,083 : INFO : EPOCH - 14 : training on 5920713 raw words (4441302 effective words) took 4.4s, 1010691 effective words/s\n",
      "2018-11-06 14:04:07,087 : INFO : EPOCH 15 - PROGRESS: at 21.34% examples, 961249 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:08,098 : INFO : EPOCH 15 - PROGRESS: at 44.10% examples, 980429 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:04:09,108 : INFO : EPOCH 15 - PROGRESS: at 67.85% examples, 1003342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:10,118 : INFO : EPOCH 15 - PROGRESS: at 89.68% examples, 989955 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:10,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:10,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:10,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 14:04:10,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:10,565 : INFO : EPOCH - 15 : training on 5920713 raw words (4440484 effective words) took 4.5s, 991651 effective words/s\n",
      "2018-11-06 14:04:11,578 : INFO : EPOCH 16 - PROGRESS: at 21.18% examples, 952206 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:04:12,587 : INFO : EPOCH 16 - PROGRESS: at 45.46% examples, 1007129 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:13,594 : INFO : EPOCH 16 - PROGRESS: at 66.02% examples, 975651 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:14,593 : INFO : EPOCH 16 - PROGRESS: at 87.32% examples, 969029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:15,146 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:15,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:15,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:15,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:15,156 : INFO : EPOCH - 16 : training on 5920713 raw words (4440473 effective words) took 4.6s, 967238 effective words/s\n",
      "2018-11-06 14:04:16,163 : INFO : EPOCH 17 - PROGRESS: at 23.40% examples, 1049955 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:17,175 : INFO : EPOCH 17 - PROGRESS: at 44.88% examples, 998329 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:18,188 : INFO : EPOCH 17 - PROGRESS: at 66.97% examples, 989468 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:19,197 : INFO : EPOCH 17 - PROGRESS: at 91.01% examples, 1005081 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:19,644 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:19,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:19,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:19,645 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:19,645 : INFO : EPOCH - 17 : training on 5920713 raw words (4442337 effective words) took 4.5s, 988445 effective words/s\n",
      "2018-11-06 14:04:20,665 : INFO : EPOCH 18 - PROGRESS: at 20.86% examples, 940951 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:21,664 : INFO : EPOCH 18 - PROGRESS: at 42.62% examples, 952783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:22,675 : INFO : EPOCH 18 - PROGRESS: at 65.23% examples, 967242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:23,676 : INFO : EPOCH 18 - PROGRESS: at 86.09% examples, 956686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:24,218 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:24,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:24,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:24,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:24,228 : INFO : EPOCH - 18 : training on 5920713 raw words (4440906 effective words) took 4.6s, 972692 effective words/s\n",
      "2018-11-06 14:04:25,238 : INFO : EPOCH 19 - PROGRESS: at 21.51% examples, 968903 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:26,250 : INFO : EPOCH 19 - PROGRESS: at 43.94% examples, 975338 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:27,251 : INFO : EPOCH 19 - PROGRESS: at 67.68% examples, 1000181 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:28,265 : INFO : EPOCH 19 - PROGRESS: at 89.51% examples, 989377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 14:04:28,682 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:28,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:28,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:28,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:28,692 : INFO : EPOCH - 19 : training on 5920713 raw words (4440819 effective words) took 4.5s, 996739 effective words/s\n",
      "2018-11-06 14:04:29,705 : INFO : EPOCH 20 - PROGRESS: at 21.01% examples, 942123 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:30,716 : INFO : EPOCH 20 - PROGRESS: at 44.68% examples, 988795 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:31,720 : INFO : EPOCH 20 - PROGRESS: at 66.35% examples, 979908 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:32,713 : INFO : EPOCH 20 - PROGRESS: at 88.55% examples, 982084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 14:04:33,194 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 14:04:33,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 14:04:33,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 14:04:33,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 14:04:33,194 : INFO : EPOCH - 20 : training on 5920713 raw words (4441873 effective words) took 4.5s, 986685 effective words/s\n",
      "2018-11-06 14:04:33,194 : INFO : training on a 118414260 raw words (88824872 effective words) took 105.7s, 839965 effective words/s\n"
     ]
    }
   ],
   "source": [
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:04:33.779348Z",
     "start_time": "2018-11-06T21:04:33.204359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain = []\n",
    "\n",
    "for i in range(0, len(taggedDocs)):\n",
    "    xTrain.append(np.hstack((m1.docvecs[i], m2.docvecs[i])))\n",
    "    \n",
    "len(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T22:38:34.131245Z",
     "start_time": "2018-11-06T22:20:53.725458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training KNN ....\n",
      "Training CART ....\n",
      "Training NB ....\n",
      "Training SVM ....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.88764</td>\n",
       "      <td>0.008067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.88604</td>\n",
       "      <td>0.007724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.88572</td>\n",
       "      <td>0.008335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.80780</td>\n",
       "      <td>0.003796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.80348</td>\n",
       "      <td>0.007507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.69208</td>\n",
       "      <td>0.011092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy    StdDev\n",
       "5   SVM   0.88764  0.008067\n",
       "1   LDA   0.88604  0.007724\n",
       "0    LR   0.88572  0.008335\n",
       "2   KNN   0.80780  0.003796\n",
       "4    NB   0.80348  0.007507\n",
       "3  CART   0.69208  0.011092"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init vars\n",
    "folds = 10\n",
    "seed = 10\n",
    "models = []\n",
    "results = {}\n",
    "\n",
    "# Use accuracy since this is a classification\n",
    "score = 'accuracy'\n",
    "\n",
    "# Assign training features and labels\n",
    "#xTrain = doc2vecModel.docvecs.models[0].vectors_docs\n",
    "yTrain = df.iloc[:, 1]\n",
    "\n",
    "# Instantiate model objects\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "# Run the models\n",
    "for modelName, model in models:\n",
    "    print(\"Training\", modelName, \"....\")\n",
    "    # Implement K-fold cross validation where K = 10\n",
    "    kFold = KFold(n_splits = folds, random_state = seed)\n",
    "    results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "    _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "# Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize = (8,6))\n",
    "figure.suptitle(\"Model Results\")\n",
    "axis = figure.add_subplot(111)\n",
    "plt.boxplot(results.values())\n",
    "axis.set_xticklabels(results.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increased vocabulary and combined Doc2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T22:39:05.596646Z",
     "start_time": "2018-11-06T22:39:04.128673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in the unlabeled data since it can also be utilized by Doc2Vec\n",
    "unlabeledTrainData = os.path.join(dataPath, 'unlabeledTrainData.tsv')\n",
    "dfUn = pd.read_csv(unlabeledTrainData, sep = '\\t', header = 0, quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T22:42:56.273287Z",
     "start_time": "2018-11-06T22:41:34.910825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDocs = taggedDocs.copy()\n",
    "\n",
    "for s in dfUn.iloc[:,1]:\n",
    "    clean = cleanReview(s)\n",
    "    i = len(allDocs)\n",
    "    allDocs.append(TaggedDocument(clean, [i]))    \n",
    "                   \n",
    "len(allDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:08:16.416466Z",
     "start_time": "2018-11-06T23:05:20.748520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:05:21,208 : INFO : collecting all words and their counts\n",
      "2018-11-06 16:05:21,208 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 16:05:21,609 : INFO : PROGRESS: at example #10000, processed 2385574 words (6098816/s), 51527 word types, 10000 tags\n",
      "2018-11-06 16:05:21,999 : INFO : PROGRESS: at example #20000, processed 4747503 words (6032845/s), 67813 word types, 20000 tags\n",
      "2018-11-06 16:05:22,379 : INFO : PROGRESS: at example #30000, processed 7100124 words (6148842/s), 81670 word types, 30000 tags\n",
      "2018-11-06 16:05:22,774 : INFO : PROGRESS: at example #40000, processed 9467843 words (6046613/s), 93389 word types, 40000 tags\n",
      "2018-11-06 16:05:23,198 : INFO : PROGRESS: at example #50000, processed 11865784 words (5626798/s), 103474 word types, 50000 tags\n",
      "2018-11-06 16:05:23,608 : INFO : PROGRESS: at example #60000, processed 14248889 words (5879829/s), 112175 word types, 60000 tags\n",
      "2018-11-06 16:05:23,989 : INFO : PROGRESS: at example #70000, processed 16609485 words (6196760/s), 119831 word types, 70000 tags\n",
      "2018-11-06 16:05:24,189 : INFO : collected 123504 word types and 75000 unique tags from a corpus of 75000 examples and 17797887 words\n",
      "2018-11-06 16:05:24,189 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 16:05:24,690 : INFO : effective_min_count=2 retains 74452 unique words (60% of original 123504, drops 49052)\n",
      "2018-11-06 16:05:24,690 : INFO : effective_min_count=2 leaves 17748835 word corpus (99% of original 17797887, drops 49052)\n",
      "2018-11-06 16:05:24,881 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2018-11-06 16:05:24,884 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-06 16:05:24,885 : INFO : downsampling leaves estimated 13317683 word corpus (75.0% of prior 17748835)\n",
      "2018-11-06 16:05:25,121 : INFO : estimated required memory for 74452 words and 100 dimensions: 126787600 bytes\n",
      "2018-11-06 16:05:25,121 : INFO : resetting layer weights\n",
      "2018-11-06 16:05:26,714 : INFO : collecting all words and their counts\n",
      "2018-11-06 16:05:26,724 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-06 16:05:27,089 : INFO : PROGRESS: at example #10000, processed 2385574 words (6454976/s), 51527 word types, 10000 tags\n",
      "2018-11-06 16:05:27,469 : INFO : PROGRESS: at example #20000, processed 4747503 words (6271675/s), 67813 word types, 20000 tags\n",
      "2018-11-06 16:05:27,873 : INFO : PROGRESS: at example #30000, processed 7100124 words (5877123/s), 81670 word types, 30000 tags\n",
      "2018-11-06 16:05:28,255 : INFO : PROGRESS: at example #40000, processed 9467843 words (6079585/s), 93389 word types, 40000 tags\n",
      "2018-11-06 16:05:28,646 : INFO : PROGRESS: at example #50000, processed 11865784 words (6140374/s), 103474 word types, 50000 tags\n",
      "2018-11-06 16:05:29,039 : INFO : PROGRESS: at example #60000, processed 14248889 words (6135674/s), 112175 word types, 60000 tags\n",
      "2018-11-06 16:05:29,469 : INFO : PROGRESS: at example #70000, processed 16609485 words (5533323/s), 119831 word types, 70000 tags\n",
      "2018-11-06 16:05:29,647 : INFO : collected 123504 word types and 75000 unique tags from a corpus of 75000 examples and 17797887 words\n",
      "2018-11-06 16:05:29,648 : INFO : Loading a fresh vocabulary\n",
      "2018-11-06 16:05:29,790 : INFO : effective_min_count=2 retains 74452 unique words (60% of original 123504, drops 49052)\n",
      "2018-11-06 16:05:29,790 : INFO : effective_min_count=2 leaves 17748835 word corpus (99% of original 17797887, drops 49052)\n",
      "2018-11-06 16:05:29,996 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2018-11-06 16:05:29,996 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-06 16:05:29,996 : INFO : downsampling leaves estimated 13317683 word corpus (75.0% of prior 17748835)\n",
      "2018-11-06 16:05:30,224 : INFO : estimated required memory for 74452 words and 100 dimensions: 126787600 bytes\n",
      "2018-11-06 16:05:30,224 : INFO : resetting layer weights\n",
      "2018-11-06 16:05:31,805 : INFO : training model with 4 workers on 74452 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-06 16:05:32,811 : INFO : EPOCH 1 - PROGRESS: at 9.51% examples, 1283342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:33,813 : INFO : EPOCH 1 - PROGRESS: at 19.51% examples, 1310979 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:34,818 : INFO : EPOCH 1 - PROGRESS: at 28.95% examples, 1291957 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:35,249 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:35,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:35,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:35,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:35,259 : INFO : EPOCH - 1 : training on 5920713 raw words (4453734 effective words) took 3.5s, 1288993 effective words/s\n",
      "2018-11-06 16:05:35,259 : WARNING : EPOCH - 1 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:36,267 : INFO : EPOCH 2 - PROGRESS: at 8.66% examples, 1164297 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:37,271 : INFO : EPOCH 2 - PROGRESS: at 18.52% examples, 1243512 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:38,294 : INFO : EPOCH 2 - PROGRESS: at 28.70% examples, 1274324 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 16:05:38,736 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:38,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:38,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:38,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:38,759 : INFO : EPOCH - 2 : training on 5920713 raw words (4454796 effective words) took 3.5s, 1277128 effective words/s\n",
      "2018-11-06 16:05:38,769 : WARNING : EPOCH - 2 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:39,759 : INFO : EPOCH 3 - PROGRESS: at 8.39% examples, 1128374 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:40,773 : INFO : EPOCH 3 - PROGRESS: at 17.80% examples, 1197107 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 16:05:41,773 : INFO : EPOCH 3 - PROGRESS: at 28.37% examples, 1266144 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:42,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:42,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:42,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:42,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:42,312 : INFO : EPOCH - 3 : training on 5920713 raw words (4453883 effective words) took 3.6s, 1252820 effective words/s\n",
      "2018-11-06 16:05:42,313 : WARNING : EPOCH - 3 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:43,329 : INFO : EPOCH 4 - PROGRESS: at 10.33% examples, 1392021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:44,340 : INFO : EPOCH 4 - PROGRESS: at 19.96% examples, 1342602 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:45,337 : INFO : EPOCH 4 - PROGRESS: at 30.01% examples, 1338350 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:45,683 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:45,693 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:45,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:45,703 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:45,703 : INFO : EPOCH - 4 : training on 5920713 raw words (4453996 effective words) took 3.4s, 1323057 effective words/s\n",
      "2018-11-06 16:05:45,703 : WARNING : EPOCH - 4 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:46,704 : INFO : EPOCH 5 - PROGRESS: at 9.95% examples, 1344232 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:47,710 : INFO : EPOCH 5 - PROGRESS: at 19.75% examples, 1327242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:48,707 : INFO : EPOCH 5 - PROGRESS: at 29.89% examples, 1332526 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:05:49,041 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:49,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:49,051 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:49,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:49,051 : INFO : EPOCH - 5 : training on 5920713 raw words (4454874 effective words) took 3.3s, 1330404 effective words/s\n",
      "2018-11-06 16:05:49,051 : WARNING : EPOCH - 5 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:50,057 : INFO : EPOCH 6 - PROGRESS: at 10.62% examples, 1428561 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:51,066 : INFO : EPOCH 6 - PROGRESS: at 20.73% examples, 1389035 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:52,051 : INFO : EPOCH 6 - PROGRESS: at 30.86% examples, 1373990 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:52,299 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:52,309 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:52,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:52,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:52,309 : INFO : EPOCH - 6 : training on 5920713 raw words (4453817 effective words) took 3.3s, 1369355 effective words/s\n",
      "2018-11-06 16:05:52,309 : WARNING : EPOCH - 6 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:53,317 : INFO : EPOCH 7 - PROGRESS: at 10.01% examples, 1348437 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:54,322 : INFO : EPOCH 7 - PROGRESS: at 20.19% examples, 1356203 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:05:55,322 : INFO : EPOCH 7 - PROGRESS: at 30.01% examples, 1334989 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:55,632 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:55,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:55,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:55,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:55,637 : INFO : EPOCH - 7 : training on 5920713 raw words (4455007 effective words) took 3.3s, 1335969 effective words/s\n",
      "2018-11-06 16:05:55,637 : WARNING : EPOCH - 7 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:05:56,654 : INFO : EPOCH 8 - PROGRESS: at 9.95% examples, 1329826 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 16:05:57,656 : INFO : EPOCH 8 - PROGRESS: at 19.01% examples, 1273453 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 16:05:58,678 : INFO : EPOCH 8 - PROGRESS: at 28.15% examples, 1249701 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:05:59,175 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:05:59,185 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:05:59,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:05:59,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:05:59,195 : INFO : EPOCH - 8 : training on 5920713 raw words (4454226 effective words) took 3.5s, 1258359 effective words/s\n",
      "2018-11-06 16:05:59,195 : WARNING : EPOCH - 8 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:00,212 : INFO : EPOCH 9 - PROGRESS: at 10.07% examples, 1346916 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 16:06:01,218 : INFO : EPOCH 9 - PROGRESS: at 20.99% examples, 1400731 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:02,221 : INFO : EPOCH 9 - PROGRESS: at 30.11% examples, 1337997 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:02,511 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:02,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:02,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:02,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:02,521 : INFO : EPOCH - 9 : training on 5920713 raw words (4455015 effective words) took 3.3s, 1342761 effective words/s\n",
      "2018-11-06 16:06:02,521 : WARNING : EPOCH - 9 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:03,531 : INFO : EPOCH 10 - PROGRESS: at 8.81% examples, 1188691 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:04,526 : INFO : EPOCH 10 - PROGRESS: at 17.80% examples, 1197231 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:05,531 : INFO : EPOCH 10 - PROGRESS: at 27.55% examples, 1228683 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:06,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:06,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:06,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:06,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:06,097 : INFO : EPOCH - 10 : training on 5920713 raw words (4453251 effective words) took 3.6s, 1246672 effective words/s\n",
      "2018-11-06 16:06:06,097 : WARNING : EPOCH - 10 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:07,111 : INFO : EPOCH 11 - PROGRESS: at 9.51% examples, 1280698 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:08,110 : INFO : EPOCH 11 - PROGRESS: at 19.07% examples, 1279016 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-06 16:06:09,120 : INFO : EPOCH 11 - PROGRESS: at 29.39% examples, 1309243 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:09,487 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:09,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:09,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:09,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:09,494 : INFO : EPOCH - 11 : training on 5920713 raw words (4455076 effective words) took 3.4s, 1308722 effective words/s\n",
      "2018-11-06 16:06:09,494 : WARNING : EPOCH - 11 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:10,520 : INFO : EPOCH 12 - PROGRESS: at 10.17% examples, 1372036 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:11,503 : INFO : EPOCH 12 - PROGRESS: at 20.08% examples, 1350675 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:12,519 : INFO : EPOCH 12 - PROGRESS: at 30.11% examples, 1341417 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:12,850 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:12,850 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:12,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:12,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:12,860 : INFO : EPOCH - 12 : training on 5920713 raw words (4454764 effective words) took 3.3s, 1330248 effective words/s\n",
      "2018-11-06 16:06:12,860 : WARNING : EPOCH - 12 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:13,868 : INFO : EPOCH 13 - PROGRESS: at 9.64% examples, 1299454 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:14,873 : INFO : EPOCH 13 - PROGRESS: at 18.56% examples, 1247569 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:15,889 : INFO : EPOCH 13 - PROGRESS: at 28.90% examples, 1285399 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-06 16:06:16,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:16,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:16,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:16,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:16,380 : INFO : EPOCH - 13 : training on 5920713 raw words (4453984 effective words) took 3.5s, 1269527 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:06:16,380 : WARNING : EPOCH - 13 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:17,388 : INFO : EPOCH 14 - PROGRESS: at 10.41% examples, 1392208 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:18,392 : INFO : EPOCH 14 - PROGRESS: at 19.75% examples, 1324413 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:19,383 : INFO : EPOCH 14 - PROGRESS: at 28.81% examples, 1283575 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:19,879 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:19,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:19,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:19,879 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:19,879 : INFO : EPOCH - 14 : training on 5920713 raw words (4453306 effective words) took 3.5s, 1272606 effective words/s\n",
      "2018-11-06 16:06:19,879 : WARNING : EPOCH - 14 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:20,895 : INFO : EPOCH 15 - PROGRESS: at 9.47% examples, 1275672 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:21,902 : INFO : EPOCH 15 - PROGRESS: at 19.01% examples, 1276377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:22,902 : INFO : EPOCH 15 - PROGRESS: at 28.96% examples, 1288175 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:23,278 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:23,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:23,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:23,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:23,308 : INFO : EPOCH - 15 : training on 5920713 raw words (4452826 effective words) took 3.4s, 1302549 effective words/s\n",
      "2018-11-06 16:06:23,308 : WARNING : EPOCH - 15 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:24,316 : INFO : EPOCH 16 - PROGRESS: at 10.22% examples, 1378633 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:25,301 : INFO : EPOCH 16 - PROGRESS: at 19.25% examples, 1295552 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:26,318 : INFO : EPOCH 16 - PROGRESS: at 28.70% examples, 1282459 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:26,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:26,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:26,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:26,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:26,732 : INFO : EPOCH - 16 : training on 5920713 raw words (4454735 effective words) took 3.4s, 1300860 effective words/s\n",
      "2018-11-06 16:06:26,742 : WARNING : EPOCH - 16 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:27,734 : INFO : EPOCH 17 - PROGRESS: at 9.62% examples, 1300297 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:28,734 : INFO : EPOCH 17 - PROGRESS: at 19.25% examples, 1293389 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:29,737 : INFO : EPOCH 17 - PROGRESS: at 28.54% examples, 1273669 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:30,201 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:30,201 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:30,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:30,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:30,211 : INFO : EPOCH - 17 : training on 5920713 raw words (4453485 effective words) took 3.5s, 1285103 effective words/s\n",
      "2018-11-06 16:06:30,211 : WARNING : EPOCH - 17 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:31,217 : INFO : EPOCH 18 - PROGRESS: at 9.14% examples, 1229310 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:32,230 : INFO : EPOCH 18 - PROGRESS: at 18.96% examples, 1269449 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:33,225 : INFO : EPOCH 18 - PROGRESS: at 28.81% examples, 1281902 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:33,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:33,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:33,627 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:33,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:33,628 : INFO : EPOCH - 18 : training on 5920713 raw words (4453788 effective words) took 3.4s, 1299255 effective words/s\n",
      "2018-11-06 16:06:33,629 : WARNING : EPOCH - 18 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:34,638 : INFO : EPOCH 19 - PROGRESS: at 9.46% examples, 1275543 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:35,652 : INFO : EPOCH 19 - PROGRESS: at 19.40% examples, 1302923 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:36,668 : INFO : EPOCH 19 - PROGRESS: at 29.34% examples, 1306439 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:36,989 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:36,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:37,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:37,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:37,016 : INFO : EPOCH - 19 : training on 5920713 raw words (4454173 effective words) took 3.4s, 1322479 effective words/s\n",
      "2018-11-06 16:06:37,016 : WARNING : EPOCH - 19 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:38,023 : INFO : EPOCH 20 - PROGRESS: at 8.81% examples, 1185699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:39,025 : INFO : EPOCH 20 - PROGRESS: at 18.72% examples, 1254288 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:40,027 : INFO : EPOCH 20 - PROGRESS: at 28.95% examples, 1289123 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:40,473 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:40,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:40,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:40,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:40,476 : INFO : EPOCH - 20 : training on 5920713 raw words (4454276 effective words) took 3.5s, 1284989 effective words/s\n",
      "2018-11-06 16:06:40,477 : WARNING : EPOCH - 20 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:40,478 : INFO : training on a 118414260 raw words (89083012 effective words) took 68.7s, 1296903 effective words/s\n",
      "2018-11-06 16:06:40,479 : INFO : training model with 4 workers on 74452 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-06 16:06:41,511 : INFO : EPOCH 1 - PROGRESS: at 7.06% examples, 947309 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:42,519 : INFO : EPOCH 1 - PROGRESS: at 13.56% examples, 904731 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:43,514 : INFO : EPOCH 1 - PROGRESS: at 20.87% examples, 927783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:44,534 : INFO : EPOCH 1 - PROGRESS: at 27.29% examples, 906050 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:45,308 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:45,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:45,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:45,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:45,318 : INFO : EPOCH - 1 : training on 5920713 raw words (4453206 effective words) took 4.8s, 923641 effective words/s\n",
      "2018-11-06 16:06:45,328 : WARNING : EPOCH - 1 : supplied example count (25000) did not equal expected count (75000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:06:46,329 : INFO : EPOCH 2 - PROGRESS: at 6.84% examples, 925831 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:47,349 : INFO : EPOCH 2 - PROGRESS: at 14.16% examples, 945765 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:48,359 : INFO : EPOCH 2 - PROGRESS: at 21.63% examples, 959123 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:49,361 : INFO : EPOCH 2 - PROGRESS: at 28.48% examples, 947189 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:49,958 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:49,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:49,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:49,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:49,968 : INFO : EPOCH - 2 : training on 5920713 raw words (4454327 effective words) took 4.6s, 960212 effective words/s\n",
      "2018-11-06 16:06:49,968 : WARNING : EPOCH - 2 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:50,967 : INFO : EPOCH 3 - PROGRESS: at 6.63% examples, 900338 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:51,972 : INFO : EPOCH 3 - PROGRESS: at 14.16% examples, 952586 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:52,972 : INFO : EPOCH 3 - PROGRESS: at 20.73% examples, 927805 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:53,979 : INFO : EPOCH 3 - PROGRESS: at 27.94% examples, 934421 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:06:54,729 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:54,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:54,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:54,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:54,729 : INFO : EPOCH - 3 : training on 5920713 raw words (4453392 effective words) took 4.8s, 935419 effective words/s\n",
      "2018-11-06 16:06:54,729 : WARNING : EPOCH - 3 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:06:55,730 : INFO : EPOCH 4 - PROGRESS: at 7.06% examples, 955597 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:56,734 : INFO : EPOCH 4 - PROGRESS: at 14.77% examples, 989921 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:57,757 : INFO : EPOCH 4 - PROGRESS: at 20.53% examples, 911615 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:58,774 : INFO : EPOCH 4 - PROGRESS: at 27.98% examples, 931034 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:06:59,546 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:06:59,556 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:06:59,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:06:59,566 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:06:59,566 : INFO : EPOCH - 4 : training on 5920713 raw words (4454481 effective words) took 4.8s, 922533 effective words/s\n",
      "2018-11-06 16:06:59,566 : WARNING : EPOCH - 4 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:00,572 : INFO : EPOCH 5 - PROGRESS: at 7.67% examples, 1040050 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:01,579 : INFO : EPOCH 5 - PROGRESS: at 14.42% examples, 969447 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:02,583 : INFO : EPOCH 5 - PROGRESS: at 21.63% examples, 965936 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:03,578 : INFO : EPOCH 5 - PROGRESS: at 28.59% examples, 957264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:04,406 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:04,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:04,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:04,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:04,416 : INFO : EPOCH - 5 : training on 5920713 raw words (4454306 effective words) took 4.8s, 918931 effective words/s\n",
      "2018-11-06 16:07:04,416 : WARNING : EPOCH - 5 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:05,436 : INFO : EPOCH 6 - PROGRESS: at 7.17% examples, 971021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:06,436 : INFO : EPOCH 6 - PROGRESS: at 13.83% examples, 928883 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:07,440 : INFO : EPOCH 6 - PROGRESS: at 20.99% examples, 935198 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-06 16:07:08,458 : INFO : EPOCH 6 - PROGRESS: at 28.10% examples, 935833 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:09,194 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:09,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:09,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:09,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:09,204 : INFO : EPOCH - 6 : training on 5920713 raw words (4453706 effective words) took 4.8s, 932484 effective words/s\n",
      "2018-11-06 16:07:09,204 : WARNING : EPOCH - 6 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:10,217 : INFO : EPOCH 7 - PROGRESS: at 7.34% examples, 989291 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 16:07:11,220 : INFO : EPOCH 7 - PROGRESS: at 13.29% examples, 890625 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:12,217 : INFO : EPOCH 7 - PROGRESS: at 20.82% examples, 930776 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:13,210 : INFO : EPOCH 7 - PROGRESS: at 27.49% examples, 919281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:13,930 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:13,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:13,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:13,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:13,950 : INFO : EPOCH - 7 : training on 5920713 raw words (4454238 effective words) took 4.7s, 940487 effective words/s\n",
      "2018-11-06 16:07:13,950 : WARNING : EPOCH - 7 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:14,966 : INFO : EPOCH 8 - PROGRESS: at 6.79% examples, 912521 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:15,982 : INFO : EPOCH 8 - PROGRESS: at 13.88% examples, 923923 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:16,980 : INFO : EPOCH 8 - PROGRESS: at 21.33% examples, 946980 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:17,989 : INFO : EPOCH 8 - PROGRESS: at 28.10% examples, 934944 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:18,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:18,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:18,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:18,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:18,626 : INFO : EPOCH - 8 : training on 5920713 raw words (4454630 effective words) took 4.7s, 952456 effective words/s\n",
      "2018-11-06 16:07:18,636 : WARNING : EPOCH - 8 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:19,645 : INFO : EPOCH 9 - PROGRESS: at 6.79% examples, 913348 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:20,671 : INFO : EPOCH 9 - PROGRESS: at 14.27% examples, 946026 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:21,669 : INFO : EPOCH 9 - PROGRESS: at 21.16% examples, 937754 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:22,684 : INFO : EPOCH 9 - PROGRESS: at 27.94% examples, 925971 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-06 16:07:23,359 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:23,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:23,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:07:23,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:23,379 : INFO : EPOCH - 9 : training on 5920713 raw words (4454947 effective words) took 4.7s, 940008 effective words/s\n",
      "2018-11-06 16:07:23,379 : WARNING : EPOCH - 9 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:24,389 : INFO : EPOCH 10 - PROGRESS: at 6.58% examples, 884699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:25,401 : INFO : EPOCH 10 - PROGRESS: at 13.94% examples, 927969 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:26,412 : INFO : EPOCH 10 - PROGRESS: at 20.93% examples, 929838 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:27,430 : INFO : EPOCH 10 - PROGRESS: at 28.25% examples, 936302 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:28,090 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:28,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:28,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:28,118 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:28,128 : INFO : EPOCH - 10 : training on 5920713 raw words (4454635 effective words) took 4.7s, 939294 effective words/s\n",
      "2018-11-06 16:07:28,128 : WARNING : EPOCH - 10 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:29,131 : INFO : EPOCH 11 - PROGRESS: at 6.84% examples, 929226 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:30,137 : INFO : EPOCH 11 - PROGRESS: at 14.21% examples, 954367 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:31,132 : INFO : EPOCH 11 - PROGRESS: at 20.82% examples, 928935 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:32,144 : INFO : EPOCH 11 - PROGRESS: at 28.09% examples, 936485 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:32,847 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:32,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:32,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:32,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:32,857 : INFO : EPOCH - 11 : training on 5920713 raw words (4454481 effective words) took 4.7s, 941715 effective words/s\n",
      "2018-11-06 16:07:32,857 : WARNING : EPOCH - 11 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:33,880 : INFO : EPOCH 12 - PROGRESS: at 7.17% examples, 965630 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:34,877 : INFO : EPOCH 12 - PROGRESS: at 13.83% examples, 923961 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:35,893 : INFO : EPOCH 12 - PROGRESS: at 20.14% examples, 897196 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:36,886 : INFO : EPOCH 12 - PROGRESS: at 26.98% examples, 898335 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:37,803 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:37,806 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:37,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:37,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:37,812 : INFO : EPOCH - 12 : training on 5920713 raw words (4453013 effective words) took 5.0s, 897888 effective words/s\n",
      "2018-11-06 16:07:37,813 : WARNING : EPOCH - 12 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:38,832 : INFO : EPOCH 13 - PROGRESS: at 7.22% examples, 980272 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:39,840 : INFO : EPOCH 13 - PROGRESS: at 14.70% examples, 987520 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:40,839 : INFO : EPOCH 13 - PROGRESS: at 21.85% examples, 975614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:41,849 : INFO : EPOCH 13 - PROGRESS: at 29.65% examples, 990824 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:42,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:42,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:42,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:42,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:42,392 : INFO : EPOCH - 13 : training on 5920713 raw words (4453714 effective words) took 4.6s, 975667 effective words/s\n",
      "2018-11-06 16:07:42,392 : WARNING : EPOCH - 13 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:43,399 : INFO : EPOCH 14 - PROGRESS: at 7.44% examples, 1011060 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:44,399 : INFO : EPOCH 14 - PROGRESS: at 14.37% examples, 967312 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:45,399 : INFO : EPOCH 14 - PROGRESS: at 21.69% examples, 969640 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:46,411 : INFO : EPOCH 14 - PROGRESS: at 28.95% examples, 970627 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:07:47,003 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:47,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:47,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:47,023 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:47,023 : INFO : EPOCH - 14 : training on 5920713 raw words (4454708 effective words) took 4.6s, 963533 effective words/s\n",
      "2018-11-06 16:07:47,023 : WARNING : EPOCH - 14 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:48,033 : INFO : EPOCH 15 - PROGRESS: at 7.57% examples, 1018736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:49,047 : INFO : EPOCH 15 - PROGRESS: at 14.72% examples, 983943 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:50,044 : INFO : EPOCH 15 - PROGRESS: at 21.85% examples, 972041 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:51,061 : INFO : EPOCH 15 - PROGRESS: at 28.76% examples, 957502 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:51,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:51,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:51,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:51,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:51,683 : INFO : EPOCH - 15 : training on 5920713 raw words (4453573 effective words) took 4.7s, 956465 effective words/s\n",
      "2018-11-06 16:07:51,684 : WARNING : EPOCH - 15 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:52,706 : INFO : EPOCH 16 - PROGRESS: at 7.00% examples, 943220 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:53,707 : INFO : EPOCH 16 - PROGRESS: at 13.67% examples, 915027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:54,718 : INFO : EPOCH 16 - PROGRESS: at 20.87% examples, 930433 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:55,729 : INFO : EPOCH 16 - PROGRESS: at 27.71% examples, 921340 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:56,423 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:07:56,433 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:07:56,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:07:56,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:07:56,443 : INFO : EPOCH - 16 : training on 5920713 raw words (4453493 effective words) took 4.7s, 938929 effective words/s\n",
      "2018-11-06 16:07:56,443 : WARNING : EPOCH - 16 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:07:57,446 : INFO : EPOCH 17 - PROGRESS: at 6.49% examples, 877978 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:58,449 : INFO : EPOCH 17 - PROGRESS: at 13.04% examples, 877704 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:07:59,462 : INFO : EPOCH 17 - PROGRESS: at 20.32% examples, 906953 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-06 16:08:00,453 : INFO : EPOCH 17 - PROGRESS: at 27.15% examples, 904712 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:01,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:08:01,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:08:01,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:08:01,366 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:08:01,366 : INFO : EPOCH - 17 : training on 5920713 raw words (4454302 effective words) took 4.9s, 905569 effective words/s\n",
      "2018-11-06 16:08:01,366 : WARNING : EPOCH - 17 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:08:02,375 : INFO : EPOCH 18 - PROGRESS: at 5.61% examples, 760906 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:03,375 : INFO : EPOCH 18 - PROGRESS: at 12.13% examples, 820260 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:04,369 : INFO : EPOCH 18 - PROGRESS: at 18.46% examples, 828828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:05,392 : INFO : EPOCH 18 - PROGRESS: at 23.80% examples, 797377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:08:06,383 : INFO : EPOCH 18 - PROGRESS: at 30.87% examples, 823966 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:06,736 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:08:06,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:08:06,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:08:06,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:08:06,736 : INFO : EPOCH - 18 : training on 5920713 raw words (4455627 effective words) took 5.4s, 830667 effective words/s\n",
      "2018-11-06 16:08:06,737 : WARNING : EPOCH - 18 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:08:07,742 : INFO : EPOCH 19 - PROGRESS: at 6.32% examples, 854384 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:08,762 : INFO : EPOCH 19 - PROGRESS: at 13.17% examples, 880490 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:08:09,773 : INFO : EPOCH 19 - PROGRESS: at 20.27% examples, 902612 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:08:10,785 : INFO : EPOCH 19 - PROGRESS: at 27.08% examples, 898706 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:11,595 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:08:11,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:08:11,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:08:11,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:08:11,615 : INFO : EPOCH - 19 : training on 5920713 raw words (4454560 effective words) took 4.9s, 915683 effective words/s\n",
      "2018-11-06 16:08:11,615 : WARNING : EPOCH - 19 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:08:12,626 : INFO : EPOCH 20 - PROGRESS: at 6.27% examples, 845853 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:13,627 : INFO : EPOCH 20 - PROGRESS: at 13.77% examples, 922506 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:14,640 : INFO : EPOCH 20 - PROGRESS: at 21.45% examples, 953105 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-06 16:08:15,650 : INFO : EPOCH 20 - PROGRESS: at 28.64% examples, 954266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-06 16:08:16,207 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-06 16:08:16,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-06 16:08:16,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-06 16:08:16,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-06 16:08:16,227 : INFO : EPOCH - 20 : training on 5920713 raw words (4454977 effective words) took 4.6s, 966053 effective words/s\n",
      "2018-11-06 16:08:16,227 : WARNING : EPOCH - 20 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-06 16:08:16,227 : INFO : training on a 118414260 raw words (89084316 effective words) took 95.7s, 930510 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = Doc2Vec(dm = 0, size = 100, negative = 5, hs = 0, min_count = 2, workers = cores)\n",
    "m2 = Doc2Vec(dm = 1, dm_mean = 1, size = 100, window = 10, negative = 5, hs = 0, min_count = 2, workers = cores)\n",
    "\n",
    "m1.build_vocab(allDocs)\n",
    "m2.build_vocab(allDocs)\n",
    "\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "\n",
    "xTrain = []\n",
    "for i in range(0, len(taggedDocs)):\n",
    "    xTrain.append(np.hstack((m1.docvecs[i], m2.docvecs[i])))\n",
    "\n",
    "print(len(xTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:20:30.944881Z",
     "start_time": "2018-11-06T23:08:16.416466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "2   SVM   0.88684  0.008090\n",
      "1   LDA   0.88572  0.006350\n",
      "0    LR   0.88548  0.006337\n"
     ]
    }
   ],
   "source": [
    "# Init vars\n",
    "folds = 10\n",
    "seed = 10\n",
    "models = []\n",
    "results = {}\n",
    "\n",
    "# Use accuracy since this is a classification\n",
    "score = 'accuracy'\n",
    "\n",
    "# Assign training features and labels\n",
    "#xTrain = doc2vecModel.docvecs.models[0].vectors_docs\n",
    "yTrain = df.iloc[:, 1]\n",
    "\n",
    "# Instantiate model objects\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "# Run the models\n",
    "for modelName, model in models:\n",
    "    print(\"Training\", modelName, \"....\")\n",
    "    # Implement K-fold cross validation where K = 10\n",
    "    kFold = KFold(n_splits = folds, random_state = seed)\n",
    "    results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "    _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "# Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:20:31.503881Z",
     "start_time": "2018-11-06T23:20:30.946881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = (8,6))\n",
    "figure.suptitle(\"Model Results\")\n",
    "axis = figure.add_subplot(111)\n",
    "plt.boxplot(results.values())\n",
    "axis.set_xticklabels(results.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual training of combined Doc2Vec model with increased vocab and diminishing alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:32:25.241881Z",
     "start_time": "2018-11-06T23:32:24.734881Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModels(xTrain, yTrain, modelsToRun = ['LR', 'LDA', 'SVM']):\n",
    "    # Init vars\n",
    "    folds = 10\n",
    "    seed = 10\n",
    "    models = []\n",
    "    results = {}\n",
    "\n",
    "    # Use accuracy since this is a classification\n",
    "    score = 'accuracy'\n",
    "    \n",
    "    # Instantiate model objects\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC()))\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    _df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "    # Run the models\n",
    "    for modelName, model in models:\n",
    "        if (modelName in modelsToRun) or (modelsToRun == 'all'):\n",
    "            print(\"Training\", modelName, \"....\")\n",
    "            # Implement K-fold cross validation where K = 10\n",
    "            kFold = KFold(n_splits = folds, random_state = seed)\n",
    "            results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "            _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "    # Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "    return(results, _df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T23:32:43.656881Z",
     "start_time": "2018-11-06T23:32:25.244881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:14<01:10, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:17<00:44, 11.03s/it]\n",
      "\n",
      "100%|██████████| 6/6 [00:17<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Accuracy    StdDev\n",
      "1   LDA   0.88572  0.006350\n",
      "0    LR   0.88548  0.006337\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "results, _df = trainModels(xTrain, yTrain, modelsToRun = ['LR', 'LDA'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T22:53:37.685121Z",
     "start_time": "2018-11-05T22:53:37.194129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this write-up we accomplished the following:\n",
    "\n",
    "1. Created a set of word embeddings from the IMDb movie review text utilizing Word2vec\n",
    "2. Clustered the embeddings utilizing a K-nearest neighbors algorithm into a set of centroids\n",
    "3. Trained and evaluated the models from the last write-up against the centroid feature set\n",
    "\n",
    "And finally, here is the baseline model's performance vs. the 'centroid' model we developed in this write-up:\n",
    "\n",
    "|Model|Accuracy|Best Params                           |\n",
    "|-------------------|--------|-----------------------------------|\n",
    "|LR (baseline)      |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|Kaggle centroid    |84.68%  |Estimators = 100                   |\n",
    "|SVM centroid       |86.36%  |Scikit-learn defaults              |\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "Similar to the last [last write-up](./Model-06.p2.ipynb) the work in this notebook was an interesting idea to explore, but ultimately didn't result in an overall performance increase versus the baseline model.  As such this line of exploration will be rejected in favor of keeping the current base line model and accuracy rating as benchmarks moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
