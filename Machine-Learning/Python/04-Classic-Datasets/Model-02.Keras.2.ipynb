{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Boston-Housing-Prices-Regression-Modeling-with-Keras\" data-toc-modified-id=\"Boston-Housing-Prices-Regression-Modeling-with-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Boston Housing Prices Regression Modeling with Keras</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Load-libraries-and-data\" data-toc-modified-id=\"Load-libraries-and-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load libraries and data</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Inspect-and-visualize-the-data\" data-toc-modified-id=\"Inspect-and-visualize-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inspect and visualize the data</a></span></li><li><span><a href=\"#Model-the-data\" data-toc-modified-id=\"Model-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-validation-data-set\" data-toc-modified-id=\"Create-validation-data-set-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Create validation data set</a></span></li><li><span><a href=\"#Build-models\" data-toc-modified-id=\"Build-models-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Build models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-model-function\" data-toc-modified-id=\"Build-model-function-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Build model function</a></span></li><li><span><a href=\"#Initial-pass\" data-toc-modified-id=\"Initial-pass-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Initial pass</a></span></li><li><span><a href=\"#Grid-search-hyperparameter-tuning\" data-toc-modified-id=\"Grid-search-hyperparameter-tuning-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Grid search hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Alter-tuneModel-for-RandomizedSearchCV-support\" data-toc-modified-id=\"Alter-tuneModel-for-RandomizedSearchCV-support-6.2.3.1\"><span class=\"toc-item-num\">6.2.3.1&nbsp;&nbsp;</span>Alter tuneModel for RandomizedSearchCV support</a></span></li><li><span><a href=\"#RandomizedSearchCV-hyperparameter-search\" data-toc-modified-id=\"RandomizedSearchCV-hyperparameter-search-6.2.3.2\"><span class=\"toc-item-num\">6.2.3.2&nbsp;&nbsp;</span>RandomizedSearchCV hyperparameter search</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-6.2.3.3\"><span class=\"toc-item-num\">6.2.3.3&nbsp;&nbsp;</span>Comments</a></span></li><li><span><a href=\"#Tune-network-topology\" data-toc-modified-id=\"Tune-network-topology-6.2.3.4\"><span class=\"toc-item-num\">6.2.3.4&nbsp;&nbsp;</span>Tune network topology</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-6.2.3.5\"><span class=\"toc-item-num\">6.2.3.5&nbsp;&nbsp;</span>Comments</a></span></li><li><span><a href=\"#Graph-final-model-performance\" data-toc-modified-id=\"Graph-final-model-performance-6.2.3.6\"><span class=\"toc-item-num\">6.2.3.6&nbsp;&nbsp;</span>Graph final model performance</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Final-comments\" data-toc-modified-id=\"Final-comments-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Final comments</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Boston Housing Prices Regression Modeling with Keras</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 40%; height: 40%; \" src=\"images/boston.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to build upon the [first](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) and [second](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) write-ups involving the Boston housing prices dataset.  \n",
    "\n",
    "Goals include:\n",
    "* Utilize RandomizedSearchCV for hyperparameter tuning\n",
    "* Feature selection with SelectKBest\n",
    "* Examine algorithm performance visually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source:  [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:48:58.543423Z",
     "start_time": "2018-08-29T23:48:46.981606Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:49:31.371897Z",
     "start_time": "2018-08-29T23:48:58.543423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "#import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:49:31.700097Z",
     "start_time": "2018-08-29T23:49:31.371897Z"
    }
   },
   "outputs": [],
   "source": [
    "dataFile = os.path.join(\".\", \"datasets\", \"housing.csv\")\n",
    "data = read_csv(dataFile, header = 0, delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:49:31.903215Z",
     "start_time": "2018-08-29T23:49:31.700097Z"
    }
   },
   "outputs": [],
   "source": [
    "def corrTableColors(value):\n",
    "    color = 'black'\n",
    "\n",
    "    if value == 1:\n",
    "        color = 'white'\n",
    "    elif value < -0.7:\n",
    "        color = 'red'\n",
    "    elif value > 0.7:\n",
    "        color = 'green'\n",
    "\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:49:32.090620Z",
     "start_time": "2018-08-29T23:49:31.903215Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeRange(start, stop, step = 1, multi = 1, dec = 1):\n",
    "    vals = []\n",
    "    for i in range(start, stop, step):\n",
    "        vals.append(np.round(multi * i, decimals = dec))\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect and visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please the [first Boston housing data's write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb#Inspect-and-visualize-the-data) details on this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:49:32.309426Z",
     "start_time": "2018-08-29T23:49:32.090620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (506, 13)\n",
      "y.shape =  (506,)\n",
      "--------\n",
      "xTrain.shape =  (404, 13)\n",
      "yTrain.shape =  (404,)\n",
      "xVal.shape =  (102, 13)\n",
      "yVal.shape =  (102,)\n"
     ]
    }
   ],
   "source": [
    "# Seperate X and Y values\n",
    "x = data.values[:, 0:len(data.columns) - 1]\n",
    "y = data.values[:, len(data.columns) - 1]\n",
    "\n",
    "# Uncomment if you want a smaller subset that runs faster for testing\n",
    "# x = data.values[1:50, 0:len(data.columns) - 1]\n",
    "# y = data.values[1:50, len(data.columns) - 1]\n",
    "\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"y.shape = \", y.shape)\n",
    "\n",
    "# Split out validation set -- 80/20 split\n",
    "seed = 10\n",
    "valSize = 0.2\n",
    "\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, y, test_size = valSize, random_state = seed)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"xTrain.shape = \", xTrain.shape)\n",
    "print(\"yTrain.shape = \", yTrain.shape)\n",
    "print(\"xVal.shape = \", xVal.shape)\n",
    "print(\"yVal.shape = \", yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on the `kernal_initializer`:  https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:59:06.039291Z",
     "start_time": "2018-08-29T23:59:05.820496Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrapper(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    \n",
    "    def buildModel():\n",
    "    \n",
    "        opt = None\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "        # bias_initializer -> 'zeros' (default per the docs) \n",
    "        model.add(Dense(20, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "        if optimizer.lower() == 'adam':\n",
    "            opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "        else:\n",
    "            # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "            # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "            opt = eval(optimizer)()\n",
    "\n",
    "        model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "\n",
    "        return model   \n",
    "    \n",
    "    return buildModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first pass an educated guess is taken for what might work well on the dataset.  This provides an initial baseline, and then we can tune the hyperparameters to hopefully improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:52:30.731991Z",
     "start_time": "2018-08-29T23:49:32.746934Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -17.87 (7.24)\n"
     ]
    }
   ],
   "source": [
    "# Define vars and init\n",
    "folds = 10\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn = wrapper(), epochs = 200, batch_size = 5, verbose = 0)\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "results = cross_val_score(model, xTrain, yTrain, cv = kFold)\n",
    "\n",
    "print(\"MSE: %.2f (%.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better then what the [previous](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) write-up's models accomplished with no tuning as of yet:\n",
    "\n",
    "<pre>\n",
    "         Model    MSE  StdDev\n",
    "3    scaledKNN -20.35   11.87\n",
    "0     scaledLR -21.26    7.11\n",
    "4   scaledCART -22.66    9.31\n",
    "1  scaledLASSO -26.94   10.38\n",
    "5    scaledSVR -28.52   13.98\n",
    "2     scaledEN -28.60   11.65\n",
    "</pre>\n",
    "\n",
    "It does not; however, compare to the results achieved via the ensemble methods:\n",
    "\n",
    "<pre>\n",
    "       Model     MSE  StdDev\n",
    "1  scaledGBM -9.700   5.342 \n",
    "3  scaledET  -10.339  5.399 \n",
    "2  scaledRF  -13.695  7.276 \n",
    "0  scaledAB  -14.176  8.917\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) we utilized [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).  We'd like to now examine [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "We observed in the last write-up that the `KerasRegressor` estimator utilizing the `Adam` optimizer give us good results.  We'll continue working with this combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alter tuneModel for RandomizedSearchCV support \n",
    "\n",
    "We need to alter the `tuneModel` function to support `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T23:52:31.013241Z",
     "start_time": "2018-08-29T23:52:30.731991Z"
    }
   },
   "outputs": [],
   "source": [
    "def tuneModel(modelName, modelObj, params, iterations = 20, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "    \n",
    "    np.random.seed(featureSeed)\n",
    "    \n",
    "    # Use MSE since this is a regression problem\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'MSE', 'StdDev', 'Best Params'])\n",
    "\n",
    "    # Create feature union (adding SelectKBest)\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    features.append(('SelectKBest', SelectKBest()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = RandomizedSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_distributions = params,\n",
    "        n_iter = iterations,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed),\n",
    "        random_state = featureSeed\n",
    "    ).fit(xTrain, yTrain)\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.cv_results_['std_test_score'][featureResults.best_index_],\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's dig in and see what sort of parameter combinations `RandomizedSearchCV` might be able to find for us that provide good algorithm performance.  If we would have utilized `GridSearchCV` as in the [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) we'd probably be here all week waiting for the combinations below to finish.  ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.574462Z",
     "start_time": "2018-08-28T17:59:33.228185Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-12.923</td>\n",
       "      <td>10.544</td>\n",
       "      <td>{'housingModel__optimizer': 'Adam', 'housingModel__lr': 0.005, 'housingModel__epsilon': 1.5, 'housingModel__epochs': 350, 'housingModel__batch_size': 36, 'FeatureUnion__SelectKBest__k': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model     MSE  StdDev  \\\n",
       "0  housingModel -12.923  10.544   \n",
       "\n",
       "                                                                                                                                                                                    Best Params  \n",
       "0  {'housingModel__optimizer': 'Adam', 'housingModel__lr': 0.005, 'housingModel__epsilon': 1.5, 'housingModel__epochs': 350, 'housingModel__batch_size': 36, 'FeatureUnion__SelectKBest__k': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = wrapper(), verbose = 0)\n",
    "params = {\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__epochs' : makeRange(200, 600, 50),\n",
    "    'housingModel__batch_size' : makeRange(4, 68, 4),\n",
    "    'FeatureUnion__SelectKBest__k': makeRange(1, xTrain.shape[1]),\n",
    "    'housingModel__lr' : makeRange(1, 9, 1, .001, 3),\n",
    "    'housingModel__epsilon' : makeRange(2, 8, 1, .5, 1),\n",
    "}\n",
    "\n",
    "set1 = tuneModel(modelName, modelObj, params, 10, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.777691Z",
     "start_time": "2018-08-28T19:20:26.574462Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_FeatureUnion__SelectKBest__k</th>\n",
       "      <th>param_housingModel__batch_size</th>\n",
       "      <th>param_housingModel__epochs</th>\n",
       "      <th>param_housingModel__epsilon</th>\n",
       "      <th>param_housingModel__lr</th>\n",
       "      <th>param_housingModel__optimizer</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.162</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-12.923</td>\n",
       "      <td>-5.768</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>350</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.856</td>\n",
       "      <td>-5.547</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-6.600</td>\n",
       "      <td>-25.413</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.054</td>\n",
       "      <td>10.544</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.126</td>\n",
       "      <td>1.164</td>\n",
       "      <td>-13.062</td>\n",
       "      <td>-7.470</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>400</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.158</td>\n",
       "      <td>-6.962</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>-7.158</td>\n",
       "      <td>-29.250</td>\n",
       "      <td>-5.741</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.050</td>\n",
       "      <td>9.324</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.680</td>\n",
       "      <td>1.363</td>\n",
       "      <td>-14.276</td>\n",
       "      <td>-7.638</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>550</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.706</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-6.938</td>\n",
       "      <td>-7.380</td>\n",
       "      <td>-31.150</td>\n",
       "      <td>-7.372</td>\n",
       "      <td>3.276</td>\n",
       "      <td>0.053</td>\n",
       "      <td>8.743</td>\n",
       "      <td>1.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>245.504</td>\n",
       "      <td>2.589</td>\n",
       "      <td>-14.861</td>\n",
       "      <td>-9.099</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.559</td>\n",
       "      <td>-9.178</td>\n",
       "      <td>-12.357</td>\n",
       "      <td>-7.707</td>\n",
       "      <td>-21.949</td>\n",
       "      <td>-6.987</td>\n",
       "      <td>4.468</td>\n",
       "      <td>0.074</td>\n",
       "      <td>5.186</td>\n",
       "      <td>2.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.193</td>\n",
       "      <td>2.366</td>\n",
       "      <td>-15.473</td>\n",
       "      <td>-8.751</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>250</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.321</td>\n",
       "      <td>-8.241</td>\n",
       "      <td>-8.194</td>\n",
       "      <td>-8.593</td>\n",
       "      <td>-30.608</td>\n",
       "      <td>-6.901</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.072</td>\n",
       "      <td>11.361</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.455</td>\n",
       "      <td>1.752</td>\n",
       "      <td>-15.506</td>\n",
       "      <td>-11.334</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.041</td>\n",
       "      <td>-11.962</td>\n",
       "      <td>-9.391</td>\n",
       "      <td>-10.604</td>\n",
       "      <td>-28.895</td>\n",
       "      <td>-9.480</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.065</td>\n",
       "      <td>7.814</td>\n",
       "      <td>2.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.434</td>\n",
       "      <td>1.562</td>\n",
       "      <td>-15.764</td>\n",
       "      <td>-12.118</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.848</td>\n",
       "      <td>-10.908</td>\n",
       "      <td>-8.697</td>\n",
       "      <td>-10.701</td>\n",
       "      <td>-28.050</td>\n",
       "      <td>-10.452</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.847</td>\n",
       "      <td>2.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.618</td>\n",
       "      <td>0.830</td>\n",
       "      <td>-16.429</td>\n",
       "      <td>-10.603</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.575</td>\n",
       "      <td>-12.045</td>\n",
       "      <td>-9.254</td>\n",
       "      <td>-9.697</td>\n",
       "      <td>-36.836</td>\n",
       "      <td>-10.174</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.045</td>\n",
       "      <td>10.529</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.628</td>\n",
       "      <td>2.328</td>\n",
       "      <td>-17.656</td>\n",
       "      <td>-13.179</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.712</td>\n",
       "      <td>-10.148</td>\n",
       "      <td>-9.390</td>\n",
       "      <td>-14.949</td>\n",
       "      <td>-43.857</td>\n",
       "      <td>-10.971</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.316</td>\n",
       "      <td>11.727</td>\n",
       "      <td>1.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.488</td>\n",
       "      <td>2.080</td>\n",
       "      <td>-18.634</td>\n",
       "      <td>-11.783</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>550</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.326</td>\n",
       "      <td>-8.258</td>\n",
       "      <td>-11.253</td>\n",
       "      <td>-11.688</td>\n",
       "      <td>-42.961</td>\n",
       "      <td>-12.149</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.365</td>\n",
       "      <td>11.097</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1  12.162         0.975           -12.923          -5.768              \n",
       "2  13.126         1.164           -13.062          -7.470              \n",
       "3  81.680         1.363           -14.276          -7.638              \n",
       "9  245.504        2.589           -14.861          -9.099              \n",
       "8  21.193         2.366           -15.473          -8.751              \n",
       "5  15.455         1.752           -15.506          -11.334             \n",
       "4  15.434         1.562           -15.764          -12.118             \n",
       "0  22.618         0.830           -16.429          -10.603             \n",
       "7  16.628         2.328           -17.656          -13.179             \n",
       "6  20.488         2.080           -18.634          -11.783             \n",
       "\n",
       "  param_FeatureUnion__SelectKBest__k param_housingModel__batch_size  \\\n",
       "1  2                                  36                              \n",
       "2  2                                  44                              \n",
       "3  7                                  8                               \n",
       "9  10                                 4                               \n",
       "8  2                                  36                              \n",
       "5  3                                  44                              \n",
       "4  3                                  60                              \n",
       "0  9                                  16                              \n",
       "7  2                                  36                              \n",
       "6  7                                  64                              \n",
       "\n",
       "  param_housingModel__epochs param_housingModel__epsilon  \\\n",
       "1  350                        1.5                          \n",
       "2  400                        2.5                          \n",
       "3  550                        1.5                          \n",
       "9  450                        2                            \n",
       "8  250                        2.5                          \n",
       "5  300                        2                            \n",
       "4  450                        1                            \n",
       "0  400                        1                            \n",
       "7  200                        1.5                          \n",
       "6  550                        3.5                          \n",
       "\n",
       "  param_housingModel__lr param_housingModel__optimizer       ...         \\\n",
       "1  0.005                  Adam                               ...          \n",
       "2  0.002                  Adam                               ...          \n",
       "3  0.006                  Adam                               ...          \n",
       "9  0.001                  Adam                               ...          \n",
       "8  0.002                  Adam                               ...          \n",
       "5  0.002                  Adam                               ...          \n",
       "4  0.001                  Adam                               ...          \n",
       "0  0.001                  Adam                               ...          \n",
       "7  0.001                  Adam                               ...          \n",
       "6  0.003                  Adam                               ...          \n",
       "\n",
       "  split7_test_score  split7_train_score  split8_test_score  \\\n",
       "1 -39.856           -5.547              -9.200               \n",
       "2 -33.158           -6.962              -6.769               \n",
       "3 -30.706           -4.547              -6.938               \n",
       "9 -24.559           -9.178              -12.357              \n",
       "8 -43.321           -8.241              -8.194               \n",
       "5 -30.041           -11.962             -9.391               \n",
       "4 -23.848           -10.908             -8.697               \n",
       "0 -37.575           -12.045             -9.254               \n",
       "7 -31.712           -10.148             -9.390               \n",
       "6 -36.326           -8.258              -11.253              \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "1 -6.600              -25.413            -4.548               0.551          \n",
       "2 -7.158              -29.250            -5.741               0.490          \n",
       "3 -7.380              -31.150            -7.372               3.276          \n",
       "9 -7.707              -21.949            -6.987               4.468          \n",
       "8 -8.593              -30.608            -6.901               0.540          \n",
       "5 -10.604             -28.895            -9.480               0.539          \n",
       "4 -10.701             -28.050            -10.452              0.755          \n",
       "0 -9.697              -36.836            -10.174              0.619          \n",
       "7 -14.949             -43.857            -10.971              0.592          \n",
       "6 -11.688             -42.961            -12.149              1.454          \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "1  0.054           10.544          0.755            \n",
       "2  0.050           9.324           0.706            \n",
       "3  0.053           8.743           1.411            \n",
       "9  0.074           5.186           2.525            \n",
       "8  0.072           11.361          0.837            \n",
       "5  0.065           7.814           2.542            \n",
       "4  0.086           6.847           2.520            \n",
       "0  0.045           10.529          0.718            \n",
       "7  0.316           11.727          1.596            \n",
       "6  0.365           11.097          1.657            \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_option('precision', 3)\n",
    "DataFrame(set1.cv_results_).sort_values(by=['mean_test_score', 'std_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:27.136971Z",
     "start_time": "2018-08-28T19:20:26.965128Z"
    }
   },
   "source": [
    "#### Comments\n",
    "\n",
    "From the results above it's pretty clear we're likely at a point of diminishing returns for further tuning with this set of hyperparamter options. (I also tested a number of additional iterations outside of this notebook which further confirmed this conclusion.)\n",
    "\n",
    "Likely the next logical step would be to experiment with the topology of the neural network itself such as adding additional layers and/or neurons, or we could simply disregard neural networks as an options for this problem and utilize one of the effective algorithms covered in previous write-ups. So let's do a few rounds of topology modification testing next, make a final model choice, examine some predictions, and then wrap up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:03:14.629238Z",
     "start_time": "2018-08-30T00:03:14.457322Z"
    }
   },
   "source": [
    "We'll first build a function to return a deep neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:11:38.683847Z",
     "start_time": "2018-08-30T00:11:38.511925Z"
    }
   },
   "outputs": [],
   "source": [
    "def buildModelDeep(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another function to return a wide neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:11:39.652599Z",
     "start_time": "2018-08-30T00:11:39.465105Z"
    }
   },
   "outputs": [],
   "source": [
    "def buildModelWide(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one final tweak to the tuning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:11:41.484372Z",
     "start_time": "2018-08-30T00:11:41.265517Z"
    }
   },
   "outputs": [],
   "source": [
    "def tuneFinalModel(modelName, modelObj, params, iterations = 20, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "    \n",
    "    np.random.seed(featureSeed)\n",
    "    \n",
    "    # Use MSE since this is a regression problem\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'MSE', 'StdDev', 'Best Params'])\n",
    "\n",
    "    # Create feature union (adding SelectKBest)\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    features.append(('SelectKBest', SelectKBest()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = GridSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_grid = params,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed),\n",
    "    ).fit(xTrain, yTrain)\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.cv_results_['std_test_score'][featureResults.best_index_],\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:20:18.878047Z",
     "start_time": "2018-08-30T00:20:18.706133Z"
    }
   },
   "source": [
    "##### Execute deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:15:10.435077Z",
     "start_time": "2018-08-30T00:12:16.259885Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-13.262929</td>\n",
       "      <td>9.448623</td>\n",
       "      <td>{'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model        MSE    StdDev  \\\n",
       "0  housingModel -13.262929  9.448623   \n",
       "\n",
       "                                                                                                                                                                                    Best Params  \n",
       "0  {'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalModelName = \"housingModel\"\n",
    "finalModelObj =  KerasRegressor(build_fn = buildModelDeep, verbose = 0)\n",
    "finalParams = {\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__epochs' : [350],\n",
    "    'housingModel__batch_size' : [36],\n",
    "    'FeatureUnion__SelectKBest__k': [2, 3],\n",
    "    'housingModel__lr' : [0.005],\n",
    "    'housingModel__epsilon' : [1.5],\n",
    "}\n",
    "\n",
    "final = tuneFinalModel(finalModelName, finalModelObj, finalParams, 2, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute wide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T00:18:46.370363Z",
     "start_time": "2018-08-30T00:15:10.435077Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-13.167054</td>\n",
       "      <td>10.427444</td>\n",
       "      <td>{'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model        MSE     StdDev  \\\n",
       "0  housingModel -13.167054  10.427444   \n",
       "\n",
       "                                                                                                                                                                                    Best Params  \n",
       "0  {'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalModelName = \"housingModel\"\n",
    "finalModelObj =  KerasRegressor(build_fn = buildModelWide, verbose = 0)\n",
    "finalParams = {\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__epochs' : [350],\n",
    "    'housingModel__batch_size' : [36],\n",
    "    'FeatureUnion__SelectKBest__k': [2, 3],\n",
    "    'housingModel__lr' : [0.005],\n",
    "    'housingModel__epsilon' : [1.5],\n",
    "}\n",
    "\n",
    "final = tuneFinalModel(finalModelName, finalModelObj, finalParams, 2, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "There doesn't really seem to be much of an improvement, so sticking with the original neural network we trained and tuned seems fine to continue on with.  Also, frankly at this point if this was a real problem I'd likely revert to the Gradient Boosting ensemble we tested in the [first write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb), and see what kind of additional performance could be gained with that model.\n",
    "\n",
    "For reference here were the results of the ensemble algorithms:\n",
    "\n",
    "<pre>\n",
    "       Model     MSE  StdDev\n",
    "1  scaledGBM -9.700   5.342 \n",
    "3  scaledET  -10.339  5.399 \n",
    "2  scaledRF  -13.695  7.276 \n",
    "0  scaledAB  -14.176  8.917 \n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.965128Z",
     "start_time": "2018-08-28T19:20:26.777691Z"
    }
   },
   "source": [
    "#### Graph final model performance\n",
    "\n",
    "Let's go ahead and do a little more testing on the final model, because frankly I'm a little unconvinced that K = 2 is a good choice for mitigating correlated features.  It seems like we might remove some desired detail from the data with such an aggressive feature pruning.\n",
    "\n",
    "##### Final model tuning for K best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T01:25:14.392120Z",
     "start_time": "2018-08-30T00:33:41.150293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 50.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.961790543418225\n"
     ]
    }
   ],
   "source": [
    "# Init vars and params\n",
    "folds = 10\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "modelName = 'finalModel'\n",
    "\n",
    "# Use MSE since this is a regression problem\n",
    "score = 'neg_mean_squared_error'\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "df = DataFrame(columns = ['Model', 'MSE', 'StdDev'])\n",
    "\n",
    "# Build the model\n",
    "model = KerasRegressor(\n",
    "    build_fn = wrapper(\n",
    "        optimizer = 'Adam', \n",
    "        lr = 0.005, \n",
    "        epsilon = 1.5\n",
    "    ), \n",
    "    epochs = 350,\n",
    "    batch_size = 36,\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Create feature union\n",
    "combined = FeatureUnion([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"select\", SelectKBest())\n",
    "])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([(\"features\", combined), (modelName, model)])\n",
    "\n",
    "# Define param grid to search over\n",
    "param_grid = dict(\n",
    "    features__select__k = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    ")\n",
    "\n",
    "# Create cross validation object\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid = param_grid, \n",
    "    scoring = score,\n",
    "    cv = kFold,\n",
    "    verbose = 1)\n",
    "\n",
    "# Train the model and search for optimal hyperparams\n",
    "grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "# Output\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T01:25:14.630135Z",
     "start_time": "2018-08-30T01:25:14.395123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score                       params\n",
      "0  -13.961791        11.748834       {'features__select__k': 2} \n",
      "1  -14.346668        10.508962       {'features__select__k': 3} \n",
      "2  -15.122275        10.261842       {'features__select__k': 4} \n",
      "5  -16.356510        8.218922        {'features__select__k': 7} \n",
      "7  -16.430802        6.577576        {'features__select__k': 9} \n",
      "3  -16.843143        11.069252       {'features__select__k': 5} \n",
      "11 -17.088482        8.540777        {'features__select__k': 13}\n",
      "9  -17.318703        4.992174        {'features__select__k': 11}\n",
      "4  -17.832024        10.696923       {'features__select__k': 6} \n",
      "6  -18.295784        10.542066       {'features__select__k': 8} \n",
      "8  -18.450330        12.740765       {'features__select__k': 10}\n",
      "10 -31.943834        41.436519       {'features__select__k': 12}\n"
     ]
    }
   ],
   "source": [
    "_df = DataFrame(grid_search.cv_results_)\n",
    "print(_df.loc[:, ['mean_test_score', 'std_test_score', 'params']].sort_values(by = ['mean_test_score', 'std_test_score'], ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrmmph!  It appears our model insists on K = 2, so that's what we'll go with.  ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph the model's loss\n",
    "\n",
    "OK, now we have the hyperparameters picked out for the final model.  We'll go ahead and fit it, graph the performance during training, and then make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T01:28:30.879926Z",
     "start_time": "2018-08-30T01:27:41.363388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature union\n",
    "combined = FeatureUnion([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"select\", SelectKBest(k = 2))\n",
    "])\n",
    "\n",
    "xFeatures     = combined.fit(xTrain, yTrain).transform(xTrain)\n",
    "xValFeatures  = combined.fit(xTrain, yTrain).transform(xVal)\n",
    "\n",
    "history = model.fit(xFeatures, yTrain, validation_data=(xValFeatures, yVal))\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T06:03:49.728302Z",
     "start_time": "2018-08-30T06:03:49.371345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAFNCAYAAACXC791AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcXGd97/nP75xaelerW63FkqzFVsALIGQBBjNhgs1iZzGZmAATLo7jXA255IZsMzFJJiFAXtfM3ARwYMg4scEmCQ6BMDgJAYyBGwjBtgB5wUZYNrbVVkvdWnrvrvU3fzynpHK7W2qpu7q6q77v16teVfXUqVO/U9u3nuecOsfcHRERkWYT1bsAERGRelAAiohIU1IAiohIU1IAiohIU1IAiohIU1IAiohIU1IAiixTZrbVzNzMUvOY9pfN7FtLUZdIo1AAiiwCM3vKzPJmtmZG+74kxLbWp7KzC1KRZqIAFFk8PwbeVrliZi8CWutXjoicjgJQZPF8CnhH1fXrgTurJzCzVWZ2p5kNmdnTZvaHZhYlt8Vm9t/N7KiZPQn89Cz3vc3MBszsWTP7gJnFCynYzLJm9mEzO5ScPmxm2eS2NWb2z2Y2bGbHzeybVbX+XlLDmJntN7MrF1KHSD0oAEUWz3eALjO7KAmmtwB/M2OavwBWAduB1xAC84bktv8M/AzwUmA3cN2M+94BFIELk2leD/zqAmv+A+ByYCfwEuDlwB8mt/0O0A/0AeuA3wfczF4A/DrwMnfvBN4APLXAOkSWnAJQZHFVeoGvA34IPFu5oSoU3+PuY+7+FPBnwH9KJvlF4MPuftDdjwP/req+64Crgd909wl3HwQ+BLx1gfX+EvA+dx909yHgT6rqKQAbgC3uXnD3b3rYeXAJyAIXm1na3Z9y9ycWWIfIklMAiiyuTwH/K/DLzBj+BNYAGeDpqrangY3J5fOAgzNuq9gCpIGBZEhyGPh/gbULrPe8Weo5L7n8fwMHgK+Y2ZNmdhOAux8AfhN4LzBoZneZ2XmIrDAKQJFF5O5PEzaGuQb4xxk3HyX0qrZUtZ3PqV7iALB5xm0VB4EcsMbdu5NTl7tfssCSD81Sz6FkWcbc/XfcfTvws8BvV9b1ufvfufurk/s68MEF1iGy5BSAIovvRuC17j5R3ejuJeAzwJ+aWaeZbQF+m1PrCT8D/IaZbTKz1cBNVfcdAL4C/JmZdZlZZGYXmNlrzqKurJm1VJ0i4NPAH5pZX/IXjj+q1GNmP2NmF5qZAaOEoc+Smb3AzF6bbCwzDUwlt4msKApAkUXm7k+4+945bv6vwATwJPAt4O+A25Pb/gr4MvAg8D2e34N8B2EI9VHgBPBZwjq6+RonhFXl9FrgA8Be4CHg4eRxP5BMvwP4anK//wD+H3f/BmH9382EHu1hwjDs759FHSLLgumAuCIi0ozUAxQRkaakABQRkaakABQRkaakABQRkaakABQRkaa0og+PsmbNGt+6dWu9yxARkWXku9/97lF37zvTdCs6ALdu3crevXP93UpERJqRmT195qk0BCoiIk1KASgiIk1JASgiIk1pRa8DnE2hUKC/v5/p6el6l7JkWlpa2LRpE+l0ut6liIisGA0XgP39/XR2drJ161bCTuwbm7tz7Ngx+vv72bZtW73LERFZMRpuCHR6epre3t6mCD8AM6O3t7eperwiIouh4QIQaJrwq2i25RURWQwNGYD1dOzYMXbu3MnOnTtZv349GzduPHk9n8/Pax433HAD+/fvr3GlIiLNreHWAdZbb28v+/btA+C9730vHR0d/O7v/u5zpnF33J0omv33xyc+8Yma1yki0uzUA5w6AYWpmj/MgQMHuPTSS3nnO9/Jrl27GBgYYM+ePezevZtLLrmE973vfSenffWrX82+ffsoFot0d3dz00038ZKXvIRXvvKVDA4O1rxWEZFm0NwBWC7BSD+ceArK5Zo/3KOPPsqNN97I97//fTZu3MjNN9/M3r17efDBB7nnnnt49NFHn3efkZERXvOa1/Dggw/yyle+kttvv73mdYqINIOGHgL9k3/6AY8eGj39ROUSFKcgHoQ4c8Z5XnxeF3/8s5ecUz0XXHABL3vZy05e//SnP81tt91GsVjk0KFDPProo1x88cXPuU9raytXX301AJdddhnf/OY3z+mxRUTkuRo6AOcliiFKQakwrwBciPb29pOXH3/8cT7ykY9w//33093dzdvf/vZZ/8qQyZyqKY5jisViTWsUEWkWDR2A8+6pTY/A8Sdh9TZo7a5tUYnR0VE6Ozvp6upiYGCAL3/5y7zxjW9ckscWEZEGD8B5y3aFXuD08JIF4K5du7j44ou59NJL2b59O1dcccWSPK6IiATm7vWu4Zzt3r3bZx4P8LHHHuOiiy46+5kdPQBegr4XLFJ1S+ucl1tEpMGY2XfdffeZpmvurUCrpbNQnIYV/INARETmTwFYkWoBL0O5UO9KRERkCSgAK+JsOC/m6luHiIgsCQVgRaolnBd1VAURkWZQswA0sxeY2b6q06iZ/aaZ9ZjZPWb2eHK+OpnezOwWMztgZg+Z2a5a1TarOA0WqQcoItIkahaA7r7f3Xe6+07gMmAS+DxwE3Cvu+8A7k2uA1wN7EhOe4CP16q2WZlBlA5/iBcRkYa3VEOgVwJPuPvTwLXAHUn7HcCbksvXAnd68B2g28w2LFF9QRSFDWEWYDEOhwRw++23c/jw4QXVIiIic1uqP8K/Ffh0cnmduw8AuPuAma1N2jcCB6vu05+0DSxRjWBx+C/gAszncEjzcfvtt7Nr1y7Wr1+/oHpERGR2NQ9AM8sAPwe850yTztL2vD/lmdkewhAp559//oLre+7Mo5oOgd5xxx187GMfI5/P86pXvYqPfvSjlMtlbrjhBvbt24e7s2fPHtatW8e+fft4y1veQmtrK/fff/9z9gkqIiILtxQ9wKuB77n7keT6ETPbkPT+NgCVA9z1A5ur7rcJODRzZu5+K3ArhD3BLGqlFoPXZivQRx55hM9//vN8+9vfJpVKsWfPHu666y4uuOACjh49ysMPPwzA8PAw3d3d/MVf/AUf/ehH2blzZ03qERFpdksRgG/j1PAnwN3A9cDNyfkXqtp/3czuAl4BjFSGSs/Zv94Ehx+e//TFaSgXIdMx9zTrXwRX33zWpXz1q1/lgQceYPfusHeeqakpNm/ezBve8Ab279/Pu9/9bq655hpe//rXn/W8RUTk7NU0AM2sDXgd8L9VNd8MfMbMbgSeAd6ctH8RuAY4QNhi9IZa1jYrm20UdnG4O7/yK7/C+9///ufd9tBDD/Gv//qv3HLLLXzuc5/j1ltvrVkdIiIS1DQA3X0S6J3RdoywVejMaR1416IWcLY9tdEBGD8MG3YuehheddVVXHfddbz73e9mzZo1HDt2jImJCVpbW2lpaeHNb34z27Zt453vfCcAnZ2djI2NLWoNIiJyig6HVC1K/hXi5bA+cBG96EUv4o//+I+56qqrKJfLpNNp/vIv/5I4jrnxxhtxd8yMD37wgwDccMMN/Oqv/qo2ghERqREdDqnaxFEYOQjrLqn50eEXmw6HJCIS6HBI58KSp6O8sD/Di4jI8qcArBYlw54L/DO8iIgsfwrAala1DlBERBpaQwbgOa/XXKFDoCt5Pa6ISL00XAC2tLRw7NixcwsFW3lDoO7OsWPHaGlpqXcpIiIrSsP9DWLTpk309/czNDR09ncul2B0EAaLkD1y5umXiZaWFjZt2lTvMkREVpSGC8B0Os22bdvO7c7To3DzFfC698PO31jcwkREZFlpuCHQBansAzQ/Xt86RESk5hSA1aII0u2Qn6h3JSIiUmMKwJmyHZDTPjhFRBqdAnCmdJt6gCIiTUABOFMqC6V8vasQEZEaUwDOFKXDQXFFRKShKQBnitPqAYqINAEF4ExxGkqFelchIiI1pgCcKc4oAEVEmoACcKYoBWUFoIhIo1MAzhRntA5QRKQJKABnitNQ0lagIiKNTgE4k7YCFRFpCgrAmaK01gGKiDQBBeBM2gpURKQpKABn0v8ARUSaQk0D0My6zeyzZvZDM3vMzF5pZj1mdo+ZPZ6cr06mNTO7xcwOmNlDZrarlrXNSesARUSaQq17gB8BvuTuLwReAjwG3ATc6+47gHuT6wBXAzuS0x7g4zWubXZxRvsCFRFpAjULQDPrAn4SuA3A3fPuPgxcC9yRTHYH8Kbk8rXAnR58B+g2sw21qm9OUUo9QBGRJlDLHuB2YAj4hJl938z+2szagXXuPgCQnK9Npt8IHKy6f3/StrQqG8G4L/lDi4jI0qllAKaAXcDH3f2lwASnhjtnY7O0PS+FzGyPme01s71DQ0OLU2m1OB0etlxa/HmLiMiyUcsA7Af63f2+5PpnCYF4pDK0mZwPVk2/uer+m4BDM2fq7re6+253393X17f4VcfpcK7/AoqINLSaBaC7HwYOmtkLkqYrgUeBu4Hrk7brgS8kl+8G3pFsDXo5MFIZKl1SURKAWg8oItLQUjWe/38F/tbMMsCTwA2E0P2Mmd0IPAO8OZn2i8A1wAFgMpl26cWZcK79gYqINLSaBqC77wN2z3LTlbNM68C7alnPvMTJU6IeoIhIQ9OeYGaq9AC1DlBEpKEpAGc6uQ5QASgi0sgUgDPFCkARkWagAJwp1lagIiLNQAE408mtQNUDFBFpZArAmaJkK1BtBCMi0tAUgDOd7AFqCFREpJEpAGfSRjAiIk1BATiTAlBEpCk0fQDedf8z7D88dqoh0s6wRUSaQVMH4Nh0gQ999Ue8/bb7ePrYRGjUOkARkabQ1AHY2ZLmUze+gkKpzG/9/T7cvWoIVDvDFhFpZE0dgAA/sa6T37/6Ir73zDB3P3hIf4QXEWkSTR+AANddtonta9r5h739WgcoItIkFIBAFBmveUEfDzx1nGmPQ6O2AhURaWgKwMQVF6whVyzz4KFkYxgFoIhIQ1MAJl6xvYc4Mv7jx6OhQesARUQamgIw0dmSZtuadvYfzYWGsrYCFRFpZArAKms6MhydLAKmHqCISINTAFZZ05Hl6Hg+/Ble6wBFRBqaArDKmo4sR8dy4b+ACkARkYamAKyypiPDWK6Ix2n9D1BEpMEpAKus6cgCULaU1gGKiDQ4BWCVSgCWLK19gYqINLiaBqCZPWVmD5vZPjPbm7T1mNk9ZvZ4cr46aTczu8XMDpjZQ2a2q5a1zaa3IxwJokSsHqCISINbih7gT7n7TnffnVy/CbjX3XcA9ybXAa4GdiSnPcDHl6C256j0AAtoCFREpNHVYwj0WuCO5PIdwJuq2u/04DtAt5ltWMrCKgGYR1uBiog0uloHoANfMbPvmtmepG2duw8AJOdrk/aNwMGq+/YnbUumNRPTnonJeQqK00v50CIissRSNZ7/Fe5+yMzWAveY2Q9PM63N0ubPmygE6R6A888/f3GqrNLbkWXK01DMLfq8RURk+ahpD9DdDyXng8DngZcDRypDm8n5YDJ5P7C56u6bgEOzzPNWd9/t7rv7+voWvea2TEyONJQUgCIijaxmAWhm7WbWWbkMvB54BLgbuD6Z7HrgC8nlu4F3JFuDXg6MVIZKl1I2FZFHQ6AiIo2ulkOg64DPm1nlcf7O3b9kZg8AnzGzG4FngDcn038RuAY4AEwCN9SwtjllUzHTGgIVEWl4NQtAd38SeMks7ceAK2dpd+BdtapnvrLpiGkUgCIijU57gpkhm4rJlVMKQBGRBqcAnCGbjpKtQLUOUESkkdX6bxArTksqZqqcArQnGBGRRqYe4AzZdBQCsDgN/ry/IYqISINQAM6QTUVMllPgZSjriBAiIo1KAThDSzoOAQjaEEZEpIEpAGc42QMEBaCISANTAM6QTSW7QgPtDk1EpIEpAGdoSUfkvdID1F8hREQalQJwhtADDEeG1xCoiEjjUgDOkE1Fp4ZAFYAiIg1LAThDSzoOR4MABaCISANTAM6QTUXkvDIEqnWAIiKNSgE4QzZdNQRa0u7QREQalQJwhucOgaoHKCLSqBSAM2gjGBGR5qAAnOE5f4RXAIqINCwF4Awt6YicVwJQQ6AiIo1KATiDeoAiIs1BAThDNhWR175ARUQangJwhrAVqHqAIiKNTgE4QyYVUSaiZCkFoIhIA1MAzhBHRjo2ipZRAIqINDAF4CxaUjHFKKOtQEVEGpgCcBbZdETBMtoIRkSkgdU8AM0sNrPvm9k/J9e3mdl9Zva4mf29mWWS9mxy/UBy+9Za1zaXbCqmSFpDoCIiDWwpeoDvBh6ruv5B4EPuvgM4AdyYtN8InHD3C4EPJdPVRTYdkbc0FKbqVYKIiNRYTQPQzDYBPw38dXLdgNcCn00muQN4U3L52uQ6ye1XJtMvuUwcMWWtkB+vx8OLiMgSqHUP8MPA/wGUk+u9wLC7F5Pr/cDG5PJG4CBAcvtIMv2Sy6Zjxq0Dpobr8fAiIrIE5hWAZnaBmWWTy/+zmf2GmXWf4T4/Awy6+3erm2eZ1OdxW/V895jZXjPbOzQ0NJ/yz1o2jhizDphWAIqINKr59gA/B5TM7ELgNmAb8HdnuM8VwM+Z2VPAXYShzw8D3WaWHHCPTcCh5HI/sBkguX0VcHzmTN39Vnff7e67+/r65ln+2cmkIkZph+mRmsxfRETqb74BWE6GJX8e+LC7/xaw4XR3cPf3uPsmd98KvBX4mrv/EvB14LpksuuBLySX706uk9z+NXd/Xg9wKTwnAMvlM99BRERWnPkGYMHM3kYIqH9O2tLn+Ji/B/y2mR0grOO7LWm/DehN2n8buOkc579g2VTESLkNvAz5sXqVISIiNZQ68yQA3AC8E/hTd/+xmW0D/ma+D+Lu3wC+kVx+Enj5LNNMA2+e7zxrKZOKGPb2cGVqGFpW1bcgERFZdPMKQHd/FPgNADNbDXS6+821LKyeMnHEiXJbuKL1gCIiDWm+W4F+w8y6zKwHeBD4hJn9eW1Lq59MKuLYyQDUlqAiIo1ovusAV7n7KPC/AJ9w98uAq2pXVn1lUzHHS0kA6r+AIiINab4BmDKzDcAvcmojmIaVSUUcK7aGK+oBiog0pPkG4PuALwNPuPsDZrYdeLx2ZdVXJhVxtFQJQK0DFBFpRPPdCOYfgH+ouv4k8Au1KqresqmIcVpxizANgYqINKT5bgSzycw+b2aDZnbEzD6X7Oi6IWVTEWB4dpWGQEVEGtR8h0A/QdhTy3mEnVb/U9LWkDKp8LR4yyoNgYqINKj5BmCfu3/C3YvJ6ZNAbXbEuQxk4vC0lLKrtBWoiEiDmm8AHjWztydHd4/N7O3AsVoWVk/ZdBKAqQ4dE1BEpEHNNwB/hfAXiMPAAGFn1TfUqqh6y8QxAMV0O+QUgCIijWheAejuz7j7z7l7n7uvdfc3Ef4U35Aq6wCLqXbIjda5GhERqYWFHBH+txetimUmmwRgIW7XEKiISINaSADOdgT3hlDpAeZTGgIVEWlUCwnAuhysdimcDMC4DUo5KObrXJGIiCy20+4JxszGmD3oDGitSUXLQOVvEDlLdoidH4dUTx0rEhGRxXbaAHT3zqUqZDlpSf4GMR0nB8XNjUKbAlBEpJEsZAi0YVX+BjFtSSdX6wFFRBqOAnAWlXWAk5UA1JagIiINRwE4i8rfIKYq6wBzY3WsRkREakEBOIvn9QAVgCIiDUcBOItKAE6gIVARkUalAJxFKjLMYNzVAxQRaVQKwFmYWXJU+Gxo0FagIiINRwE4h0wckStFkG7TDrFFRBpQzQLQzFrM7H4ze9DMfmBmf5K0bzOz+8zscTP7ezPLJO3Z5PqB5PattaptPjKpmFyxBBkdE1BEpBHVsgeYA17r7i8BdgJvNLPLgQ8CH3L3HcAJ4MZk+huBE+5+IfChZLq6yaYicsUyZDs1BCoi0oBqFoAeVJIjnZwceC3w2aT9DuBNyeVrk+skt19pZnU74kQ2FZEvliHboY1gREQaUE3XAZpZbGb7gEHgHuAJYNjdi8kk/cDG5PJG4CBAcvsI0DvLPPeY2V4z2zs0NFSz2rPpmOlCCTKdGgIVEWlANQ1Ady+5+05gE/By4KLZJkvOZ+vtPe9IFO5+q7vvdvfdfX19i1fsDKtaU4xOFZMhUG0EIyLSaJZkK1B3Hwa+AVwOdJtZ5SgUm4BDyeV+YDNAcvsq4PhS1Deb7tYMw1P5ZAhUPUARkUZTy61A+8ysO7ncClwFPAZ8Hbgumex64AvJ5buT6yS3f83d63bQ3e62NMOTBW0FKiLSoE57PMAF2gDcYWYxIWg/4+7/bGaPAneZ2QeA7wO3JdPfBnzKzA4Qen5vrWFtZ7SqLc3wVAHPdmLaCEZEpOHULADd/SHgpbO0P0lYHzizfRp4c63qOVvdrRnyxTLFVDvp4jSUihDX8veCiIgsJe0JZg7dbWkAJiuHRMqrFygi0kgUgHPobg0BOEFLaNAwqIhIQ1EAzmFV0gMcO3lECG0IIyLSSBSAc+huzQAwVq4cEUI9QBGRRqIAnENlHeCJUjIEqnWAIiINRQE4h0oAHi/qmIAiIo1IATiH1nRMJo44VghDoRoCFRFpLArAOZgZq9rSHM2HnqD2BiMi0lgUgKfR3ZrmSC4JQPUARUQaigLwNLrb0hyfcki1KABFRBqMAvA0VrVmGJ7SDrFFRBqRAvA0utvSjEzmk2MCqgcoItJIFICn0d0ajgihYwKKiDQeBeBpdLelmcyXKGe6dFR4EZEGowA8jVVt4T+A+cwqmDpR52pERGQxKQBPo3JEiFyqCyaP17kaERFZTArA0zh5TMBU0gN0r3NFIiKyWBSAp3HyiBDWAaUcFKbqXJGIiCwWBeBpVHqAI9YZGqY0DCoi0igUgKdROSjucLkjNGhDGBGRhqEAPI3ObIo4Mo6W20ODNoQREWkYCsDTMDNWtaYZKraFBvUARUQahgLwDLrb0hxWAIqINJxUvQtY7rpb0xzKWbiijWBERBpGzXqAZrbZzL5uZo+Z2Q/M7N1Je4+Z3WNmjyfnq5N2M7NbzOyAmT1kZrtqVdvZ6O3IcnjCINWqHqCISAOp5RBoEfgdd78IuBx4l5ldDNwE3OvuO4B7k+sAVwM7ktMe4OM1rG3e1nRkODqeh7YemFQAiog0ipoFoLsPuPv3kstjwGPARuBa4I5ksjuANyWXrwXu9OA7QLeZbahVffPV257l+EQOb+1WD1BEpIEsyUYwZrYVeClwH7DO3QcghCSwNplsI3Cw6m79SVtd9XZkKDsUsz0webTe5YiIyCKpeQCaWQfwOeA33f10xxSyWdqet/NNM9tjZnvNbO/Q0NBilTmn3o4sAFPZXhg/UvPHExGRpVHTADSzNCH8/tbd/zFpPlIZ2kzOB5P2fmBz1d03AYdmztPdb3X33e6+u6+vr3bFJ9a0h/2BjqfXwNgR7RBbRKRB1HIrUANuAx5z9z+vuulu4Prk8vXAF6ra35FsDXo5MFIZKq2nSg9wOO6B4pQOjCsi0iBq+T/AK4D/BDxsZvuStt8HbgY+Y2Y3As8Ab05u+yJwDXAAmARuqGFt89bbEXqAR1kdGsYOQ8uqOlYkIiKLoWYB6O7fYvb1egBXzjK9A++qVT3nanVbhshgoNwdGsYOQ98L6luUiIgsmHaFdgZxZPS0Z+gvJL0+bQgjItIQtCu0eehtz/J0PgyFMna4vsWIiMiiUA9wHno7MhyciCHdpgAUEWkQCsB5WNfVwuBYHjrWwbgCUESkESgA52FtZ5ahsRzeuT78F1BERFY8BeA89HVmyZfKFFrXqgcoItIgFIDzsLarBYDxzBqtAxQRaRAKwHlY1xn2BjMS90B+HHLjda5IREQWSgE4D5Ue4Mm9wei/gCIiK54CcB7WJj3Aw9V7gxERkRVNATgP7dkU7ZmYg8Wu0DBW9310i4jIAmlPMPO0rquFH0+HoVANgYqIrHwKwHla25XlyfEyxFkNgYqINAANgc7Txu42+oenkr3BqAcoIrLSKQDnaXNPK0dGc5Q71modoIhIA1AAztPm1W0ATLash5Fn61yNiIgslAJwnjatbgXgePY8GH4GyqU6VyQiIguhAJynzT2hBzhg66FcgNFDda5IREQWQgE4T+u6WkjHxpOltaHhxFN1rUdERBZGAThPcWSc193KY7me0HDix/UtSEREFkT/AzwL5/e08dBoBBarBygissKpB3gWtq9p58DRabx7swJQRGSFUwCehQvWdjCeK5Lv2gLHn6x3OSIisgAKwLNwQV8HAMdaL4DBx6BUrHNFIiJyrhSAZ6ESgE+mL4DiNBz9UZ0rEhGRc1WzADSz281s0MweqWrrMbN7zOzx5Hx10m5mdouZHTCzh8xsV63qWoh1XVnaMzEPFreGhsMP1bUeERE5d7XsAX4SeOOMtpuAe919B3Bvch3gamBHctoDfLyGdZ0zM2N7Xwf3jfVAqhUGHqx3SSIico5qFoDu/m/A8RnN1wJ3JJfvAN5U1X6nB98Bus1sQ61qW4gXru/kkYEJfP2LFIAiIivYUq8DXOfuAwDJebJbFTYCB6um60/alp2XbO7m+ESe8Z5LYOAhKJfrXZKIiJyD5bIRjM3S5rNOaLbHzPaa2d6hoaEal/V8Ozd3A/BEvB3yY9ojjIjICrXUAXikMrSZnA8m7f3A5qrpNgGz7m3a3W91993uvruvr6+mxc7mBes7yaQiHsgl5WoYVERkRVrqALwbuD65fD3whar2dyRbg14OjFSGSpebdBxx6Xld3Hu0B6K0AlBEZIWq5d8gPg38B/ACM+s3sxuBm4HXmdnjwOuS6wBfBJ4EDgB/BfyXWtW1GC7bsprvPTtJee3FMLCv3uWIiMg5qNnOsN39bXPcdOUs0zrwrlrVsthesa2Xv/rmjxnsvJj1z/xLODhuFNe7LBEROQvLZSOYFeVl23owg+/bxZAbhcMP17skERE5SwrAc7CqNc1F67u4e3hraHj63+taj4iInD0F4Dl67QvX8uWDMcVVW+ApBaCIyEqjADxHP79rI2WHA60vgWe+rT/Ei4isMArAc3RBXwcvPb+bfxrZBlMnYOixepckIiJnQQG4AL+waxNfGN4ermgYVERkRVEALsDPvvj3w/IBAAAVgklEQVQ8BuN1DGfWwdPfqnc5IiJyFhSAC7CqLc3rLl7H/8i/EH/y36BUqHdJIiIyTwrABfqVK7bxL/ld2PQJeEq9QBGRlUIBuECXbVnNxObXMEkLpR/8f/UuR0RE5kkBuAhueM3FfLX0UoqPfAGK+XqXIyIi86AAXASvfeFavtNxFdn8CcqPf6Xe5YiIyDwoABdBFBkvu/I6hnwVg/92e73LERGReVAALpKf27WFr2avYu3A15j88f31LkdERM5AAbhI4sjY/vP/J0O+iqG73oWXivUuSURETkMBuIhecdE2Hr7099iS+xHf/PQH612OiIichgJwkV35C+/ksbbdXPb4R/jSl/+53uWIiMgcFICLzKKIbb96JxPp1bzq2/+ZT/71Rzg+NlXvskREZAYFYA209Gxk9a99memOTfxy/x+R/7NL+OZd/50Tg/31Lk1ERBIKwBpJ925l7W99i4HXfZzJdA//0w/fT+fHXsTjH/0FRh+4KxxCSURE6sbcvd41nLPdu3f73r17613GGXm5xJMP/TtPfP1OLhv+Er02RhljtOsnaLvgVWTO3w3rXww92yDbWe9yRURWNDP7rrvvPuN0CsCltf/QMA98+x5yP/wqP5F7hJdGB+iw6ZO3e9sarPdCWHMh9CanzvOgY204pbJ1rF5EZPlTAC5z7s73Dw7zLw8+y48e3UfXyH7Ot0EuSA1yUWaQjaVn6S7PMkyaXQUdfdDeB6kWiDMQp0Mw9l4ImXbIdoXbILSnW+HQPkhlYN2LoFyA1p4wfUtXmMYdnvgamMH2nwIvQzEXbovipX1yJHCHg/fB2ougZdXc05XL4XUzW7raaq1UgCg1v2XKjYVp061nmGcRykVItyxOjYuhVAyfr8pyTg1Dui18VheLezhFM9Z4jR2Bo/thyxXP/YyXS+G6O+QnwndAnH7u/Io5KOXCd01hMnxfHPlB+E5pX/PceQFgMPpseB+n2yA3Cgfuhe7NcP7lYZ7lYjhfhGVXAK4g7s7B41N895njfO/pYfYfHuPEZJ7Dg4NsscOssxOstWE2xGNc2D7NuniU1YzSYgUyViLtRcr5CbpzhzDmeD0tCm/SWW+LwxdIKff8adNt0HMBlPIwfiR8MLrOg8nj4UOx7tIwXbkU7lcuhvWbbb1w9EcwdRw2Xhbe+JmO8CV1/EnoWAcTQ2Ge2a4w9Ds9Aj3bw4fD4jBtui18YbmHmsrF8FheCmGfn4DxQZg4Cq3dcOyJMJTccwFk2mDwh0k4JLW19oRzPFw+8ghMD8Pai089H9MjYZ4d66A4FR67ZdWpU7o1PB/F/KnnZWwANuwMz2HvheH5zE/A4Ydh5CCsfxGk25MXvASF6fBBP/DVsPzrLoVjB6BrA6SS+U8MwdP/Dl0bofeCML8TT8HqbdB9fphPqRCmsRg2vxy6t4T6h5+B1tXhORg9FGqufFmlW8MPpKnh8BrGmXAyC4/h5bCcXg6vYWEKNu4KyxunwzyOPh7mkWkPz+dIP2zaHeYz8BC09UDnhvB85CfCF2bPNojScPyJ8B4qTIXnwUuAnQqCUgGe+Hp4Hje+NEwzMRiel1QmXC9OJ/efCl/imXbY8upQX5QK9RSnYfXWMP9yGQ59L7xvN788WY5pyI9B+9pwn8lj4X2b7QyhWpwO76lyKUw/dhhWbQrLUpgM7ymLk7Aow4mnYexQWJ2R7QzLUS6E56cSvtmO8NxOj4b5Hd0f3oeZ9lDD8SfC67buklPv+cpn0aLwXE4dD6/lqs3hPTNyMPwg7t4S3teV+3g5zGP8SPh8rLs4LEupEF6XynPUuSHMDw/LPX4kvOcmjob3P4RpysXkOZ88VVOUDstYrfJ+iuKwnHN9J1VUz+Pia+EX7zz99POwIgPQzN4IfASIgb9295tPN32jBOBsKqF48MQkg2PTTOZL7D88xg8Hxhgaz3F8Is/I1Kk3XmSQ8RwxZTqZJG1FDGghTzvT9EcbSadTXBL3M16KWG/DbMuO0JfOsSpdJONFnkptZTxX5PxSP6lMC+PFiJ7yUc5jCKI0E5k1tFmeztIwE/Eq4sIYa/PPYFEKi1LEVqZUdoa9nbbiKEMtmymmOthaeIJUaYp0YZx0cYypzq2kp49Rausj37qWqDBBnB+llGqjdexpSi3dREBUmsIK01gpDBF7lMKJIEphUYTlJ/B0K8XWPgotvWRyx/HO80gdfZSoMA6FKcodGyDOUMYoRi2kc8eJ4hRYhE0dxzs3UO7YgJ14isgccIizeNfGcHu6FTDKU6MwPUycH4XCFJbKnvqgt3RRau3FBh/F0q3Y5NHkVbEQXF3nwZFHk+AlfMmnWsIX7vafwr0Eh74fhr4njoYv7DgDGPkdV8NT/046Ast2hHkN7Q+hbTFYxHTvxUSZFjKH9sL4Ych0hoAcGwiP2b0Fz43i+QmiTHv4gVHMQ3tv+GIu5cOXopdDYGJhGndYsyPUe/iR8OVdKoTHXfvCMO9KYHasC6MMpTxseHH44hs/EnoPmY7ky/3J8AW8+nwYHQghkWkPX+wkvZRyKcxv08tg4MHwHKVboG1N+DIul8I8U62hPdUaVhcMHwzPSyVw2taE28cOJz3JOIRX13nhR4mXT9U2MRTqbl8TAjI/HgIhTocfExaHx+5YH57Tyg8zknorvZzuzSGIBh481YuK0+ELPk6fCrDp4TD/jnXh+Z04mrwGOejdASd+HOq2KHluTn4phMduXR1CcPxImEffC0NdJ+9jz71vtiss27EDp96zcSbcd/2loSdWCbRMe1jVMvJsOG/vC6E32h/uk247tfxRKjx3ravDc9G7IwT49EgSsnlo6Q7TlYvQuT4se6kY3mfn7YLBR8MPtDh5jvpeCBf97IK/P1dcAJpZDPwIeB3QDzwAvM3dH53rPo0cgPNRKJUZniwwMlVg0+pWfnh4jKNjOaYKJaYKJaaT01S+fPL6ZL5IWyZFsVzm2HieY+N5jk7kKJedlnTM6rYMU4US47kiq9vCsMeJyQKTuSKFsjM2XWC6UCYVGe3ZFOO5IqXyc99Dve0Z4igM6YxNF5kqlKpudaDWQ3XhMVIUKRLX5PFa03H4nkkebTJ/ahk7LPxqLhCT57nDOZEZq1rTdLemyRVKTBXLjOeK5ItletsztKTDUJS7Uyw7g2OhV96eieloSZErlskVynS3pcmkIqbyJQbHcsSRcWFfB50tqZPPwMlnw53Hj4wzXSyxYVUrremYdMqIzYiicH5iMh9+/PS0kY4jUnHEdL7E0fEc2XRMSzqiJRXTmolxd05MFkjHxnShTGsmPvl8lMrOeK7IdKHM+q4smVREZJaM0BpGOI+S5y4yo+zOoeFp+jqztGdjimWnXHZKDuWyUyyXKZWhXHlORqdZ1Zpm4+pWIjMGRqYYny6yrquFnvYME/kSE7kimTiipyPD2HSRiVyRbCpiPFdkdKpAb0eWNR0ZOlvSlE4+hlMsOWWHTCoim5xSsRFHEcVSmUKpTKHkjE4VeGJoHDPj/J42tvS2USw7E7kiuUKZvs4s+VIIFTMYGs1RdieTikjH4ZRJRcSRcWRkmjgyejuyRAZThRId2VTyXIfXsFx2nOQ3gofLuPPs8DTTxRJbe9vobc8m03jy2S+H1y0dk44jSmVnqlBidLpAZzZFV2uaobEcjw2M8rKtPaTjiGI5vL9yxTJj0wUOj06zsbuNrWvC+4LnvK+g5I67YxbeR6koeU9F4bVNRRGRwchUgaGxHEfHc3S1punIpig7PHN8kshg4+pW1nRk2bamnZdt7Vnw53MlBuArgfe6+xuS6+8BcPf/Ntd9mj0A66WcBF4UGe7OZL7E2HSRyXyRzpY0fZ2nNtQplso8OzyFe/giKJadsekiqcgYniwk84HYjDgKX5QTuRDAZfcwCgRkYjv55TFdKDORK2IW9sGaigwzY3SqQL5Uxh2m8iVWtaaZLpYolZ2uljSrWtMcHc8xPFUgsvABzRVDmGdTEZOFEvliGcNOhlvli7stE9PTnmFkqsCJiQLjucLJ2gxY1ZpmbVeWZ4en4TSfqVISHiNTBbKpiPZMirZsTHsmxcDIFPmin1wdFBls6W2nuy3N/sNj5AplsunwHJyYzFMqO5k4Yse6Dkanivzw8BhThVP7oLWq4D+vu4We9iyHR6aYLpTJl8IXftnDqS2TojOb4tDIFMVSCJpMHNHXlSVfLJ/8MTVdKFN2Z3VbhmK5TEs6Tn5khR8AZkZnS4pMHHF4dDoJFD/5xVx5ztxD0DihbcOqFgbHcuSLZaLkvXDylAR15cu1tz3DsfEcxybylMvOms4sq9syHDwxyfh0kY5seE6n8iVGpgq0ZVKsak2TK5bIpmK629Lhx99EjvHpYngPxRGpqvdSrlgmXyyRK5Yplp1S2UnHdjK8WtMxF67tAOCpYxM8Ozx18kdhJo4YGs+RSQKj7M7azhZSsZEvhhAN506hFMLSHY5N5Ch7+HE1mS9SnsdX85qODB3ZFAdPTD3vh6jZ7G/FTBw9J5zPW9XKs8PP3VlHZNCeSdHXlWVgeHrGj9hz19WSSj7bp65HVd8FP/2iDXzsl3Yt+HHmG4CpBT/S4tkIHKy63g+8ok61yGlE0akvVrPwoW/Pzv5WSsURW3rbl6o0kZqo9HLmUir7yVEPCD8Sqz8nZ/sYxVIIXuBUD7r68oxaCqXKj8JweyYOvddCyZkuligUy8SR0ZKOaUnH5IrhR2tkxuq2NCcmw4/CVHK/6t5euezJKNHza46iU734cjn8wCuVPJwnPfdS2VnVlmZNR4ZsKk560WFmYeTAmMgVOT6RJxUv7YZcyykAZ1vy5/1+MbM9wB6A888/v9Y1iYicNvyA54QfcNbhN/MxUnFE6iw2vk7HEd1tz996MpMKIyczZVMx2Y5TD9DTPveWl1FkrO1cvC1nK73oaqf7EV1Ly2lPMP3A5qrrm4BDMydy91vdfbe77+7r61uy4kREpLEspwB8ANhhZtvMLAO8Fbi7zjWJiEiDWjZDoO5eNLNfB75M+BvE7e7+gzqXJSIiDWrZBCCAu38R+GK96xARkca3nIZARURElowCUEREmpICUEREmpICUEREmpICUEREmpICUEREmtKy2Rn2uTCzIeDpRZjVGuDoGadaGbQsy0+jLAdoWZYrLctzbXH3M+4qbEUH4GIxs73z2XP4SqBlWX4aZTlAy7JcaVnOjYZARUSkKSkARUSkKSkAg1vrXcAi0rIsP42yHKBlWa60LOdA6wBFRKQpqQcoIiJNqakD0MzeaGb7zeyAmd1U73rOlpk9ZWYPm9k+M9ubtPWY2T1m9nhyvrredc7GzG43s0Eze6SqbdbaLbgleZ0eMrNd9av8+eZYlvea2bPJa7PPzK6puu09ybLsN7M31Kfq2ZnZZjP7upk9ZmY/MLN3J+0r6rU5zXKsuNfFzFrM7H4zezBZlj9J2reZ2X3Ja/L3yXFUMbNscv1AcvvWetZf7TTL8kkz+3HV67Izaa/t+8vdm/JEOObgE8B2IAM8CFxc77rOchmeAtbMaPu/gJuSyzcBH6x3nXPU/pPALuCRM9UOXAP8K2DA5cB99a5/HsvyXuB3Z5n24uS9lgW2Je/BuN7LUFXfBmBXcrkT+FFS84p6bU6zHCvudUme247kchq4L3muPwO8NWn/S+DXksv/BfjL5PJbgb+v9zLMY1k+CVw3y/Q1fX81cw/w5cABd3/S3fPAXcC1da5pMVwL3JFcvgN4Ux1rmZO7/xtwfEbzXLVfC9zpwXeAbjPbsDSVntkcyzKXa4G73D3n7j8GDhDei8uCuw+4+/eSy2PAY8BGVthrc5rlmMuyfV2S53Y8uZpOTg68Fvhs0j7zNam8Vp8FrjQzW6JyT+s0yzKXmr6/mjkANwIHq673c/oPyHLkwFfM7LtmtidpW+fuAxC+BIC1davu7M1V+0p9rX49Gba5vWooesUsSzJ09lLCr/QV+9rMWA5Yga+LmcVmtg8YBO4h9FCH3b2YTFJd78llSW4fAXqXtuK5zVwWd6+8Ln+avC4fMrNs0lbT16WZA3C2X0QrbZPYK9x9F3A18C4z+8l6F1QjK/G1+jhwAbATGAD+LGlfEctiZh3A54DfdPfR0006S9uyWZ5ZlmNFvi7uXnL3ncAmQs/0otkmS85X1LKY2aXAe4AXAi8DeoDfSyav6bI0cwD2A5urrm8CDtWplnPi7oeS80Hg84QPxpHKEEFyPli/Cs/aXLWvuNfK3Y8kH/Qy8FecGk5b9stiZmlCaPytu/9j0rziXpvZlmMlvy4A7j4MfIOwPqzbzFLJTdX1nlyW5PZVzH+IfslULcsbkyFrd/cc8AmW6HVp5gB8ANiRbEmVIawsvrvONc2bmbWbWWflMvB64BHCMlyfTHY98IX6VHhO5qr9buAdyRZhlwMjleG45WrGeoqfJ7w2EJblrcmWetuAHcD9S13fXJJ1RbcBj7n7n1fdtKJem7mWYyW+LmbWZ2bdyeVW4CrCOs2vA9clk818TSqv1XXA1zzZoqTe5liWH1b9uDLCuszq16V2769ab/WznE+ELYx+RBhP/4N613OWtW8nbLX2IPCDSv2Esf57gceT85561zpH/Z8mDEEVCL/ybpyrdsIwyMeS1+lhYHe965/HsnwqqfWh5EO8oWr6P0iWZT9wdb3rn7EsryYMMT0E7EtO16y01+Y0y7HiXhfgxcD3k5ofAf4oad9OCOkDwD8A2aS9Jbl+ILl9e72XYR7L8rXkdXkE+BtObSla0/eX9gQjIiJNqZmHQEVEpIkpAEVEpCkpAEVEpCkpAEVEpCkpAEVEpCkpAEWWETMrVe0Rf58t4lFKzGyrVR2xQqTZpc48iYgsoSkPu4kSkRpTD1BkBbBw7McPJsdSu9/MLkzat5jZvclOhO81s/OT9nVm9vnkuGsPmtmrklnFZvZXybHYvpLsjUOkKSkARZaX1hlDoG+pum3U3V8OfBT4cNL2UcLhYl4M/C1wS9J+C/A/3P0lhGMV/iBp3wF8zN0vAYaBX6jx8ogsW9oTjMgyYmbj7t4xS/tTwGvd/clkJ8+H3b3XzI4SdudVSNoH3H2NmQ0BmzzsXLgyj62Ew8/sSK7/HpB29w/UfslElh/1AEVWDp/j8lzTzCZXdbmEtgOQJqYAFFk53lJ1/h/J5W8TjmQC8EvAt5LL9wK/BicPQNq1VEWKrBT69SeyvLQmR8uu+JK7V/4KkTWz+wg/XN+WtP0GcLuZ/e/AEHBD0v5u4FYzu5HQ0/s1whErRCShdYAiK0CyDnC3ux+tdy0ijUJDoCIi0pTUAxQRkaakHqCIiDQlBaCIiDQlBaCIiDQlBaCIiDQlBaCIiDQlBaCIiDSl/x/UTi3jOb4+EgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1908bcd208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = pyplot.figure(figsize = (7,5))\n",
    "axis = figure.add_subplot(111)\n",
    "axis.plot(history.history['loss'])\n",
    "axis.plot(history.history['val_loss'])\n",
    "pyplot.title('Model Loss')\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.xlabel('Epoch')\n",
    "axis.legend(['Train', 'Test'], loc='upper left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss graph looks pretty good.  We have a nice smooth curve the slopes downwards. and then it flattens out as the model converges.  We don't for example have a large gap between the Test and Train results, or have the Test line flatten out while the Train line continues to decrease.  (Both of these would indicate an overfitting issue.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T06:05:49.628303Z",
     "start_time": "2018-08-30T06:05:04.355466Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(xFeatures, yTrain)\n",
    "preds = model.predict(xValFeatures)\n",
    "mse = mean_squared_error(yVal, preds)\n",
    "rmse = sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T06:05:49.798297Z",
     "start_time": "2018-08-30T06:05:49.631259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  14.257438902440343\n",
      "RMSE =  3.7759023957777753\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE = \", mse)\n",
    "print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T06:05:49.981246Z",
     "start_time": "2018-08-30T06:05:49.804238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 36,\n",
       " 'build_fn': <function __main__.wrapper.<locals>.buildModel>,\n",
       " 'epochs': 350,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comments\n",
    "\n",
    "I as noted above the Gradient Boosting ensemble outperforms the neural network implementation explored in this write-up.  For a real project at this point I'd likely stop working on improving the neural network and explore increasing performance with Gradient Boosting.\n",
    "\n",
    "For reference:\n",
    "\n",
    "|Model     |Write-up              |Prediction MSE|\n",
    "|----------|------------------------|--------------|\n",
    "|GB        | Model-02.Keras         | 12.24        |\n",
    "|Neural Net| Model-02.Keras.1.ipynb | 11.94        |\n",
    "|Neural Net| Model-02.Keras.2.ipynb | 14.26        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
