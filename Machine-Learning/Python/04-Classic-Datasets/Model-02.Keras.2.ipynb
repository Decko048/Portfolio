{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Boston-Housing-Prices-Regression-Modeling-with-Keras\" data-toc-modified-id=\"Boston-Housing-Prices-Regression-Modeling-with-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Boston Housing Prices Regression Modeling with Keras</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Load-libraries-and-data\" data-toc-modified-id=\"Load-libraries-and-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load libraries and data</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Inspect-and-visualize-the-data\" data-toc-modified-id=\"Inspect-and-visualize-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inspect and visualize the data</a></span></li><li><span><a href=\"#Model-the-data\" data-toc-modified-id=\"Model-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-validation-data-set\" data-toc-modified-id=\"Create-validation-data-set-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Create validation data set</a></span></li><li><span><a href=\"#Build-models\" data-toc-modified-id=\"Build-models-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Build models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-model-function\" data-toc-modified-id=\"Build-model-function-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Build model function</a></span></li><li><span><a href=\"#Initial-pass\" data-toc-modified-id=\"Initial-pass-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Initial pass</a></span></li><li><span><a href=\"#Grid-search-hyperparameter-tuning\" data-toc-modified-id=\"Grid-search-hyperparameter-tuning-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Grid search hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Alter-tuneModel-for-RandomizedSearchCV-support\" data-toc-modified-id=\"Alter-tuneModel-for-RandomizedSearchCV-support-6.2.3.1\"><span class=\"toc-item-num\">6.2.3.1&nbsp;&nbsp;</span>Alter tuneModel for RandomizedSearchCV support</a></span></li><li><span><a href=\"#RandomizedSearchCV-hyperparameter-search\" data-toc-modified-id=\"RandomizedSearchCV-hyperparameter-search-6.2.3.2\"><span class=\"toc-item-num\">6.2.3.2&nbsp;&nbsp;</span>RandomizedSearchCV hyperparameter search</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-6.2.3.3\"><span class=\"toc-item-num\">6.2.3.3&nbsp;&nbsp;</span>Comments</a></span></li><li><span><a href=\"#Tune-network-topology\" data-toc-modified-id=\"Tune-network-topology-6.2.3.4\"><span class=\"toc-item-num\">6.2.3.4&nbsp;&nbsp;</span>Tune network topology</a></span></li><li><span><a href=\"#Graph-final-model-performance\" data-toc-modified-id=\"Graph-final-model-performance-6.2.3.5\"><span class=\"toc-item-num\">6.2.3.5&nbsp;&nbsp;</span>Graph final model performance</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-6.2.3.6\"><span class=\"toc-item-num\">6.2.3.6&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Predictions\" data-toc-modified-id=\"Predictions-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Predictions</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Boston Housing Prices Regression Modeling with Keras</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 40%; height: 40%; \" src=\"images/boston.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source:  [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to build upon the [first](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) and [second](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) write-ups involving the Boston housing prices dataset.  \n",
    "\n",
    "Goals include:\n",
    "* Utilize RandomizedSearchCV for hyperparameter tuning\n",
    "* Feature selection with SelectKBest\n",
    "* Examine algorithm performance visually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:14:35.543268Z",
     "start_time": "2018-08-29T15:14:33.023480Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:14:54.695382Z",
     "start_time": "2018-08-29T15:14:35.543268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "#import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:14:55.194780Z",
     "start_time": "2018-08-29T15:14:54.695382Z"
    }
   },
   "outputs": [],
   "source": [
    "dataFile = os.path.join(\".\", \"datasets\", \"housing.csv\")\n",
    "data = read_csv(dataFile, header = 0, delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:14:55.613978Z",
     "start_time": "2018-08-29T15:14:55.194780Z"
    }
   },
   "outputs": [],
   "source": [
    "def corrTableColors(value):\n",
    "    color = 'black'\n",
    "\n",
    "    if value == 1:\n",
    "        color = 'white'\n",
    "    elif value < -0.7:\n",
    "        color = 'red'\n",
    "    elif value > 0.7:\n",
    "        color = 'green'\n",
    "\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:14:56.093376Z",
     "start_time": "2018-08-29T15:14:55.614978Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeRange(start, stop, step = 1, multi = 1, dec = 1):\n",
    "    vals = []\n",
    "    for i in range(start, stop, step):\n",
    "        vals.append(np.round(multi * i, decimals = dec))\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect and visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please the [first Boston housing data's write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb#Inspect-and-visualize-the-data) details on this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:40:32.582998Z",
     "start_time": "2018-08-29T22:40:31.884998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (506, 13)\n",
      "y.shape =  (506,)\n",
      "--------\n",
      "xTrain.shape =  (404, 13)\n",
      "yTrain.shape =  (404,)\n",
      "xVal.shape =  (102, 13)\n",
      "yVal.shape =  (102,)\n"
     ]
    }
   ],
   "source": [
    "# Seperate X and Y values\n",
    "x = data.values[:, 0:len(data.columns) - 1]\n",
    "y = data.values[:, len(data.columns) - 1]\n",
    "\n",
    "# Uncomment if you want a smaller subset that runs faster for testing\n",
    "# x = data.values[1:50, 0:len(data.columns) - 1]\n",
    "# y = data.values[1:50, len(data.columns) - 1]\n",
    "\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"y.shape = \", y.shape)\n",
    "\n",
    "# Split out validation set -- 80/20 split\n",
    "seed = 10\n",
    "valSize = 0.2\n",
    "\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, y, test_size = valSize, random_state = seed)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"xTrain.shape = \", xTrain.shape)\n",
    "print(\"yTrain.shape = \", yTrain.shape)\n",
    "print(\"xVal.shape = \", xVal.shape)\n",
    "print(\"yVal.shape = \", yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on the `kernal_initializer`:  https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:40:34.079998Z",
     "start_time": "2018-08-29T22:40:33.630998Z"
    }
   },
   "outputs": [],
   "source": [
    "def buildModel(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None, debug = False):\n",
    "    \n",
    "    opt = None\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "    # bias_initializer -> 'zeros' (default per the docs) \n",
    "    model.add(Dense(20, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    if optimizer.lower() == 'adam':\n",
    "        opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "    else:\n",
    "        # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "        # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "        opt = eval(optimizer)()\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:40:35.812998Z",
     "start_time": "2018-08-29T22:40:35.350998Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrapper(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    \n",
    "    def buildModel():\n",
    "    \n",
    "        opt = None\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "        # bias_initializer -> 'zeros' (default per the docs) \n",
    "        model.add(Dense(20, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "        if optimizer.lower() == 'adam':\n",
    "            opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "        else:\n",
    "            # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "            # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "            opt = eval(optimizer)()\n",
    "\n",
    "        model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "\n",
    "        return model   \n",
    "    \n",
    "    return buildModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first pass an educated guess is taken for what might work well on the dataset.  This provides an initial baseline, and then we can tune the hyperparameters to hopefully improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -17.67 (7.86)\n"
     ]
    }
   ],
   "source": [
    "# Define vars and init\n",
    "folds = 10\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn = buildModel, epochs = 200, batch_size = 5, verbose = 0)\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "results = cross_val_score(model, xTrain, yTrain, cv = kFold)\n",
    "\n",
    "print(\"MSE: %.2f (%.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-29T22:40:37.911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define vars and init\n",
    "folds = 10\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn = wrapper(), epochs = 200, batch_size = 5, verbose = 0)\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "results = cross_val_score(model, xTrain, yTrain, cv = kFold)\n",
    "\n",
    "print(\"MSE: %.2f (%.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better then what the [previous](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) write-up's models accomplished with no tuning as of yet:\n",
    "\n",
    "<pre>\n",
    "         Model    MSE  StdDev\n",
    "3    scaledKNN -20.35   11.87\n",
    "0     scaledLR -21.26    7.11\n",
    "4   scaledCART -22.66    9.31\n",
    "1  scaledLASSO -26.94   10.38\n",
    "5    scaledSVR -28.52   13.98\n",
    "2     scaledEN -28.60   11.65\n",
    "</pre>\n",
    "\n",
    "It does not; however, compare to the results achieved via the ensemble methods:\n",
    "\n",
    "<pre>\n",
    "       Model     MSE  StdDev\n",
    "1  scaledGBM -9.700   5.342 \n",
    "3  scaledET  -10.339  5.399 \n",
    "2  scaledRF  -13.695  7.276 \n",
    "0  scaledAB  -14.176  8.917\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) we utilized [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).  We'd like to now examine [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "We observed in the last write-up that the `KerasRegressor` estimator utilizing the `Adam` optimizer give us good results.  We'll continue working with this combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alter tuneModel for RandomizedSearchCV support \n",
    "\n",
    "We need to alter the `tuneModel` function to support `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T21:00:50.821028Z",
     "start_time": "2018-08-28T21:00:50.555364Z"
    }
   },
   "outputs": [],
   "source": [
    "def tuneModel(modelName, modelObj, params, iterations = 20, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "    \n",
    "    np.random.seed(featureSeed)\n",
    "    \n",
    "    # Use MSE since this is a regression problem\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'MSE', 'StdDev', 'Best Params'])\n",
    "\n",
    "    # Create feature union (adding SelectKBest)\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    features.append(('SelectKBest', SelectKBest()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = RandomizedSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_distributions = params,\n",
    "        n_iter = iterations,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed),\n",
    "        random_state = featureSeed\n",
    "    ).fit(xTrain, yTrain)\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.cv_results_['std_test_score'][featureResults.best_index_],\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's dig in and see what sort of parameter combinations `RandomizedSearchCV` might be able to find for us that provide good algorithm performance.  If we would have utilized `GridSearchCV` as in the [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.1.ipynb) we'd probably be here all week waiting for the combinations below to finish.  ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.574462Z",
     "start_time": "2018-08-28T17:59:33.228185Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-12.923</td>\n",
       "      <td>10.544</td>\n",
       "      <td>{'housingModel__optimizer': 'Adam', 'housingModel__lr': 0.005, 'housingModel__epsilon': 1.5, 'housingModel__epochs': 350, 'housingModel__batch_size': 36, 'FeatureUnion__SelectKBest__k': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model     MSE  StdDev  \\\n",
       "0  housingModel -12.923  10.544   \n",
       "\n",
       "                                                                                                                                                                                    Best Params  \n",
       "0  {'housingModel__optimizer': 'Adam', 'housingModel__lr': 0.005, 'housingModel__epsilon': 1.5, 'housingModel__epochs': 350, 'housingModel__batch_size': 36, 'FeatureUnion__SelectKBest__k': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__epochs' : makeRange(200, 600, 50),\n",
    "    'housingModel__batch_size' : makeRange(4, 68, 4),\n",
    "    'FeatureUnion__SelectKBest__k': makeRange(1, xTrain.shape[1]),\n",
    "    'housingModel__lr' : makeRange(1, 9, 1, .001, 3),\n",
    "    'housingModel__epsilon' : makeRange(2, 8, 1, .5, 1),\n",
    "}\n",
    "\n",
    "set1 = tuneModel(modelName, modelObj, params, 10, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.777691Z",
     "start_time": "2018-08-28T19:20:26.574462Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_FeatureUnion__SelectKBest__k</th>\n",
       "      <th>param_housingModel__batch_size</th>\n",
       "      <th>param_housingModel__epochs</th>\n",
       "      <th>param_housingModel__epsilon</th>\n",
       "      <th>param_housingModel__lr</th>\n",
       "      <th>param_housingModel__optimizer</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.162</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-12.923</td>\n",
       "      <td>-5.768</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>350</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.856</td>\n",
       "      <td>-5.547</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-6.600</td>\n",
       "      <td>-25.413</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.054</td>\n",
       "      <td>10.544</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.126</td>\n",
       "      <td>1.164</td>\n",
       "      <td>-13.062</td>\n",
       "      <td>-7.470</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>400</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.158</td>\n",
       "      <td>-6.962</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>-7.158</td>\n",
       "      <td>-29.250</td>\n",
       "      <td>-5.741</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.050</td>\n",
       "      <td>9.324</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.680</td>\n",
       "      <td>1.363</td>\n",
       "      <td>-14.276</td>\n",
       "      <td>-7.638</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>550</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.706</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-6.938</td>\n",
       "      <td>-7.380</td>\n",
       "      <td>-31.150</td>\n",
       "      <td>-7.372</td>\n",
       "      <td>3.276</td>\n",
       "      <td>0.053</td>\n",
       "      <td>8.743</td>\n",
       "      <td>1.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>245.504</td>\n",
       "      <td>2.589</td>\n",
       "      <td>-14.861</td>\n",
       "      <td>-9.099</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.559</td>\n",
       "      <td>-9.178</td>\n",
       "      <td>-12.357</td>\n",
       "      <td>-7.707</td>\n",
       "      <td>-21.949</td>\n",
       "      <td>-6.987</td>\n",
       "      <td>4.468</td>\n",
       "      <td>0.074</td>\n",
       "      <td>5.186</td>\n",
       "      <td>2.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.193</td>\n",
       "      <td>2.366</td>\n",
       "      <td>-15.473</td>\n",
       "      <td>-8.751</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>250</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.321</td>\n",
       "      <td>-8.241</td>\n",
       "      <td>-8.194</td>\n",
       "      <td>-8.593</td>\n",
       "      <td>-30.608</td>\n",
       "      <td>-6.901</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.072</td>\n",
       "      <td>11.361</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.455</td>\n",
       "      <td>1.752</td>\n",
       "      <td>-15.506</td>\n",
       "      <td>-11.334</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.041</td>\n",
       "      <td>-11.962</td>\n",
       "      <td>-9.391</td>\n",
       "      <td>-10.604</td>\n",
       "      <td>-28.895</td>\n",
       "      <td>-9.480</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.065</td>\n",
       "      <td>7.814</td>\n",
       "      <td>2.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.434</td>\n",
       "      <td>1.562</td>\n",
       "      <td>-15.764</td>\n",
       "      <td>-12.118</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.848</td>\n",
       "      <td>-10.908</td>\n",
       "      <td>-8.697</td>\n",
       "      <td>-10.701</td>\n",
       "      <td>-28.050</td>\n",
       "      <td>-10.452</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.847</td>\n",
       "      <td>2.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.618</td>\n",
       "      <td>0.830</td>\n",
       "      <td>-16.429</td>\n",
       "      <td>-10.603</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.575</td>\n",
       "      <td>-12.045</td>\n",
       "      <td>-9.254</td>\n",
       "      <td>-9.697</td>\n",
       "      <td>-36.836</td>\n",
       "      <td>-10.174</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.045</td>\n",
       "      <td>10.529</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.628</td>\n",
       "      <td>2.328</td>\n",
       "      <td>-17.656</td>\n",
       "      <td>-13.179</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.712</td>\n",
       "      <td>-10.148</td>\n",
       "      <td>-9.390</td>\n",
       "      <td>-14.949</td>\n",
       "      <td>-43.857</td>\n",
       "      <td>-10.971</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.316</td>\n",
       "      <td>11.727</td>\n",
       "      <td>1.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.488</td>\n",
       "      <td>2.080</td>\n",
       "      <td>-18.634</td>\n",
       "      <td>-11.783</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>550</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.326</td>\n",
       "      <td>-8.258</td>\n",
       "      <td>-11.253</td>\n",
       "      <td>-11.688</td>\n",
       "      <td>-42.961</td>\n",
       "      <td>-12.149</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.365</td>\n",
       "      <td>11.097</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1  12.162         0.975           -12.923          -5.768              \n",
       "2  13.126         1.164           -13.062          -7.470              \n",
       "3  81.680         1.363           -14.276          -7.638              \n",
       "9  245.504        2.589           -14.861          -9.099              \n",
       "8  21.193         2.366           -15.473          -8.751              \n",
       "5  15.455         1.752           -15.506          -11.334             \n",
       "4  15.434         1.562           -15.764          -12.118             \n",
       "0  22.618         0.830           -16.429          -10.603             \n",
       "7  16.628         2.328           -17.656          -13.179             \n",
       "6  20.488         2.080           -18.634          -11.783             \n",
       "\n",
       "  param_FeatureUnion__SelectKBest__k param_housingModel__batch_size  \\\n",
       "1  2                                  36                              \n",
       "2  2                                  44                              \n",
       "3  7                                  8                               \n",
       "9  10                                 4                               \n",
       "8  2                                  36                              \n",
       "5  3                                  44                              \n",
       "4  3                                  60                              \n",
       "0  9                                  16                              \n",
       "7  2                                  36                              \n",
       "6  7                                  64                              \n",
       "\n",
       "  param_housingModel__epochs param_housingModel__epsilon  \\\n",
       "1  350                        1.5                          \n",
       "2  400                        2.5                          \n",
       "3  550                        1.5                          \n",
       "9  450                        2                            \n",
       "8  250                        2.5                          \n",
       "5  300                        2                            \n",
       "4  450                        1                            \n",
       "0  400                        1                            \n",
       "7  200                        1.5                          \n",
       "6  550                        3.5                          \n",
       "\n",
       "  param_housingModel__lr param_housingModel__optimizer       ...         \\\n",
       "1  0.005                  Adam                               ...          \n",
       "2  0.002                  Adam                               ...          \n",
       "3  0.006                  Adam                               ...          \n",
       "9  0.001                  Adam                               ...          \n",
       "8  0.002                  Adam                               ...          \n",
       "5  0.002                  Adam                               ...          \n",
       "4  0.001                  Adam                               ...          \n",
       "0  0.001                  Adam                               ...          \n",
       "7  0.001                  Adam                               ...          \n",
       "6  0.003                  Adam                               ...          \n",
       "\n",
       "  split7_test_score  split7_train_score  split8_test_score  \\\n",
       "1 -39.856           -5.547              -9.200               \n",
       "2 -33.158           -6.962              -6.769               \n",
       "3 -30.706           -4.547              -6.938               \n",
       "9 -24.559           -9.178              -12.357              \n",
       "8 -43.321           -8.241              -8.194               \n",
       "5 -30.041           -11.962             -9.391               \n",
       "4 -23.848           -10.908             -8.697               \n",
       "0 -37.575           -12.045             -9.254               \n",
       "7 -31.712           -10.148             -9.390               \n",
       "6 -36.326           -8.258              -11.253              \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "1 -6.600              -25.413            -4.548               0.551          \n",
       "2 -7.158              -29.250            -5.741               0.490          \n",
       "3 -7.380              -31.150            -7.372               3.276          \n",
       "9 -7.707              -21.949            -6.987               4.468          \n",
       "8 -8.593              -30.608            -6.901               0.540          \n",
       "5 -10.604             -28.895            -9.480               0.539          \n",
       "4 -10.701             -28.050            -10.452              0.755          \n",
       "0 -9.697              -36.836            -10.174              0.619          \n",
       "7 -14.949             -43.857            -10.971              0.592          \n",
       "6 -11.688             -42.961            -12.149              1.454          \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "1  0.054           10.544          0.755            \n",
       "2  0.050           9.324           0.706            \n",
       "3  0.053           8.743           1.411            \n",
       "9  0.074           5.186           2.525            \n",
       "8  0.072           11.361          0.837            \n",
       "5  0.065           7.814           2.542            \n",
       "4  0.086           6.847           2.520            \n",
       "0  0.045           10.529          0.718            \n",
       "7  0.316           11.727          1.596            \n",
       "6  0.365           11.097          1.657            \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_option('precision', 3)\n",
    "DataFrame(set1.cv_results_).sort_values(by=['mean_test_score', 'std_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:27.136971Z",
     "start_time": "2018-08-28T19:20:26.965128Z"
    }
   },
   "source": [
    "#### Comments\n",
    "\n",
    "From the results above it's pretty clear we're likely at a point of diminishing returns for further tuning with this set of hyperparamter options. (I also tested a number of additional iterations outside of this notebook which further confirmed this conclusion.)\n",
    "\n",
    "Likely the next logical step would be to experiment with the topology of the neural network itself such as adding additional layers and/or neurons, or we could simply disregard neural networks as an options for this problem and utilize one of the effective algorithms covered in previous write-ups. So let's do a few rounds of topology modification testing next, make a final model choice, examine some predictions, and then wrap up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune network topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some NN funcs for wide, deep, deep/wide and run them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T22:51:22.102035Z",
     "start_time": "2018-08-28T22:51:21.867721Z"
    }
   },
   "outputs": [],
   "source": [
    "def tuneFinalModel(modelName, modelObj, params, iterations = 20, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "    \n",
    "    np.random.seed(featureSeed)\n",
    "    \n",
    "    # Use MSE since this is a regression problem\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'MSE', 'StdDev', 'Best Params'])\n",
    "\n",
    "    # Create feature union (adding SelectKBest)\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    features.append(('SelectKBest', SelectKBest()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = GridSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_grid = params,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed),\n",
    "    ).fit(xTrain, yTrain)\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.cv_results_['std_test_score'][featureResults.best_index_],\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T21:12:59.013310Z",
     "start_time": "2018-08-28T21:06:37.978926Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-13.386</td>\n",
       "      <td>10.404</td>\n",
       "      <td>{'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model     MSE  StdDev  \\\n",
       "0  housingModel -13.386  10.404   \n",
       "\n",
       "                                                                                                                                                                                    Best Params  \n",
       "0  {'FeatureUnion__SelectKBest__k': 2, 'housingModel__batch_size': 36, 'housingModel__epochs': 350, 'housingModel__epsilon': 1.5, 'housingModel__lr': 0.005, 'housingModel__optimizer': 'Adam'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalModelName = \"housingModel\"\n",
    "finalModelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "finalParams = {\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__epochs' : [350],\n",
    "    'housingModel__batch_size' : [36],\n",
    "    'FeatureUnion__SelectKBest__k': [2],\n",
    "    'housingModel__lr' : [0.005],\n",
    "    'housingModel__epsilon' : [1.5],\n",
    "}\n",
    "\n",
    "final = tuneFinalModel(finalModelName, finalModelObj, finalParams, 2, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:20:26.965128Z",
     "start_time": "2018-08-28T19:20:26.777691Z"
    }
   },
   "source": [
    "#### Graph final model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T20:01:47.820998Z",
     "start_time": "2018-08-29T19:52:55.126998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.964120641914151\n",
      "Pipeline(memory=None,\n",
      "     steps=[('features', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('select', SelectKBest(k=6, score_func=<function f_classif at 0x00000000120A90D0>))],\n",
      "       transformer_weights=None)), ('finalModel', <keras.wrappers.scikit_learn.KerasRegressor object at 0x00000000F305FC88>)])\n"
     ]
    }
   ],
   "source": [
    "# Concatenating multiple feature extraction methods\n",
    "# http://scikit-learn.org/stable/auto_examples/plot_feature_stacker.html\n",
    "\n",
    "# Init vars and params\n",
    "folds = 10\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "modelName = 'finalModel'\n",
    "\n",
    "# Use MSE since this is a regression problem\n",
    "score = 'neg_mean_squared_error'\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "df = DataFrame(columns = ['Model', 'MSE', 'StdDev'])\n",
    "\n",
    "# Build the model\n",
    "model = KerasRegressor(\n",
    "    build_fn = wrapper(\n",
    "        optimizer = 'Adam', \n",
    "        lr = 0.005, \n",
    "        epsilon = 1.5\n",
    "    ), \n",
    "    epochs = 350,\n",
    "    batch_size = 36,\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Create feature union\n",
    "combined = FeatureUnion([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"select\", SelectKBest())\n",
    "])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([(\"features\", combined), (modelName, model)])\n",
    "\n",
    "# Define param grid to search over\n",
    "param_grid = dict(\n",
    "    features__select__k = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    ")\n",
    "\n",
    "# Create cross validation object\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid = param_grid, \n",
    "    scoring = score,\n",
    "    cv = kFold,\n",
    "    verbose = 1)\n",
    "\n",
    "# Train the model and search for optimal hyperparams\n",
    "grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "# Output\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T20:01:48.526998Z",
     "start_time": "2018-08-29T20:01:47.825998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_test_score  std_test_score                      params\n",
      "1       -13.964121       16.279770  {'features__select__k': 6}\n",
      "2       -15.630663       15.829647  {'features__select__k': 7}\n",
      "0       -17.076485       22.337540  {'features__select__k': 5}\n"
     ]
    }
   ],
   "source": [
    "_df = DataFrame(grid_search.cv_results_)\n",
    "print(_df.loc[:, ['mean_test_score', 'std_test_score', 'params']].sort_values(by = ['mean_test_score', 'std_test_score'], ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:14:19.602998Z",
     "start_time": "2018-08-29T22:14:19.125998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build model w/out pipeline or CV, and get the history and then make predictions\n",
    "# https://stackoverflow.com/questions/44132652/keras-how-to-perform-a-prediction-using-kerasregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:14:41.173998Z",
     "start_time": "2018-08-29T22:14:19.855998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature union\n",
    "combined = FeatureUnion([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"select\", SelectKBest(k = 6))\n",
    "])\n",
    "\n",
    "xFeatures    = combined.fit(xTrain, yTrain).transform(xTrain)\n",
    "xValFeatures = combined.fit(xTrain, yTrain).transform(xVal)\n",
    "\n",
    "history = model.fit(xFeatures, yTrain, validation_data=(xValFeatures, yVal))\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:14:41.761998Z",
     "start_time": "2018-08-29T22:14:41.175998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeclNW9x/HPb/r2ZQt16U2qgKAo1qjYW6yxJtdrT78xanpyU8xNookxFowkWGIJBjWWWFDsIEUQkLYgZWnb++7Uc/84z1ZmYcEdZmF/79drX/PMU2Z++7DMd845TxFjDEoppVR7rmQXoJRSqnvSgFBKKRWXBoRSSqm4NCCUUkrFpQGhlFIqLg0IpZRScWlAKHUAROTvIvLLTq67WURO+6Kvo9TBpgGhlFIqLg0IpZRScWlAqMOW07Vzu4h8KiJ1IvKoiPQRkVdFpEZE3hSRXq3WP19EVotIpYgsEJExrZZNFpFlznbPAIF273WuiCx3tv1QRCYeYM03iEihiJSLyIsi0t+ZLyJyr4gUi0iV8zuNd5adLSKfObVtF5HvHdAOU6odDQh1uLsYOB0YBZwHvAr8AMjD/v1/E0BERgFPAd8G8oFXgH+LiE9EfMDzwONADvBP53Vxtp0CzAZuAnKBh4EXRcS/P4WKyJeA3wCXAf2ALcDTzuKZwInO75ENXA6UOcseBW4yxmQA44G39ud9leqIBoQ63P3ZGLPbGLMdeA9YZIz5xBgTBOYBk531LgdeNsa8YYwJA78HUoDjgOmAF/ijMSZsjJkLLG71HjcADxtjFhljosaYOUDQ2W5/XAXMNsYsc+q7CzhWRIYAYSADOAIQY8waY8xOZ7swMFZEMo0xFcaYZfv5vkrFpQGhDne7W003xHme7kz3x35jB8AYEwO2AQOcZdtN2ytbbmk1PRj4H6d7qVJEKoGBznb7o30NtdhWwgBjzFvA/cBfgN0iMktEMp1VLwbOBraIyDsicux+vq9ScWlAKGXtwH7QA7bPH/shvx3YCQxw5jUZ1Gp6G/ArY0x2q59UY8xTX7CGNGyX1XYAY8x9xpijgHHYrqbbnfmLjTEXAL2xXWHP7uf7KhWXBoRS1rPAOSJyqoh4gf/BdhN9CHwERIBviohHRL4MHN1q20eAm0XkGGcwOU1EzhGRjP2s4R/A10RkkjN+8Wtsl9hmEZnmvL4XqAMagagzRnKViGQ5XWPVQPQL7AelmmlAKAUYY9YBVwN/BkqxA9rnGWNCxpgQ8GXgq0AFdrziX622XYIdh7jfWV7orLu/NcwHfgw8h221DAeucBZnYoOoAtsNVYYdJwG4BtgsItXAzc7vodQXJnrDIKWUUvFoC0IppVRcGhBKKaXi0oBQSikVlwaEUkqpuDzJLuCLyMvLM0OGDEl2GUopdUhZunRpqTEmf1/rHdIBMWTIEJYsWZLsMpRS6pAiIlv2vZZ2MSmllOqABoRSSqm4NCCUUkrFdUiPQcQTDocpKiqisbEx2aUkVCAQoKCgAK/Xm+xSlFKHqcMuIIqKisjIyGDIkCG0vfjm4cMYQ1lZGUVFRQwdOjTZ5SilDlMJ7WJybvm40rkV4xJnXo6IvCEiG5zHXs58EZH7nNstfurcpWu/NTY2kpube9iGA4CIkJube9i3kpRSyXUwxiBOMcZMMsZMdZ7fCcw3xowE5jvPAc4CRjo/NwIPHugbHs7h0KQn/I5KqeRKxiD1BcAcZ3oOcGGr+Y8ZayGQLSL9ElJBsBaqd4BeyVYppTqU6IAwwOsislREbnTm9Wm6l67z2NuZPwB7Z64mRc68NkTkRhFZIiJLSkpKDqyqcAPU7oZY5MC234vKykoeeOCB/d7u7LPPprKyssvrUUqpA5XogJhhjJmC7T66TURO3Mu68fpM9viKb4yZZYyZaoyZmp+/zzPF4/MG7GO44cC234uOAiIa3ftNvl555RWys7O7vB6llDpQCQ0IY8wO57EYmIe9TePupq4j57HYWb0Iew/gJgXYe/R2PY8TEJGuH+S988472bhxI5MmTWLatGmccsopXHnllUyYMAGACy+8kKOOOopx48Yxa9as5u2GDBlCaWkpmzdvZsyYMdxwww2MGzeOmTNn0tDQ9UGmlFL7krDDXJ0brruMMTXO9EzgF8CLwHXA3c7jC84mLwJfF5GngWOAqqauqAP183+v5rMd1fEXhurAVQmejfv1mmP7Z/LT88Z1uPzuu+9m1apVLF++nAULFnDOOeewatWq5sNRZ8+eTU5ODg0NDUybNo2LL76Y3NzcNq+xYcMGnnrqKR555BEuu+wynnvuOa6+Wu8iqZQ6uBJ5HkQfYJ5ztI0H+Icx5j8ishh4VkSuB7YClzrrvwKcjb2fbz3wtQTWBuICE0voWwAcffTRbc5VuO+++5g3bx4A27ZtY8OGDXsExNChQ5k0aRIARx11FJs3b054nUop1V7CAsIYswk4Ms78MuDUOPMNcFtX1rC3b/pUFUF9GfSdCAk8ZDQtLa15esGCBbz55pt89NFHpKamcvLJJ8c9l8Hv9zdPu91u7WJSSiVFz70Wk9tnWxCxvQ8e76+MjAxqamriLquqqqJXr16kpqaydu1aFi5c2KXvrZRSXemwu9RGp7l99jEaAnfX7Ybc3FxmzJjB+PHjSUlJoU+fPs3LzjzzTB566CEmTpzI6NGjmT59epe9r1JKdTUxh/DJYlOnTjXtbxi0Zs0axowZs++NQ/VQug56DYWUQ/Pw0k7/rkop1YqILG11dYsO9dwuJk9TCyKY3DqUUqqb6rkB4fKAuG0Xk1JKqT303IAAOw4R0YBQSql4enhAeCEaTnYVSinVLfXwgPAk5IJ9Sil1OOjZAeHy2oA4hI/kUkqpROnhAeEBDJiuO1nuQC/3DfDHP/6R+vr6LqtFKaW+CA0I6NJuJg0IpdThoueeSQ0tARGNdNmeaH2579NPP53evXvz7LPPEgwGueiii/j5z39OXV0dl112GUVFRUSjUX784x+ze/duduzYwSmnnEJeXh5vv/121xSklFIH6PAOiFfvhF0rO15uohCuB09KS1jsS98JcNbdHS5ufbnv119/nblz5/Lxxx9jjOH888/n3XffpaSkhP79+/Pyyy8D9hpNWVlZ3HPPPbz99tvk5eXtz2+plFIJ0bO7mJpvYpeYQerXX3+d119/ncmTJzNlyhTWrl3Lhg0bmDBhAm+++SZ33HEH7733HllZWQl5f6WU+iIO7xbEXr7pAxCLwa4VkNEPMvp2+dsbY7jrrru46aab9li2dOlSXnnlFe666y5mzpzJT37yky5/f6WU+iJ6dgvC5bI3DurCQerWl/s+44wzmD17NrW1tQBs376d4uJiduzYQWpqKldffTXf+973WLZs2R7bKqVUsh3eLYjOcHXtyXKtL/d91llnceWVV3LssccCkJ6ezhNPPEFhYSG33347LpcLr9fLgw8+CMCNN97IWWedRb9+/XSQWimVdD33ct9NStbaE+Zyh3dxdYmnl/tWSh0Ivdx3Z4m7y+8qp5RSh4MeGxCxmNNycrm79ExqpZQ6XByWAbGvbrOSmiCf7ay2IXGItiAO5a5BpdSh4bALiEAgQFlZ2V4/QP0eFzFjqAtFDskWhDGGsrIyAoFAsktRSh3GDrujmAoKCigqKqKkpKTDdWLGUFzVSH2xhyyph8YqqPCCSIfbdDeBQICCgoJkl6GUOowddgHh9XoZOnToPtf7xcMfUdNYxytHfwqv/QDu2AwpvRJfoFJKHSIOuy6mzjpmaA5rd1UT8qTbGY3VyS1IKaW6mR4bEGP7ZxEzsL3Ba2cENSCUUqq1nhsQ/TIB+LzWbWdoC0IppdrosQFR0CuFDL+HdZXOLmisSm5BSinVzfTYgHC5hDH9Mlld5szQLiallGqjxwYEwNC8tFYtCA0IpZRqrUcHxKDcVLbUOWMQQe1iUkqp1hIeECLiFpFPROQl5/lQEVkkIhtE5BkR8Tnz/c7zQmf5kETXNignlRBeYm6/tiCUUqqdg9GC+BawptXz3wL3GmNGAhXA9c7864EKY8wI4F5nvYQalJMKQMSdYu9NrZRSqllCA0JECoBzgL86zwX4EjDXWWUOcKEzfYHzHGf5qc76CdMUEEFXAEIaEEop1VqiWxB/BL4PxJznuUClMabpFm5FwABnegCwDcBZXuWs34aI3CgiS0Rkyd6ut9QZ2aleMgIeGghAqPYLvZZSSh1uEhYQInIuUGyMWdp6dpxVTSeWtcwwZpYxZqoxZmp+fv4XrZEB2SnUxfzaxaSUUu0k8mJ9M4DzReRsIABkYlsU2SLicVoJBcAOZ/0iYCBQJCIeIAsoT2B9AORn+Kmt82sXk1JKtZOwFoQx5i5jTIExZghwBfCWMeYq4G3gEme164AXnOkXnec4y98yB+GuOHnpfqqjXu1iUkqpdpJxHsQdwHdFpBA7xvCoM/9RINeZ/13gzoNRTF66j8qID6NdTEop1cZBuR+EMWYBsMCZ3gQcHWedRuDSg1FPa3npfmpjfkyoLu4giFJK9VQ9+kxqsAFRjx+CdckuRSmluhUNiAwnILSLSSml2tCASPdRbwK4TAQioWSXo5RS3UaPD4j8dD8N+O0TPZJJKaWa9fiAyEnzUU/APtFuJqWUatbjA8LjdmG8KfaJniynlFLNenxAAIgvzU5oF5NSSjXTgADEn24ntItJKaWaaUAAnoATENrFpJRSzTQgAG9TC0K7mJRSqpkGBOBLzbAT2sWklFLNNCAAf2rTILUGhFJKNdGAAFJTbRdTRANCKaWaaUAAqWk2IIINesE+pZRqogEBZKalEDZuQo3aglBKqSYaEEBmwEsjPsKN2oJQSqkmGhBAZoqXRrxEgtqCUEqpJgfljnLdXVaKhyA+TKgh2aUopVS3oS0InC4m4yOmAaGUUs00IIA0v4dGfBDRgFBKqSYaEECK100DPiTSmOxSlFKq29CAAFwuISx+DQillGpFA8IRcflxR4PJLkMppboNDQhH1O3HHdMWhFJKNdGAcETdATzaglBKqWYaEI6YO4DHaEAopVQTDQiH8QTwxkLJLkMppboNDYgmngB+tAWhlFJNNCAc4k3BTQyi4WSXopRS3YIGRBNvin0M69nUSikFGhDN3E5AGA0IpZQCEhgQIhIQkY9FZIWIrBaRnzvzh4rIIhHZICLPiIjPme93nhc6y4ckqrZ4XH4bEMEGveS3UkpBYlsQQeBLxpgjgUnAmSIyHfgtcK8xZiRQAVzvrH89UGGMGQHc66x30Hj8qQDU19cezLdVSqluK2EBYaymT1uv82OALwFznflzgAud6Quc5zjLTxURSVR97Xl8NiCCDRoQSikFCR6DEBG3iCwHioE3gI1ApTEm4qxSBAxwpgcA2wCc5VVAbpzXvFFElojIkpKSki6r1RuwAdHQoLcdVUopSHBAGGOixphJQAFwNDAm3mrOY7zWgtljhjGzjDFTjTFT8/Pzu6xWXyANgHCjjkEopRQcpKOYjDGVwAJgOpAtIk23Oi0AdjjTRcBAAGd5FlB+MOoD8KU4XUwaEEopBST2KKZ8Ecl2plOA04A1wNvAJc5q1wEvONMvOs9xlr9ljNmjBZEoPucopmhIr+iqlFIAnn2vcsD6AXNExI0NomeNMS+JyGfA0yLyS+AT4FFn/UeBx0WkENtyuCKBte3B5xzFFNGAUEopIIEBYYz5FJgcZ/4m7HhE+/mNwKWJqmdf/E4Xk7YglFLK0jOpHX7nKKaYnkmtlFKABkSzQKDpUhvaglBKKdCAaOZ1BqljGhBKKQVoQDQTt5eoEYhoQCilFGhAtBAhJD5MRG8apJRSoAHRRggvogGhlFKABkQbYfFBVANCKaWgkwEhIt8SkUyxHhWRZSIyM9HFHWxh8eHSgFBKKaDzLYj/MsZUAzOBfOBrwN0JqypJIi4NCKWUatLZgGi60urZwN+MMSuIf/XVQ1pUfLhjGhBKKQWdD4ilIvI6NiBeE5EMIJa4spIj6vLhjoWSXYZSSnULnb0W0/XY24ZuMsbUi0gOtpvpsBJz+/GEtQWhlFLQ+RbEscA6Y0yliFwN/Ah7x7fDSsztx2O0BaGUUtD5gHgQqBeRI4HvA1uAxxJWVZLE3H48sXCyy1BKqW6hswERcW7ecwHwJ2PMn4CMxJWVHMbtx4u2IJRSCjo/BlEjIncB1wAnODcB8iaurCTx+PERJhyN4XXrOYRKqZ6ts5+ClwNB7PkQu4ABwO8SVlWyeAL4CdEQjia7EqWUSrpOBYQTCk8CWSJyLtBojDnsxiDE68dPmMaQBoRSSnX2UhuXAR9jbwl6GbBIRC5JZGHJIJ4AfsLUa0AopVSnxyB+CEwzxhQDiEg+8CYwN1GFJYPLG8AvEYLhSLJLUUqppOvsGISrKRwcZfux7SHD5Q0AEGzU+1IrpVRnWxD/EZHXgKec55cDrySmpORx+WxAhIIaEEop1amAMMbcLiIXAzOwF+mbZYyZl9DKksDltfelDmtAKKVUp1sQGGOeA55LYC1J53FaEOFgfZIrUUqp5NtrQIhIDWDiLQKMMSYzIVUlidtnWxDRUGOSK1FKqeTba0AYYw67y2nsjbe5BaFdTEopddgdifRFePxOCyKsAaGUUhoQrTQFREy7mJRSSgOiNV9TQIQ1IJRSSgOiFa8GhFJKNdOAaEU8GhBKKdUkYQEhIgNF5G0RWSMiq0XkW878HBF5Q0Q2OI+9nPkiIveJSKGIfCoiUxJVW4c8fgCMBoRSSiW0BREB/scYMwaYDtwmImOBO4H5xpiRwHznOcBZwEjn50bsbU4PLo89zJVI8KC/tVJKdTcJCwhjzE5jzDJnugZYg73R0AXAHGe1OcCFzvQFwGPGWghki0i/RNUXl8dnHyPaglBKqYMyBiEiQ4DJwCKgjzFmJ9gQAXo7qw0AtrXarMiZ1/61bhSRJSKypKSkpGsL1RaEUko1S3hAiEg69hpO3zbGVO9t1Tjz9rjMhzFmljFmqjFman5+fleVabntGIRENSCUUiqhASEiXmw4PGmM+Zcze3dT15Hz2HSfiSJgYKvNC4AdiaxvDy4XYbxIVLuYlFIqkUcxCfAosMYYc0+rRS8C1znT1wEvtJp/rXM003Sgqqkr6mAKixdXNHSw31YppbqdTl/u+wDMAK4BVorIcmfeD4C7gWdF5HpgK/Y+12BvQHQ2UAjUA19LYG0diogPV0wDQimlEhYQxpj3iT+uAHBqnPUNcFui6umsiMuPW8cglFJKz6RuL+Ly4dYWhFJKaUC0F3P58MS0BaGUUhoQ7URdPjwmnOwylFIq6TQg2om5/XiNtiCUUkoDoh3j9uMjTCQaS3YpSimVVBoQ7cTcfvyECUY0IJRSPZsGRHueAD7CNIajya5EKaWSSgOiPY+2IJRSCjQg9uQJ4BdtQSillAZEO+LxaQtCKaXQgNiDeAP4dQxCKaU0INqzAREiqAGhlOrhNCDacXtTcIshGNKT5ZRSPZsGRDsun73taKixIcmVKKVUcmlAtOP2pQAQCeld5ZRSPZsGRDuepoAIagtCKdWzaUC043G6mKIhDQilVM+mAdGOx69dTEopBRoQe/BqC0IppQANiD00jUHEwtqCUEr1bBoQ7XlsCyIW1haEUqpn04Boz+MHIBbWE+WUUj2bBkR7TgvCRLSLSSnVs2lAtOe0IExEWxBKqZ5NA6I9pwWBDlIrpXo4DYj2nBYEUW1BKKV6Ng2I9pyAcGkXk1Kqh9OAaM/pYhJtQSilejgNiPZcHmK4cGlAKKV6OA2I9kQIiw9XTANCKdWzaUDEEXH5cMVCyS5DKaWSKmEBISKzRaRYRFa1mpcjIm+IyAbnsZczX0TkPhEpFJFPRWRKourqjKjLh1u7mJRSPVwiWxB/B85sN+9OYL4xZiQw33kOcBYw0vm5EXgwgXXtU9Tlx60tCKVUD5ewgDDGvAuUt5t9ATDHmZ4DXNhq/mPGWghki0i/RNW2LzGXD48JEYuZZJWglFJJd7DHIPoYY3YCOI+9nfkDgG2t1ity5u1BRG4UkSUisqSkpCQhRRq3Hz9hGiPRhLy+UkodCrrLILXEmRf367sxZpYxZqoxZmp+fn5Ciol5bEDUhzQglFI918EOiN1NXUfOY7EzvwgY2Gq9AmDHQa6thduPX8I0aEAopXqwgx0QLwLXOdPXAS+0mn+tczTTdKCqqSsqKTx+/IRoDEcJRqLc/PhSPtlakbRylFIqGRJ5mOtTwEfAaBEpEpHrgbuB00VkA3C68xzgFWATUAg8AtyaqLo6xRPAT4T6UJRtpdX8Z/UuLnrgQ21RKKV6FE+iXtgY85UOFp0aZ10D3JaoWvaXeAP4CFMVijDmqRk85s3n+vDtLN5czomjnHGP2hLwpYIvLbnFKqVUgnSXQepuxeUNEJAQ4fpKfPW7ONG9knNcCymrc06ea6iE34+Audcnt1CllEogDYg4xJ9BOg3EaloOox0kxZTVOifPvX+vfVz/KjRWJaFCpZRKPA2IOFwpWWTQgKktbp7XV8opr3MCYv1rkNLLTq/5dxIqVEqpxNOAiMOdlo1LDN6arc3zBnoqbUDEYlDxOUy6yoZE0eIkVqqUUomjARGHJ9W2DlJqtgCwnkH0c1dSWhuC6u0QaYTcEZB/BJSsS2apSimVMBoQcXjTbECk19mA2OQeRr4po7wuCGWFdqXc4TYgiteA0Ws2KaUOPxoQcXhSswHIqN9KUAKU+gaQFauiprYOyjfalXKGQ+8x0FgJtbuTWK1SSiWGBkQ8gSwAejVso1oyqA/0AcBVvxvKNoEnBTL6Qf5ou37J2mRVqpRSCaMBEY8TEIFYHeVkEkyxAZERLCZaVmi7l1wuyB9j1y/WgFBKHX40IOJxAgKg1GQSyrDXERwkxZjSjZAzzC5M7w2B7M61IGJReP42+L9h8OGfE1G1Ukp1KQ2IePyZzZO7oxlEMwdhcDHctQN35WbbggB2VQcx+WNaAqK+HB67EF69c8/XXPAbWP4ENFTA27+xl+pQSqluTAMiHpe7eXJVdDC9MtIIZQxghms1YiKQM5y31u5m+m/mszzYt+VIple+B5vehkUPsmz9lpbXq9wKH/wJJl4Oty6CSAMs/EsSfjGllOo8DYh9WBEbRn6GH9NrGJNc9ggmkzucO55bCcBLOzPtkUzlm2Dty2xPGQXAghf/1vIib/8axAWn/gTyR8Hos2Hp3yFUf2BFRYLw+btQnbwroiulDn8aEPvwmRlMXrofb/7w5nnbXQMoqQlyzsR+rIwMsjPf/ClEGvlRw1VsifXmhJpXCUaisGsVrHgajrkJsgrsusfeZruaPvjj/hcUDcOTl8Kc8+Avx0DF5i/+SyqlVBwaEPvQQID8DD/unCEAFPsHs7TUdkHdctJw1vrGUePJgTX/JpwxkAWNw1mY92WmyVrWL3sHXr0DUrLh+O+0vOjg42DiFfDu76Hwzc4XE6qDp6+Cz9+BU35o5/3rJnv5j85orIbVz8PWRZ1/T6VUj6UB0YGXjn+OM4P2fkZ56T4YeyHzfOfx675/5JNtVaT63BzRN4NJg3NZLBMAWD78ZgwuRp55C+UmndH/uRK2vG+7lpou7tfk7N9Bn7Hw9NXwyRN2gLt4Dbz4Dfjr6bDs8bYf/HVlMOd8KHwDzrkHTvo+nPlr2LbQDn7vS9ESeHAG/PM6mD0TXv+RngGulNqrhN0w6FCXWjCBtSaI2yX0SvWBazDP9f4GtfURTF0FEwuy8LhdTBvcizvWX84758zk36UnkObbyZEjBvPdnLu5tfZ+Rp96JUz56p5vEMiEq+fBM1fBC63uleRNhexB8OLX4e1f2cNjc4ZBVRHUlcBlj8GY8+y6R14Jy5+CV74Pmf1h2Cl2gL2+3F4SJLO/DaaPH4G3/tc+v2YerHnJHmrrSYEv/fCg7E+l1KFHA6IDfTNTAMhN8+FyCQC9M/ys3VVNZX2YG06050JMG5rDH8jmw9zTeG/RGqYOycHtEvqPnsY57/6UFVNnkubqoKGWng9ffQU2v2tbD750GDkT0vvAiqdg/X/sB/zOFZA7DC6ZDYOOadne5bLzZs+EJy4Gl9eem1FXAtFQ2/cacx6cf7/t7hp2il3+7v+BPwNmfLNlvS0fwZJHoWo7mJg9W3zGt5oP7VVK9RwaEB3olxUAIC/d3zwvP9Nvr+gKTB5or9c0aWA2Xrfwz6Xb+Ly0juuOHQzAjOF5PLhgIx8UljJzXF8AtpbV871/rmB3TSO3nzGacyf2B7cHhn/J/rQ2+Sr7sy8ZfeDWhXZsoXQd1OyGtDwYPMNeljxYC4OPtc/FBh0icN6fIFQLb/wY3r8H3D578cHP34HUXOg9FowLVs6FT5+B0//X1uNLg3CjfQ23zz5WboOV/7TvN+YCGHnaF9n1HSv/HEo3wKiZiXl9pVQbGhAdyE714ve4yM9oCYiZY/vw8DubAJg0yAZEwOtmYkE2r622F+w7eXRvAI4emkPvDD+PL9zCzHF9KSyu5YpZCwlHY/TPTuE7zyynX1YKRw1uNzZxILwpMKmjW4B3wOWGLz8Cg461J/o1VEDZRjjuG3DyD+z9tsEeSjvvJnj1dvjPnbbF0Vhpl7n9tsVSVQQY8GfBssdgyrVwwveg1+DO19NQYc9Kbwqx9iq3wuwzoXaXHaA/6fv79/smWrDWtvomXan3KVeHDQ2IDogIEwuyGNu/5azqowbnMLZfJtsrG+idEWieP2FAFku3VHDCyDyG5NkPB5/HxbXHDub3r6/nkXc38df3NwGG5245jvx0P+f8+T2+++xy5t58XJsQam/plgo+2VrB6WP7MDi3iz943F57+O3eZPaDa1+ALR/ApgX2ftzpfewHeUMF1JXae2NMvNRewPDtX9nxjWWPQb9J9sOyoQI8ATsGMvQkKJhqu6y8abDjE/j3N6H4MyiYBmf9FgYctWcd838BwRoYcTq881s48iuQPbDr9kU0AosehD7j9mzNtbZpASx8CC56yHbXNVn8V3uo84qn4Po3bfefUoc4MYfwkSxTp041S5YsSdjrN+0bafWtNhiJEozEyAx4m+cVFtfw1/c+5wfnjGkzvzYY4dpHF7FsayW5aT7+ccN0RvfNAGDx5nKueXQfMDt7AAAaEklEQVQR6X4PXzqiN6u2V9MQjnL8iDyOHJjNuP6ZrNlZzffnfkokZtpsv6uqkd+8uoYlmys4eXQ+Pz53LAFvy9nfSVe51Z77sfl9iEXsOEq4wZ5MWPH5nutn9LfdV588ATU7YeQZthVSMNWGUfEaeGiGPX/k6Jvgvkkw5To49x67fbAGXvqObclcM8+2qPbX87fC8ift9On/23Zcpkm4Ae4/Gqq2wuRr4IL7W5bNPhO2fmSn/3u+rT0RaovhxW/aAxe+9KOWlp5S+0FElhpj9vlHqgGRYI3hKJ/trGZ0nwzS/G0bbJ/tqObu/6xl9fYqhuenk5Xq5Z11JYSiLYe3Hj00h7vOOoIbHltKdWOYYXlpbCypRRBOGJnH/LXFTB6Uze1njCYSNWwpr6dPhp9TjuiN193NvsUaYwNi1yp7gl+k0XZRjTkfUnNs62TRQ/aoq/pSu40v3Q6W+9Lg5g/smMtL37UD6Ud+xY6trHkRCueDicJRX4Nz723bVVVXCmtftmezDz0Beg1pW9f2ZfDIKbZ7rWILrH0Jrnkehp3Udr2PHoDX7rLdcts+hu9vsq2IulL4/UiY9t+2JXHC9+IfHVa01C7vOx6OubnNJV0A29JC2rZM2u+/J74MG9+yz+N1tW1aACuegTN/0/Z1omF7aPNnL8DXXoWcofHfQx04Y+yXhH5HdvtuRg2IQ1RDKMqOqgZWba+iMRzly1MK8LpdlNQE+cvbhWwrr2dE73Sunj6YgTmpvLpyJ999dgUN4Wib18lO9TJtSA5j+mbQLzuF7BQvq3dU8/pnuygsrmVoXhrXHz+MS6cWsPjzcn70/CoAHrz6qOZWTtKEG2Hnctv9VLHFDqbP+BbkjbTL60rh/qnOB6rjrN9B1Tb48D7IGwW9hkLWABswK56yR3Y1KZgGZ/7W3vDJE4AnL4HtS+Dbq2ywPHIq1BXbdSZcaruLwo1w32T7zf3UH8PsM+DSOTDuQhtor3wPbn4fXv4fe0Ljze+3DalgDdw/zZ6sGK6DQcfBJY/abjewJy8+/RVweWDmr2DIjJZlTT5/155Bf+bdtnW2aQF8Z1XLOTbbl8IjTvfYKT+Ck25v2XbRLDuOBHD0jfY8nCbGwKKH7fk0Y86HE29vW3vpBttCa6iwIXrkFW1/r1XP2dAddnLn/n23fQzzbobJV9sTSDsad9qXWNSG/v5uHw3bLwFDT7JfTLrKJ0/CC7dCSg58fbE9WKSb0oDoQcrrQqzeUYXX7WJwbiqrt9sg+PjzcraW1xNz/ondLuHoITlMGpTNh4WlrCiqoqBXCmW1IfplB6gLRmgIRfnWaaPITfOREfCQEfCSm+5jcE4qnu7UIqkvB4/fditVFbWMGyx62H5wVjvzgzUwYKr9Ru1NtScafvQA1Oyw6/uzIFhlA+aYG+28so3w3PU2oPJG22/8tcWw+T247t/2w/23g21wjTnftmD6jIdbPoClc+yYyik/tIcWh+rtN/n377VdaP89356j8vJ3IXswXP+aPR/lgWPsBxdApXOhx+O+Caf93AaUMfYSKzs+saFQugEePsGGxfRb7PpPX2WDI3+07c771gr7TTZYa7vl8o+ArIHw2fPwndUtH45N4ZEzzG7Xel8YY0Np16c2BHaugKvmwsjT7fK5/2UDAuDKf7YcYRYJwYp/QMl6mH6zPbenyZzzbNgBfO0/9ig7sB/4nz0Pu1baWide3vGHf9lGePxCEDec/2fbMuyMaAT+fo49wXTwDLj2RXskYZOmz8N471uzGz553E5P++92LbQI/GWa3X8AM39pw7SrNFZDuB4y+nbJy2lAKAAi0Ri7a4JU1IUYlJvaPEZijGH+mmIeX7iFzBQvPz5nDKFojK/+bTGFxbV7vE7TEV3G2M+r8f2zGJSbSl6an7wMH7lpdqDd53Exqk8GOWm+g/L7NYajex9/MWbP/+z15XYQPRax4yX5o2H6rW3Xi8Xg06dt66Nym13v5DtbunT+/S1Y9S/7LbF8E5z1f3bAPxaDf1wa/xIqx38XTvupnS6cbz/w80bZAwE2vgWXPwGjzrQfkEv/ZmsccZr92bXSjpGc9nM4/tv2Nf56mg2KYSeBL8O2AE6604bl7Jk2YKbfYkPzgz/acPKmwIPHwUl32FbZpnfg2WthxKlwxT/g6Stt7Zf+HYaeCKvn2d/1rN/BlGvse9YWw22LbGA+ey3M+Lb9fUrX2w/F1FwbhsWr7Tf8QBZc95LtAizbCHO/ZgN04QMw8Bj4ytO2dfLc9XY/iMt2Kx55JZx/nz2YorVgDTx0AgSr7ZFvDeW2tVf0sQ2wQBYMOQHGf7ltMEFLgI+/BFbNtdtNv9ku2/iWHYsCG7zjLmzZbs1L8Pwt9j0Beo+Dr77UErKfPgv/usH+G37wJ/uBfuvCloMVVs+DBb+1fy8X/GXPI/xWP29boqk5ttU67GR7Mm3Tti983f4tf/UlGDBlz7+t/aQBoQ5INGYorwtR0ximpjFCTWOE3dWNrNlZTVldCBEIRWIs31ZJcXWwzXhJa70z/AS8bjwuITfdx5h+mfTPTiErxUskGqMxHMPjFobkpTF5YDYBr5tIzJDebpxmd3Ujm0vrmDyoF26X8Oaa3cRihpnj+rJ8WwVXzFrIyaN786crJpHqS+BBebHonmMGxrB4SwXpoVLGjBiBEaGiPkxOitte2qR6u2211JfZ8JlwWdtvqxvegNd+YP/jjzgVzvhNyweKMfDxLHjz57ZLyuW1XTvn3deyzo7l9krBZYW21TH2QrjwQfD4YO719gOwyZjz7IcXwONfho3zW5b1nWA/wFOyobHKfsPetbJl+dCT4Op/2dp3fgqzTnZqjNruuutesq2pF78J614BDOSOhNN+ZlsCj57WtjswbxTc9C589Bd7hn/fiXZfBWts0E651l6nbMGv7fb9jrTLPH774b9rpW1JffVlexDD38+xBzd4UuzBAfVl9qg4sF12/gz7O2QPgsWP2hbhf70Gj51vx8OO+4YdD3vvD7Y2T8B2cZ50J/SfZM+/ee0HdvrLj9h9/Y/L7dF2x33T/r6v/8hud/MHdr//6wY49us2pJY/BYsfgT4TbDdoLAr9JtoW5MBptoYlj9qjARurbHdoINt+EfClw2s/tOvX7rYt0mvm2X8rf8ael/DpJA0IlXDGGKobI5TVBimtteHREIqyZmc1G4priURjRGKGXVWNrN1VQ20wss/X7J3hZ1h+GrEYbCqto7Q2CMARfTPIDHj5eHM5AMcOy6U+FGFFURUAJ4zM46pjBjGhIJtUr5u6UIS+mYG9dov98c31zPlwMxdPKeCH54yhqKKBlz7dyZDcVE4b26d5kP/DwlJeWbWTK6YNYvyALJ5dvI0lW8q57ZQRnPS7BQD89uIJbC2v54EFG7nrrCO48UR75nljOMqba3YzKCeViQUdDD7vTTRizztJydn7obOxWNvlkRBseN2OpaTkwKgzWo7uaqi0g9UNFfbb/tjz29xFkXCDbR01lNsPvQmXtu1O2bTAdhF5AjD1ekjLbVlWX267ytJ7t7TIStbbQErNteMkR33Vjv8YY1sR6161H/TH3tr2EOeVc+0HevV2+0EZDdkPUF8anPIDmHiZ87sGbVj2Hd8yOFz+uQ2r+jKo2WVbSjU77Otf/qQ92GH3Z/ZSN03dQoOPh6/8w4bKvJtt12GTAVPh2ufthzLYbrXnb7P3dgFb3xVP2m/+sRjMOrFtyE6/1bb+Kj6Hj+63Lb/S9bY+sEfnzfylnd62yLZCCt+wzwdOt627hgrbMmza5rw/2X15ADQgVLdTH4pQ1RDG63bh97gIRWKs213Dp0VVxIxBEAqLa9lSVodLhMG5qYzpl0lGwMOf3ypkZ1UDv7hgPAL8+IVVRGKGey47kg8Ky5i7tGiP9/O4hPSAh5w0HwOyUwiGY/i9LrJTfcRihpdX7mRE73QKi2s5eXQ+HxaWNbeIBuakcPaEfgDMencTxkB+hp9zJvTj7x9ubvM+uWk+yuraXtrk3suPJBSJ8ej7n7N+t+2yu+8rk0n3u1m6pYIB2amcNrY3frebZ5dsw+0SrjxmEBt219I3K9Dm3Jji6kbe21DKkQOzGdE7nUWbypjz0WZG9cngtlNGcM8b69laVs8tJw9n/IAsaoMRItEY2am2my8UieHz2PDYVFLL7uogxw7P5WALRqK8v6GUY4bl7tFSTKpgje3Wan3kkTH2QzxUY8/XyRu1Z0BXbW8Jl5xh9qCIJpXb7LhNuMF2YfadsOf7GmNbI940e9md9orX2LDtO6ElbGt2wZp/2263IScc8CVwNCDUYSUWM1Q3hps/9HZVNeIS6J0ZoCEU5dOiSgJeN4udFkaa38O28npqgxF2VjVSXBMk4HERisaoqAvRGI5x+tg+/OjcMfz+tXU8s3gbRw/N4afnjWPtrhoefX8TizdXEI0ZTh6dz3dPH8UNjy1hd3WQS44qYNLAbH732jpOHp3P2RP6cdPjS8nP8POvW47jhseWsHZXDQDD89P4n5mjmfXuJpZvs2eguwRiztBIZsBLVYMdnPZ7XAQjMTwuYfyALMYPyGRoXjqz3t3I7uogGX4PVx87mIff2UhWipeK+jDjB2SyarvtF89L93PdsYP50/wNAPzs/HE8/8l2lmyp4IppA8nP8PPntwoBuOPMI9hYUktNY5gbTxzGEX0zeXbJNlYWVXHCqDzOP3IA76wv5q/vfc51xw2hd4af5z/ZjgHOndif/tkBHvtoCxdPKcDncfHW2mLG9MvguOHxj9ypDUa44P732VhSx0WTB3DtsYOZu7SIiyYPYOqQAz+SqDEcxet24Xbt/5FQdcEIaX4PtcEIq7ZXMbZ/ZpvzmMCG65ayOgblpuL37DnWFYxE+cPr6xnXP5MLJg2gvC7Eq6t2cuLIfAp6pfD4wi2MyE/nuBHd64gmDQilvqBINEYoGiPF60ZECEdj7KhsYFBOKiJC1Dk8zCWwbGsF4/pnEfC6qW4M88GGUnpnBpgyKBsRobQ2yPOfbCc/w8/ZE/qxsaSW/6zaxcqiKm45eTgriqpYtrWCM8f15bOd1SzbUsFnO6qpCUbIS/fz24sn8NMXV1NU0cBJo/J54KopPPXxVh5+dxPThvTiG18ayWUPfURNMMIJI/NoDEdZvLkCn9vF6WP78PJKe/fBi6cUUFEf4q21xXhcQnaqj7K6ID63DafsVC+V9WEyAx6qGyP4nJYeQKrPjQB1oSgi9guwz+1CBILOOkcWZNEnM4DHLYSjho0ltYQiMTICXtbtqmZE73TW764l1eem3nmd40fkUd0QZnBuGj6Pi3VOd+SA7BTG9s9k3a4aSmqC9M8OUF4XYsPuWqYM7kVOmo+XV+7E5bzG+AFZpHjdeN0uvB4XqV436QEPXrcQDMd4btl2dlU3cOa4vvx7xU7W7a7hoskDWLurhjU7q+mT6ecHZ9uuxoyAhxG90/nVy2tYvaOawbmp/OicseysamDNzmpSfR5OGpXPI+9t4r0NpbjEBvI/Fm1l7a4aAl4XF00u4KmPt+Jzu7jvK5OZWJDFmp3VpPs9DM1PIy/NjwGKKurpleYj4HFTWhskze8hM+BBRKgNRvB7XBgDG0tqSfd7cLuE11bv4qRR+QzLTz+gv+1DMiBE5EzgT4Ab+Ksx5u69ra8BoQ5nsZihvD5ERsCD3+MmFImxq6qRgl4pzVcYbq2yPsTSLRUcPzIPlwgLN5XRNzPAiN7pLFhfQorXzTFDc4gZeyZ/bpqPvlkB/vbBZqoawpwzsR+TB2bz2updvLW2mCP6ZnLJ1AJeWL6DUCTG5dMG4nEJsz/4nFAkxsmje/PSih3UBiPceOIwXv9sN2+vLaa60XZxicDQvDQEoaiynsumDuSyqQO59831fLajmp+cO5bZH2zmk60V5KX72VBcgzEwum8GmSleCnfX8nlZHQN7pTAoJ5UdlY0EvC7G9s/k7bUlNISjnD2hL163i7fXFbOtvGGv+zPd72FoXhort1cxIDuFE0fl8+ySbQDcddYRPPzuJkpqgm228XtcfPu0UTzy3ibKnW7EnDQf9aEIjWEbiv97wTheWL6DJVsqSPW5+eWF4/n9a+vYUdXIBZP6s7m0rnmsbG+aWpZNtfo9LsrqQrhdQorXvccY3k/OHct/HX9gJzwecgEhIm5gPXA6UAQsBr5ijPmso200IJTqmYwxziHXLUEZisQIR+1PKBKjPhSlNhghGjO4XcLQvLTmrsfcdB+pPg/VjWGq6sMMzEmlNhhhS1kdBb1SqWkMs2F3LeMHZJGf4ae6Mcz6XTX0zQrY8axIjHfWl+AW4bSxfQhFYrywfDszRuTRPzuFbeX17KpuZNqQHBrDUZ7+eCsAEwqyqAtG2VRSS2VDmJiBAdkBqhrsUYP9s1OobYywvbKBYCRGQa8U6oIRKurDTB+W0xxSJ4zMY0TvAz+h9VAMiGOBnxljznCe3wVgjPlNR9toQCil1P7rbEB0o1NjGQBsa/W8yJnXhojcKCJLRGRJSUlJ+8VKKaW6SHcKiHiHIezRvDHGzDLGTDXGTM3Pj3NomFJKqS7RnQKiCGh9gf8CYEeSalFKqR6vOwXEYmCkiAwVER9wBfDiPrZRSimVIN3mdEZjTEREvg68hj3MdbYxZnWSy1JKqR6r2wQEgDHmFeCVZNehlFKqe3UxKaWU6kY0IJRSSsXVbU6UOxAiUgJsOcDN84DSLiwn0bTexDmUaoVDq95DqVboOfUONsbs8zyBQzogvggRWdKZMwm7C603cQ6lWuHQqvdQqhW03va0i0kppVRcGhBKKaXi6skBMSvZBewnrTdxDqVa4dCq91CqFbTeNnrsGIRSSqm968ktCKWUUnuhAaGUUiquHhkQInKmiKwTkUIRuTPZ9bQnIptFZKWILBeRJc68HBF5Q0Q2OI+9kljfbBEpFpFVrebFrU+s+5x9/amITOkm9f5MRLY7+3i5iJzdatldTr3rROSMg1zrQBF5W0TWiMhqEfmWM79b7t+91Nvt9q+IBETkYxFZ4dT6c2f+UBFZ5OzbZ5yLhSIifud5obN8yMGqdR/1/l1EPm+1byc587v+b8Heuq/n/GAvBLgRGAb4gBXA2GTX1a7GzUBeu3n/B9zpTN8J/DaJ9Z0ITAFW7as+4GzgVez9PqYDi7pJvT8Dvhdn3bHO34QfGOr8rbgPYq39gCnOdAb2Nrxju+v+3Uu93W7/Ovso3Zn2AoucffYscIUz/yHgFmf6VuAhZ/oK4JmDvG87qvfvwCVx1u/yv4We2II4Gig0xmwyxoSAp4ELklxTZ1wAzHGm5wAXJqsQY8y7QHm72R3VdwHwmLEWAtki0u/gVGp1UG9HLgCeNsYEjTGfA4XYv5mDwhiz0xizzJmuAdZg76zYLffvXurtSNL2r7OPap2nXufHAF8C5jrz2+/bpn0+FzhVROLd2Cwh9lJvR7r8b6EnBkSnbm2aZAZ4XUSWisiNzrw+xpidYP9TAr2TVl18HdXXnff3152m+OxWXXbdpl6nS2My9ptjt9+/7eqFbrh/RcQtIsuBYuANbAum0hgTiVNPc63O8iog92DVGq9eY0zTvv2Vs2/vFRF/+3odX3jf9sSA6NStTZNshjFmCnAWcJuInJjsgr6A7rq/HwSGA5OAncAfnPndol4RSQeeA75tjKne26px5nWHervl/jXGRI0xk7B3rDwaGLOXepK+b9vXKyLjgbuAI4BpQA5wh7N6l9fbEwOi29/a1Bizw3ksBuZh/5B3NzUXncfi5FUYV0f1dcv9bYzZ7fzniwGP0NLNkfR6RcSL/bB90hjzL2d2t92/8ertzvvXqa8SWIDtq88WkaZ747Sup7lWZ3kWne+q7FKt6j3T6dYzxpgg8DcSuG97YkB061ubikiaiGQ0TQMzgVXYGq9zVrsOeCE5FXaoo/peBK51jrCYDlQ1dZUkU7u+2Yuw+xhsvVc4R7AMBUYCHx/EugR4FFhjjLmn1aJuuX87qrc77l8RyReRbGc6BTgNO2byNnCJs1r7fdu0zy8B3jLOaHAS613b6ouCYMdLWu/brv1bOJij8t3lBzvavx7b//jDZNfTrrZh2KM8VgCrm+rD9n3OBzY4jzlJrPEpbLdBGPut5fqO6sM2e//i7OuVwNRuUu/jTj2fOv+x+rVa/4dOveuAsw5yrcdjuwU+BZY7P2d31/27l3q73f4FJgKfODWtAn7izB+GDalC4J+A35kfcJ4XOsuHHeR921G9bzn7dhXwBC1HOnX534JeakMppVRcPbGLSSmlVCdoQCillIpLA0IppVRcGhBKKaXi0oBQSikVlwaEUkkiIieLyEvJrkOpjmhAKKWUiksDQql9EJGrnevyLxeRh50LqNWKyB9EZJmIzBeRfGfdSSKy0LmQ2jxpuW/DCBF507m2/zIRGe68fLqIzBWRtSLy5MG8WqhS+6IBodReiMgY4HLsBRQnAVHgKiANWGbsRRXfAX7qbPIYcIcxZiL2bNam+U8CfzHGHAkchz2zG+zVT7+NvU/CMGBGwn8ppTrJs+9VlOrRTgWOAhY7X+5TsBfKiwHPOOs8AfxLRLKAbGPMO878OcA/nWtrDTDGzAMwxjQCOK/3sTGmyHm+HBgCvJ/4X0upfdOAUGrvBJhjjLmrzUyRH7dbb2/XrNlbt1Gw1XQU/T+puhHtYlJq7+YDl4hIb2i+N/Rg7P+dpiuAXgm8b4ypAipE5ARn/jXAO8beH6FIRC50XsMvIqkH9bdQ6gDotxWl9sIY85mI/Ah7hz8X9oqwtwF1wDgRWYq909jlzibXAQ85AbAJ+Joz/xrgYRH5hfMalx7EX0OpA6JXc1XqAIhIrTEmPdl1KJVI2sWklFIqLm1BKKWUiktbEEoppeLSgFBKKRWXBoRSSqm4NCCUUkrFpQGhlFIqrv8HrXsNVuI2ep8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize history for loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'test'], loc='upper left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:15:04.958998Z",
     "start_time": "2018-08-29T22:14:41.762998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  16.96153230073573\n",
      "RMSE =  4.118438089948145\n"
     ]
    }
   ],
   "source": [
    "model.fit(xFeatures, yTrain)\n",
    "preds = model.predict(xFeatures)\n",
    "mean_squared_error(yTrain, preds)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(\"MSE = \", mse)\n",
    "print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:15:05.471998Z",
     "start_time": "2018-08-29T22:15:04.960998Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(xValFeatures)\n",
    "mse = mean_squared_error(yVal, preds)\n",
    "rmse = sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:15:05.954998Z",
     "start_time": "2018-08-29T22:15:05.472998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  20.772631017447935\n",
      "RMSE =  4.557700189508733\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE = \", mse)\n",
    "print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T22:15:06.442998Z",
     "start_time": "2018-08-29T22:15:05.955998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 350,\n",
       " 'batch_size': 36,\n",
       " 'verbose': 0,\n",
       " 'build_fn': <function __main__.wrapper.<locals>.buildModel()>}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "Again, if we were creating a production quality model we would have started with randomized parameter optimization process.  The results from that process would then lead to a set of smaller grids focusing more and more on whatever parameter option permutations showed the most promise.\n",
    "\n",
    "You can see an example of this type of process I worked on previously [here](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/03-ComputerVision-Classification/Classification-03.ipynb).\n",
    "\n",
    "Also, unless the randomized parameter optimization process were to lead to signifigant improvements from what we've seen so far we'd be better of utilizing the gradient boosting algorithm we utilized in [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb#Initial-pass---Ensemble-methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Hopefully to same some one else some pain down the road:\n",
    "\n",
    "I kept getting the following error when working on this prediction section, which frankly was driving me nuts:\n",
    "    \n",
    "```\n",
    "TypeError: call() missing 1 required positional argument: 'inputs'\n",
    "```\n",
    "\n",
    "After researching the error message I came upon this comment which let me to the resolution:\n",
    "\n",
    "_The thing here is that KerasRegressor expects a callable that builds a model, rather than the model itself. By wrapping your function in this way you can return the build function (without calling it)._  [Source](https://stackoverflow.com/questions/47944463/specify-input-argument-with-kerasregressor)\n",
    "\n",
    "Solution:  I needed to **wrap** the `buildModel()` function!  :(\n",
    "\n",
    "Once I 'wrapped' the `buildModel()` function the prediction code blocks finally started working, and that's why we have the `wrapper()` function implemented below...\n",
    "\n",
    "**END NOTE**\n",
    "\n",
    "And now that that's out of the way we'll take a look at some predictions using the test data set based on the tuning results from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See NOTE above on why we have this new function\n",
    "def wrapper(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    \n",
    "    def buildModel():\n",
    "        opt = None\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "        # bias_initializer -> 'zeros' (default per the docs)\n",
    "\n",
    "        model.add(Dense(20, input_dim = xTrain.shape[1], kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "        if optimizer.lower() == 'adam':\n",
    "            opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "        else:\n",
    "            # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "            # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "            opt = eval(optimizer)()\n",
    "\n",
    "        model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "\n",
    "        return model\n",
    "\n",
    "    return buildModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  11.93922294223878\n",
      "RMSE =  3.4553180667253747\n"
     ]
    }
   ],
   "source": [
    "# Build the model, and pass the KerasRegressor a callable function to the 'build_fn' argument\n",
    "# Use the parameters we found were most effective during the hyperparameter tuning\n",
    "m =  KerasRegressor(\n",
    "    build_fn = wrapper(optimizer = 'Adam', lr = 0.003, epsilon = 1), \n",
    "    epochs = 300, \n",
    "    batch_size = 32, \n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Now fit the model to the training data ensuring we perform the same sort of pipeline transformations\n",
    "# that occured during the hyperparameter tuning (i.e. feature scaling)\n",
    "xScaled = StandardScaler().fit(xTrain).transform(xTrain)\n",
    "m.fit(xScaled, yTrain)\n",
    "\n",
    "# Now we can finally make some predictions using our trained model on unseen data\n",
    "xScaled = StandardScaler().fit(xTrain).transform(xVal)\n",
    "preds = m.predict(xScaled)\n",
    "mse = mean_squared_error(yVal, preds)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(\"MSE = \", mse)\n",
    "print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T01:52:09.339400Z",
     "start_time": "2018-08-27T01:52:09.114369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeRange(4, 68, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T01:50:45.294455Z",
     "start_time": "2018-08-27T01:50:45.040458Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3715696215e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'col'"
     ]
    }
   ],
   "source": [
    "xTrain.col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T02:23:35.274301Z",
     "start_time": "2018-08-27T02:23:35.055287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeRange(1, 9, 1, .001, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T02:29:43.169231Z",
     "start_time": "2018-08-27T02:29:42.949309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.5, 2.0, 2.5, 3.0, 3.5]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeRange(2, 8, 1, .5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T22:44:52.794003Z",
     "start_time": "2018-08-28T22:44:52.606469Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(a1, a2, a3):\n",
    "    print(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T22:44:53.840847Z",
     "start_time": "2018-08-28T22:44:53.668944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a3': 'abc', 'a2': 2, 'a1': 1}\n"
     ]
    }
   ],
   "source": [
    "test(1, 2, 'abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
