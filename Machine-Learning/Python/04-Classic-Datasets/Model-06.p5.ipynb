{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#IMDB-Movie-Review-Sentiment-Classification\" data-toc-modified-id=\"IMDB-Movie-Review-Sentiment-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IMDB Movie Review Sentiment Classification</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Process\" data-toc-modified-id=\"Process-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Process</a></span></li><li><span><a href=\"#Configure-notebook,-import-libraries,-and-import-dataset\" data-toc-modified-id=\"Configure-notebook,-import-libraries,-and-import-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configure notebook, import libraries, and import dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Define-global-variables\" data-toc-modified-id=\"Define-global-variables-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Define global variables</a></span></li></ul></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#Examine-the-data\" data-toc-modified-id=\"Examine-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Examine the data</a></span></li><li><span><a href=\"#Cleaning-and-preprocessing\" data-toc-modified-id=\"Cleaning-and-preprocessing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cleaning and preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-labeled-training-data\" data-toc-modified-id=\"Load-labeled-training-data-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Load labeled training data</a></span></li><li><span><a href=\"#Write-helper-functions\" data-toc-modified-id=\"Write-helper-functions-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Write helper functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-cleaner\" data-toc-modified-id=\"Sentence-cleaner-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Sentence cleaner</a></span></li></ul></li><li><span><a href=\"#Create-list-of-Doc2Vec-TaggedDocument-objects\" data-toc-modified-id=\"Create-list-of-Doc2Vec-TaggedDocument-objects-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Create list of Doc2Vec TaggedDocument objects</a></span></li></ul></li><li><span><a href=\"#Train-Doc2Vec-model---Initial-pass\" data-toc-modified-id=\"Train-Doc2Vec-model---Initial-pass-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Train Doc2Vec model - Initial pass</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-Doc2Vec-model-object\" data-toc-modified-id=\"Define-the-Doc2Vec-model-object-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Define the Doc2Vec model object</a></span></li><li><span><a href=\"#Build-vocabulary-from-a-sequence-of-sentences-(i.e.-our-reviews)\" data-toc-modified-id=\"Build-vocabulary-from-a-sequence-of-sentences-(i.e.-our-reviews)-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Build vocabulary from a sequence of sentences (i.e. our reviews)</a></span></li><li><span><a href=\"#Train-the-Doc2Vec-model\" data-toc-modified-id=\"Train-the-Doc2Vec-model-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Train the Doc2Vec model</a></span></li><li><span><a href=\"#Create-a-feature-set-utilizing-the-trained-Doc2Vec-model\" data-toc-modified-id=\"Create-a-feature-set-utilizing-the-trained-Doc2Vec-model-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Create a feature set utilizing the trained Doc2Vec model</a></span></li><li><span><a href=\"#Pass-the-feature-set-to-the-Scikit-learn-models-for-training-and-evaluation\" data-toc-modified-id=\"Pass-the-feature-set-to-the-Scikit-learn-models-for-training-and-evaluation-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Pass the feature set to the Scikit-learn models for training and evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kaggle-model\" data-toc-modified-id=\"Kaggle-model-8.5.1\"><span class=\"toc-item-num\">8.5.1&nbsp;&nbsp;</span>Kaggle model</a></span></li><li><span><a href=\"#Standard-write-up-models\" data-toc-modified-id=\"Standard-write-up-models-8.5.2\"><span class=\"toc-item-num\">8.5.2&nbsp;&nbsp;</span>Standard write-up models</a></span></li><li><span><a href=\"#Standard-model-comments\" data-toc-modified-id=\"Standard-model-comments-8.5.3\"><span class=\"toc-item-num\">8.5.3&nbsp;&nbsp;</span>Standard model comments</a></span></li></ul></li></ul></li><li><span><a href=\"#Tuning-Doc2Vec\" data-toc-modified-id=\"Tuning-Doc2Vec-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Tuning Doc2Vec</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Implementation</a></span></li><li><span><a href=\"#Create-the-model,-build-the-vocab,-and-train\" data-toc-modified-id=\"Create-the-model,-build-the-vocab,-and-train-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Create the model, build the vocab, and train</a></span></li><li><span><a href=\"#Train-and-assess-classifiers\" data-toc-modified-id=\"Train-and-assess-classifiers-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Train and assess classifiers</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Combining-Doc2Vec-models\" data-toc-modified-id=\"Combining-Doc2Vec-models-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Combining Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Doc2Vec-models,-build-vocabulary,-and-train\" data-toc-modified-id=\"Create-Doc2Vec-models,-build-vocabulary,-and-train-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Create Doc2Vec models, build vocabulary, and train</a></span></li><li><span><a href=\"#Combination-one:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-one:--Train-and-assess-classifiers-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Combination one:  Train and assess classifiers</a></span></li><li><span><a href=\"#Combination-two:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-two:--Train-and-assess-classifiers-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Combination two:  Train and assess classifiers</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-10.4\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Increased-vocabulary-and-combined-Doc2Vec-models\" data-toc-modified-id=\"Increased-vocabulary-and-combined-Doc2Vec-models-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Increased vocabulary and combined Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Process-and-combine-unlabeled-data\" data-toc-modified-id=\"Process-and-combine-unlabeled-data-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Process and combine unlabeled data</a></span></li><li><span><a href=\"#Create-Doc2Vec-models,-build-vocabulary,-and-train\" data-toc-modified-id=\"Create-Doc2Vec-models,-build-vocabulary,-and-train-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Create Doc2Vec models, build vocabulary, and train</a></span></li><li><span><a href=\"#Combination-one:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-one:--Train-and-assess-classifiers-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Combination one:  Train and assess classifiers</a></span></li><li><span><a href=\"#Combination-Two:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-Two:--Train-and-assess-classifiers-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Combination Two:  Train and assess classifiers</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-11.5\"><span class=\"toc-item-num\">11.5&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Manual-training-and-feature-set-creation-utilizing-combined-Doc2Vec-models\" data-toc-modified-id=\"Manual-training-and-feature-set-creation-utilizing-combined-Doc2Vec-models-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Manual training and feature set creation utilizing combined Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Doc2Vec-models,-build-vocabulary,-and-train\" data-toc-modified-id=\"Create-Doc2Vec-models,-build-vocabulary,-and-train-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Create Doc2Vec models, build vocabulary, and train</a></span></li><li><span><a href=\"#Combination-one:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-one:--Train-and-assess-classifiers-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Combination one:  Train and assess classifiers</a></span></li><li><span><a href=\"#Combination-two:--Train-and-assess-classifiers\" data-toc-modified-id=\"Combination-two:--Train-and-assess-classifiers-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Combination two:  Train and assess classifiers</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-12.4\"><span class=\"toc-item-num\">12.4&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Movie Review Sentiment Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 30%; height: 30%;\" src=\"images/imdb.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The overall goal of this set of write-ups is to explore a number of machine learning algorithms utilizing natural language processing (NLP) to classify sentiment IMDB movie reviews.\n",
    "\n",
    "The specific goals of this write-up include:\n",
    "1. Create a set of document vectors from the IMDb movie review text utilizing [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "2. Tune and train a number of Doc2Vec models on the movie review corpus \n",
    "2. Run the models from the [first write-up](./Model-06.ipynb) against the Doc2Vec feature set outputs\n",
    "3. Determine if utilizing Doc2Vec improves our ability to correctly classify movie review sentiment\n",
    "\n",
    "This series of write-ups is inspired by the Kaggle [\n",
    "Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial) competition.\n",
    "\n",
    "References:\n",
    "* [Gensim Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "* [Original paper](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "\n",
    "Dataset source:  [IMDB Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure notebook, import libraries, and import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T15:16:22.416553Z",
     "start_time": "2018-10-16T15:16:22.413553Z"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:27.770656Z",
     "start_time": "2018-11-16T21:04:20.152656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# http://www.nltk.org/index.html\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Creating function implementing punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Only need this the first time...\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# https://pypi.org/project/gensim/\n",
    "# pip install gensim\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert(gensim.models.doc2vec.FAST_VERSION > -1, \"Going to be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:28.349656Z",
     "start_time": "2018-11-16T21:04:27.771656Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Opens a GUI that allows us to download the NLTK data\n",
    "# nltk.download()\n",
    "\n",
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function trains the \"standard\" set of Scikit-learn models we've been evaluating and returns the results.  This should reduce the verbosity of the write-up below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:28.937656Z",
     "start_time": "2018-11-16T21:04:28.350656Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModels(xTrain, yTrain, modelsToRun = ['LR', 'LDA', 'SVM']):\n",
    "    # Init vars\n",
    "    folds = 10\n",
    "    seed = 10\n",
    "    models = []\n",
    "    results = {}\n",
    "\n",
    "    # Use accuracy since this is a classification\n",
    "    score = 'accuracy'\n",
    "    \n",
    "    # Instantiate model objects\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC()))\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    _df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "    # Run the models\n",
    "    for modelName, model in models:\n",
    "        if (modelName in modelsToRun) or (modelsToRun == 'all'):\n",
    "            print(\"Training\", modelName, \"....\")\n",
    "            # Implement K-fold cross validation where K = 10\n",
    "            kFold = KFold(n_splits = folds, random_state = seed)\n",
    "            results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "            _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "    # Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "    return(results, _df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T21:50:24.692548Z",
     "start_time": "2018-11-07T21:47:53.669Z"
    }
   },
   "source": [
    "And another function to draw the whisker plots of model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:29.514656Z",
     "start_time": "2018-11-16T21:04:28.939656Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeWhisker(results):\n",
    "    figure = plt.figure(figsize = (8,6))\n",
    "    figure.suptitle(\"Model Results\")\n",
    "    axis = figure.add_subplot(111)\n",
    "    plt.boxplot(results.values())\n",
    "    axis.set_xticklabels(results.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Examine-the-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labeled training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Previous process justification and methodology also previously covered [here](./Model-06.ipynb#Cleaning-and-preprocessing).)\n",
    "\n",
    "We need to load the labeled training data exactly as we've done in previous write-ups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:30.472656Z",
     "start_time": "2018-11-16T21:04:29.515656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape : (25000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Pull in the labeled data\n",
    "df = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "\n",
    "# Sanity check\n",
    "print('df.shape :', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write helper functions\n",
    "\n",
    "Doc2Vec expects a list of `TaggedDocument` objects.  The first argument of the `TaggedDocument` constructor is a contiguous list of words (which we'll clean as usual), and the second argument is a unique tag.  For example, here is what a sample `TaggedDocument` object looks like:\n",
    "\n",
    "```\n",
    "TaggedDocument(words=['with', 'all', 'this', 'stuff', 'going', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'started', 'listening', 'to', 'his', ...... <SNIP>], tags=[0])\n",
    "```\n",
    "\n",
    "In order to facilitate this we'll first write the \"cleaner\" function to process the review text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence cleaner\n",
    "\n",
    "Take a given sentence and process/clean it (i.e. remove HTML and other cruft, lower case the text, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:31.085656Z",
     "start_time": "2018-11-16T21:04:30.474656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update stop word helper function to output a list of words\n",
    "\n",
    "# Clean IMDB review text\n",
    "def cleanReview(review, removeStopWords = False):\n",
    "    results = []\n",
    "    \n",
    "    # Convert the stop words to a set\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Remove HTML\n",
    "    clean = BeautifulSoup(review)\n",
    "    \n",
    "    # Remove non-alpha chars\n",
    "    clean = re.sub(\"[^a-zA-Z]\", ' ', clean.get_text())\n",
    "    \n",
    "    # Convert to lower case and \"tokenize\"\n",
    "    clean = clean.lower().split()\n",
    "    \n",
    "    # Remove stop words and add to global vocab\n",
    "    for x in clean:\n",
    "        if removeStopWords:\n",
    "            if not x in stopWords:\n",
    "                results.append(x)\n",
    "                #if x not in vocab:\n",
    "                #    vocab.append(x)\n",
    "        else:\n",
    "            results.append(x)\n",
    "            #if x not in vocab:\n",
    "            #    vocab.append(x)\n",
    "    \n",
    "    # Return results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick examination of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:31.751656Z",
     "start_time": "2018-11-16T21:04:31.087656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looking',\n",
       " 'quo',\n",
       " 'vadis',\n",
       " 'local',\n",
       " 'video',\n",
       " 'store',\n",
       " 'found',\n",
       " 'version',\n",
       " 'looked',\n",
       " 'interesting',\n",
       " 'wow',\n",
       " 'amazing']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine\n",
    "cleanReview(df.iloc[25,2], True)[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:32.772656Z",
     "start_time": "2018-11-16T21:04:31.753656Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can skip the blocks below if desired and load the cleanDocs and vocab objects from disk\n",
    "with open('Model-06.p5.cleanDocs.pkl','rb') as f:\n",
    "    cleanDocs =  pickle.load(f)\n",
    "    \n",
    "with open('Model-06.p5.vocab.pkl','rb') as f:\n",
    "    vocab =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T20:37:23.037656Z",
     "start_time": "2018-11-16T20:30:57.083656Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# **NOTE**  This can be skipped if you load from disk above...\n",
    "cleanDocs = []\n",
    "vocab = []\n",
    "\n",
    "# Clean the reviews\n",
    "for i, s in enumerate(df.iloc[:,2]):\n",
    "    cleanDocs.append(cleanReview(s, True))\n",
    "\n",
    "# Create a vocab of all the words in the cleaned reviews\n",
    "for d in cleanDocs:\n",
    "    words = set(d)\n",
    "    for w in words:\n",
    "        if w not in vocab:\n",
    "            vocab.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:33.343656Z",
     "start_time": "2018-11-16T21:04:32.773656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74065\n",
      "['wants', 'visually', 'mj', 'dunno', 'maybe', 'moonwalker', 'innocent', 'bit', 'patience', 'stay', 'film', 'remotely', 'may', 'character', 'hmmm', 'jackson', 'egotist', 'made', 'bad', 'dead']\n"
     ]
    }
   ],
   "source": [
    "# Examine some vocab metrics\n",
    "print(len(vocab))\n",
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:33.945656Z",
     "start_time": "2018-11-16T21:04:33.345656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now create a collection of review sizes in words\n",
    "counts = []\n",
    "\n",
    "for i, d in enumerate(cleanDocs):\n",
    "    counts.append(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:34.550656Z",
     "start_time": "2018-11-16T21:04:33.947656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max review size in words: 1416\n",
      "Min review size in words: 4\n"
     ]
    }
   ],
   "source": [
    "# What are the max and min review sizes in words?\n",
    "print(\"Max review size in words:\", max(counts))\n",
    "print(\"Min review size in words:\", min(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:35.157656Z",
     "start_time": "2018-11-16T21:04:34.552656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to help his brother, but the referee restrained him while Benoit and Guerrero ganged up on him in the corner. With Benoit stomping away on Bubba, Guerrero set up a table outside. Spike dashed into the ring and somersaulted over the top rope onto Guerrero on the outside! After recovering and taking care of Spike, Guerrero slipped a table into the ring and helped the Wolverine set it up. The tandem then set up for a double superplex from the middle rope which would have put Bubba through the table, but Spike knocked the table over right before his brother came crashing down! Guerrero and Benoit propped another table in the corner and tried to Irish Whip Spike through it, but Bubba dashed in and blocked his brother. Bubba caught fire and lifted both opponents into back body drops! Bubba slammed Guerrero and Spike stomped on the Wolverine from off the top rope. Bubba held Benoit at bay for Spike to soar into the Wassup! headbutt! Shortly after, Benoit latched Spike in the Crossface, but the match continued even after Spike tapped out. Bubba came to his brother\\'s rescue and managed to sprawl Benoit on a table. Bubba leapt from the middle rope, but Benoit moved and sent Bubba crashing through the wood! But because his opponents didn\\'t force him through the table, Bubba was allowed to stay in the match. The first man was eliminated shortly after, though, as Spike put Eddie through a table with a Dudley Dawg from the ring apron to the outside! Benoit put Spike through a table moments later to even the score. Within seconds, Bubba nailed a Bubba Bomb that put Benoit through a table and gave the Dudleys the win! Winner: Bubba Ray and Spike Dudley<br /><br />Match 2: Cruiserweight Championship Jamie Noble vs Billy Kidman Billy Kidman challenged Jamie Noble, who brought Nidia with him to the ring, for the Cruiserweight Championship. Noble and Kidman locked up and tumbled over the ring, but raced back inside and grappled some more. When Kidman thwarted all Noble\\'s moves, Noble fled outside the ring where Nidia gave him some encouragement. The fight spread outside the ring and Noble threw his girlfriend into the challenger. Kidman tossed Nidia aside but was taken down with a modified arm bar. Noble continued to attack Kidman\\'s injured arm back in the ring. Kidman\\'s injured harm hampered his offense, but he continued to battle hard. Noble tried to put Kidman away with a powerbomb but the challenger countered into a facebuster. Kidman went to finish things with a Shooting Star Press, but Noble broke up the attempt. Kidman went for the Shooting Star Press again, but this time Noble just rolled out of harm\\'s way. Noble flipped Kidman into a power bomb soon after and got the pin to retain his WWE Cruiserweight Championship! Winner: Jamie Noble<br /><br />Match 3: European Championship William Regal vs Jeff Hardy William Regal took on Jeff Hardy next in an attempt to win back the European Championship. Jeff catapulted Regal over the top rope then took him down with a hurracanrana off the ring apron. Back in the ring, Jeff hit the Whisper in the wind to knock Regal for a loop. Jeff went for the Swanton Bomb, but Regal got his knees up to hit Jeff with a devastating shot. Jeff managed to surprise Regal with a quick rollup though and got the pin to keep the European Championship! Regal started bawling at seeing Hardy celebrate on his way back up the ramp. Winner: Jeff Hardy<br /><br />Match 4: Chris Jericho vs John Cena Chris Jericho had promised to end John Cena\\'s career in their match at Vengeance, which came up next. Jericho tried to teach Cena a lesson as their match began by suplexing him to the mat. Jericho continued to knock Cena around the ring until his cockiness got the better of him. While on the top rope, Jericho began to showboat and allowed Cena to grab him for a superplex! Cena followed with a tilt-a-whirl slam but was taken down with a nasty dropkick to the gut. The rookie recovered and hit a belly to belly suplex but couldn\\'t put Y2J away. Jericho launched into the Lionsault but Cena dodged the move. Jericho nailed a bulldog and then connected on the Lionsault, but did not go for the cover. He goaded Cena to his feet so he could put on the Walls of Jericho. Cena had other ideas, reversing the move into a pin attempt and getting the 1-2-3! Jericho went berserk after the match. Winner: John Cena<br /><br />Match 5: Intercontinental Championship RVD vs Brock Lesnar via disqualification The Next Big Thing and Mr. Pay-Per-View tangled with the Intercontinental Championship on the line. Brock grabbed the title from the ref and draped it over his shoulder momentarily while glaring at RVD. Van Dam \\'s quickness gave Brock fits early on. The big man rolled out of the ring and kicked the steel steps out of frustration. Brock pulled himself together and began to take charge. With Paul Heyman beaming at ringside, Brock slammed RVD to the hard floor outside the ring. From there, Brock began to overpower RVD, throwing him with ease over the top rope. RVD landed painfully on his back, then had to suffer from having his spine cracked against the steel ring steps. The fight returned to the ring with Brock squeezing RVD around the ribs. RVD broke away and soon after leveled Brock with a kick to the temple. RVD followed with the Rolling Thunder but Brock managed to kick out after a two-count. The fight looked like it might be over soon as RVD went for a Five-Star Frog Splash. Brock, though, hoisted Van Dam onto his shoulder and went for the F-5, but RVD whirled Brock into a DDT and followed with the Frog Splash! He went for the pin, but Heyman pulled the ref from the ring! The ref immediately called for a disqualification and soon traded blows with Heyman! After, RVD leapt onto Brock from the top rope and then threatened to hit the Van Terminator! Heyman grabbed RVD\\'s leg and Brock picked up the champ and this time connected with the F-5 onto a steel chair! Winner: RVD<br /><br />Match 6: Booker T vs the Big Show Booker T faced the Big Show one-on-one next. Show withstood Booker T\\'s kicks and punches and slapped Booker into the corner. After being thrown from the ring, Booker picked up a chair at ringside, but Big Show punched it back into Booker\\'s face. Booker tried to get back into the game by choking Show with a camera cable at ringside. Booker smashed a TV monitor from the Spanish announcers\\' position into Show\\'s skull, then delivered a scissors kick that put both men through the table! Booker crawled back into the ring and Big Show staggered in moments later. Show grabbed Booker\\'s throat but was met by a low blow and a kick to the face. Booker climbed the top rope and nailed a somersaulting leg drop to get the pin! Winner: Booker T<br /><br />Announcement: Triple H entered the ring to a thunderous ovation as fans hoped to learn where The Game would end up competing. Before he could speak, Eric Bishoff stopped The Game to apologize for getting involved in his personal business. If Triple H signed with RAW, Bischoff promised his personal life would never come into play again. Bischoff said he\\'s spent the past two years networking in Hollywood. He said everyone was looking for the next breakout WWE Superstar, and they were all talking about Triple H. Bischoff guaranteed that if Triple H signed with RAW, he\\'d be getting top opportunities coming his way. Stephanie McMahon stepped out to issue her own pitch. She said that because of her personal history with Triple H, the two of them know each other very well. She said the two of them were once unstoppable and they can be again. Bischoff cut her off and begged her to stop. Stephanie cited that Triple H once told her how Bischoff said Triple H had no talent and no charisma. Bischoff said he was young at the time and didn\\'t know what he had, but he still has a lot more experience that Stephanie. The two continued to bicker back and forth, until Triple H stepped up with his microphone. The Game said it would be easy to say \\\\\"screw you\\\\\" to either one of them. Triple H went to shake Bischoff\\'s hand, but pulled it away. He said he would rather go with the devil he knows, rather than the one he doesn\\'t know. Before he could go any further, though, Shawn Michaels came out to shake things up. HBK said the last thing he wanted to do was cause any trouble. He didn\\'t want to get involved, but he remembered pledging to bring Triple H to the nWo. HBK said there\\'s nobody in the world that Triple H is better friends with. HBK told his friend to imagine the two back together again, making Bischoff\\'s life a living hell. Triple H said that was a tempting offer. He then turned and hugged HBK, making official his switch to RAW! Triple H and HBK left, and Bischoff gloated over his victory. Bischoff said the difference between the two of them is that he\\'s got testicles and she doesn\\'t. Stephanie whacked Bischoff on the side of the head and left!<br /><br />Match 7: Tag Team Championship Match Christian and Lance Storm vs Hollywood Hogan and Edge The match started with loud \\\\\"USA\\\\\" chants and with Hogan shoving Christian through the ropes and out of the ring. The Canadians took over from there. But Edge scored a kick to Christian\\'s head and planted a facebuster on Storm to get the tag to Hogan. Hogan began to Hulk up and soon caught Christian with a big boot and a leg drop! Storm broke up the count and Christian tossed Hogan from the ring where Storm superkicked the icon. Edge tagged in soon after and dropped both opponents. He speared both of them into the corner turnbuckles, but missed a spear on Strom and hit the ref hard instead. Edge nailed a DDT, but the ref was down and could not count. Test raced down and took down Hogan then leveled Edge with a boot. Storm tried to get the pin, but Edge kicked out after two. Riksihi sprinted in to fend off Test, allowing Edge to recover and spear Storm. Christian distracted the ref, though, and Y2J dashed in and clocked Edge with the Tag Team Championship! Storm rolled over and got the pinfall to win the title! Winners and New Tag Team Champions: Christian and Lance Storm<br /><br />Match 8: WWE Undisputed Championship Triple Threat Match. The Rock vs Kurt Angle and the Undertaker Three of WWE\\'s most successful superstars lined up against each other in a Triple Threat Match with the Undisputed Championship hanging in the balance. Taker and The Rock got face to face with Kurt Angle begging for some attention off to the side. He got attention in the form of a beat down form the two other men. Soon after, Taker spilled out of the ring and The Rock brawled with Angle. Angle gave a series of suplexes that took down Rock, but the Great One countered with a DDT that managed a two-count. The fight continued outside the ring with Taker coming to life and clotheslining Angle and repeatedly smacking The Rock. Taker and Rock got into it back into the ring, and Taker dropped The Rock with a sidewalk slam to get a two-count. Rock rebounded, grabbed Taker by the throat and chokeslammed him! Angle broke up the pin attempt that likely would have given The Rock the title. The Rock retaliated by latching on the ankle lock to Kurt Angle. Angle reversed the move and Rock Bottomed the People\\'s Champion. Soon after, The Rock disposed of Angle and hit the People\\'s Elbow on the Undertaker. Angle tried to take advantage by disabling the Great One outside the ring and covering Taker, who kicked out after a two count. Outside the ring, Rock took a big swig from a nearby water bottle and spewed the liquid into Taker\\'s face to blind the champion. Taker didn\\'t stay disabled for long, and managed to overpower Rock and turn his attention to Angle. Taker landed a guillotine leg drop onto Angle, laying on the ring apron. The Rock picked himself up just in time to break up a pin attempt on Kurt Angle. Taker nailed Rock with a DDT and set him up for a chokeslam. ANgle tried sneaking up with a steel chair, but Taker caught on to that tomfoolery and smacked it out of his hands. The referee got caught in the ensuing fire and didn\\'t see Angle knock Taker silly with a steel chair. Angle went to cover Taker as The Rock lay prone, but the Dead Man somehow got his shoulder up. Angle tried to pin Rock, but he too kicked out. The Rock got up and landed Angle in the sharpshooter! Angle looked like he was about to tap, but Taker kicked The Rock out of the submission hold. Taker picked Rock up and crashed him with the Last Ride. While the Dead Man covered him for the win, Angle raced in and picked Taker up in the ankle lock! Taker went delirious with pain, but managed to counter. He picked Angle up for the last ride, but Angle put on a triangle choke! It looked like Taker was about to pass out, but The Rock broke Angle\\'s hold only to find himself caught in the ankle lock. Rock got out of the hold and watched Taker chokeslam Angle. Rocky hit the Rock Bottom, but Taker refused to go down and kicked out. Angle whirled Taker up into the Angle Slam but was Rock Bottomed by the Great One and pinned! Winner and New WWE Champion: The Rock<br /><br />~Finally there is a decent PPV! Lately the PPV weren\\'t very good, but this one was a winner. I give this PPV a A-<br /><br />\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect the max review\n",
    "df.iloc[counts.index(max(counts)),2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:35.771656Z",
     "start_time": "2018-11-16T21:04:35.159656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"This movie is terrible but it has some good effects.\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect the min review\n",
    "df.iloc[counts.index(min(counts)),2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:36.357656Z",
     "start_time": "2018-11-16T21:04:35.773656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 largest reviews in words: [700, 707, 731, 794, 796, 811, 873, 911, 924, 1416]\n",
      "10 smallest reviews in words: [4, 6, 6, 6, 7, 8, 8, 8, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "# View the 10 largest and 10 smallest reviews in words\n",
    "counts.sort()\n",
    "print(\"10 largest reviews in words:\", counts[-10:])\n",
    "print(\"10 smallest reviews in words:\", counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:03:29.981656Z",
     "start_time": "2018-11-16T21:03:27.840656Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# **NOTE** This block can be skipped if you've already written cleanDocs and vocab to disk\n",
    "\n",
    "# Pickle the cleanDocs and vocab to save time if/when we run this again\n",
    "with open('Model-06.p5.cleanDocs.pkl','wb') as f:\n",
    "    pickle.dump(cleanDocs, f)\n",
    "    \n",
    "with open('Model-06.p5.vocab.pkl','wb') as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest review in words frankly looks like junk.  We are going to ignore it and make the max seq. length the 2nd largest review size in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:36.934656Z",
     "start_time": "2018-11-16T21:04:36.358656Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabSize = len(vocab)\n",
    "seqLength = counts[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build a neural network with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:37.492656Z",
     "start_time": "2018-11-16T21:04:36.935656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:41.952656Z",
     "start_time": "2018-11-16T21:04:37.494656Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocabSize)\n",
    "tokenizer.fit_on_texts(cleanDocs)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(cleanDocs)\n",
    "data = pad_sequences(sequences, maxlen = seqLength, padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:42.525656Z",
     "start_time": "2018-11-16T21:04:41.953656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's confirm Keras was smart enough to understand we already tokenized the review text\n",
    "assert(len(sequences) == len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:43.100656Z",
     "start_time": "2018-11-16T21:04:42.527656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  404,    70,   419, ...,     0,     0,     0],\n",
       "       [  232,   203,  3048, ...,     0,     0,     0],\n",
       "       [    2,   382,  2818, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  117,  3104,    14, ...,     0,     0,     0],\n",
       "       [  639,   516, 16593, ...,     0,     0,     0],\n",
       "       [  109,     1,   350, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's also examine what the final product looks like\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:04:43.996656Z",
     "start_time": "2018-11-16T21:04:43.103656Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, 100, input_length = seqLength))\n",
    "model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run Keras' fit or fit_generator with verbose=0 settings, but with a callback to the imported TQDMNotebookCallback, e.g. model.fit(X_train, Y_train, verbose=0, callbacks=[TQDMNotebookCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T21:27:04.742656Z",
     "start_time": "2018-11-16T21:09:38.452656Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9a8290151c4f3b82e3c5fcec3f328d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=3, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9e51bc3fe34225bf92361c1f1cb1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=15000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cb55c332fc4953a0f3770828546460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=15000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9581b200e22e4ecd94660a15c13e9d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=15000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x527b198>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data, \n",
    "    df.iloc[:, 1], \n",
    "    validation_split = 0.4, \n",
    "    epochs = 3, \n",
    "    verbose = 0, \n",
    "    callbacks = [TQDMNotebookCallback(leave_inner = True, leave_outer = True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty poor results...   Let's try another model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T22:01:14.820656Z",
     "start_time": "2018-11-16T22:01:14.205656Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T22:01:15.558656Z",
     "start_time": "2018-11-16T22:01:14.821656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 924, 100)          7406500   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 917, 32)           25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 458, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 14656)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                146570    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 7,578,713\n",
      "Trainable params: 7,578,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = define_model(vocabSize, seqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T22:10:14.919656Z",
     "start_time": "2018-11-16T22:01:15.560656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e4a1741f5f477ca53154878325f54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=3, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d6181e0aaf461f9f1cc9e7d061f4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=25000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a353955524a485993248c1f83b4481d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=25000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd40e6c7d0d407fa1973dc0ed059ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=25000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x421b1780>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(data, df.iloc[:, 1], epochs = 3, verbose = 0, callbacks = [TQDMNotebookCallback(leave_inner = True, leave_outer = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T22:19:01.962656Z",
     "start_time": "2018-11-16T22:19:00.770656Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('Model-06.p5.CNN-1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make predictons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T23:00:40.927798Z",
     "start_time": "2018-11-16T23:00:39.938502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testDF.shape : (25000, 2)\n",
      "\n",
      "         id                                             review\n",
      "0  12311_10  \"Naturally in a film who's main themes are of ...\n",
      "1    8348_2  \"This movie is a disaster within a disaster fi...\n",
      "2    5828_4  \"All in all, this is a movie for kids. We saw ...\n",
      "3    7186_2  \"Afraid of the Dark left me with the impressio...\n",
      "4   12128_7  \"A very accurate depiction of small time mob l...\n"
     ]
    }
   ],
   "source": [
    "# Pull in the labeled data\n",
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "testData = os.path.join(dataPath, 'testData.tsv')\n",
    "\n",
    "testDF = pd.read_csv(testData, sep = '\\t', header = 0, quoting = 3)\n",
    "testDF['id'] = testDF['id'].str.replace('\"', '')\n",
    "\n",
    "# Sanity check\n",
    "print('testDF.shape :', testDF.shape)\n",
    "print(\"\")\n",
    "print(testDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T23:01:22.261195Z",
     "start_time": "2018-11-16T23:00:40.929799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naturally',\n",
       " 'film',\n",
       " 'main',\n",
       " 'themes',\n",
       " 'mortality',\n",
       " 'nostalgia',\n",
       " 'loss',\n",
       " 'innocence',\n",
       " 'perhaps',\n",
       " 'surprising']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the test data\n",
    "cleanTest = []\n",
    "\n",
    "# Clean the reviews\n",
    "for i, s in enumerate(testDF.iloc[:,1]):\n",
    "    cleanTest.append(cleanReview(s, True))\n",
    "    \n",
    "# Examine a portion of the first clean review\n",
    "cleanTest[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T23:02:04.142755Z",
     "start_time": "2018-11-16T23:01:22.263195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Create test data sequences for use by the Keras CNN model\n",
    "sequences = tokenizer.texts_to_sequences(cleanTest)\n",
    "data = pad_sequences(sequences, maxlen = seqLength, padding = \"post\")\n",
    "\n",
    "ynew = m.predict_classes(data)\n",
    "print(ynew[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T23:02:04.753939Z",
     "start_time": "2018-11-16T23:02:04.144756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  sentiment\n",
       "0  12311_10  \"Naturally in a film who's main themes are of ...          1\n",
       "1    8348_2  \"This movie is a disaster within a disaster fi...          0\n",
       "2    5828_4  \"All in all, this is a movie for kids. We saw ...          0\n",
       "3    7186_2  \"Afraid of the Dark left me with the impressio...          1\n",
       "4   12128_7  \"A very accurate depiction of small time mob l...          1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the predictions to the test data frame\n",
    "testDF['sentiment'] = ynew\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T23:02:05.385128Z",
     "start_time": "2018-11-16T23:02:04.755939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Kaggle submission file\n",
    "import csv\n",
    "header = ['id', 'sentiment']\n",
    "testDF.to_csv('submission.csv', columns = header, index = False, quoting = csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of Doc2Vec TaggedDocument objects\n",
    "\n",
    "Next we need to create a collection of `TaggedDocument` objects; one object for each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:49:24.978259Z",
     "start_time": "2018-11-08T16:48:49.531079Z"
    }
   },
   "outputs": [],
   "source": [
    "taggedDocs = []\n",
    "\n",
    "for i, s in enumerate(df.iloc[:,2]):\n",
    "    clean = cleanReview(s)\n",
    "    taggedDocs.append(TaggedDocument(clean, [i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:49:25.373251Z",
     "start_time": "2018-11-08T16:49:24.978259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check we have the same number of objects as reviews\n",
    "len(taggedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:49:25.851251Z",
     "start_time": "2018-11-08T16:49:25.375251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['with', 'all', 'this', 'stuff', 'going', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'started', 'listening', 'to', 'his', 'music', 'watching', 'the', 'odd', 'documentary', 'here', 'and', 'there', 'watched', 'the', 'wiz', 'and', 'watched', 'moonwalker', 'again', 'maybe', 'i', 'just', 'want', 'to', 'get', 'a', 'certain', 'insight', 'into', 'this', 'guy', 'who', 'i', 'thought', 'was', 'really', 'cool', 'in', 'the', 'eighties', 'just', 'to', 'maybe', 'make', 'up', 'my', 'mind', 'whether', 'he', 'is', 'guilty', 'or', 'innocent', 'moonwalker', 'is', 'part', 'biography', 'part', 'feature', 'film', 'which', 'i', 'remember', 'going', 'to', 'see', 'at', 'the', 'cinema', 'when', 'it', 'was', 'originally', 'released', 'some', 'of', 'it', 'has', 'subtle', 'messages', 'about', 'mj', 's', 'feeling', 'towards', 'the', 'press', 'and', 'also', 'the', 'obvious', 'message', 'of', 'drugs', 'are', 'bad', 'm', 'kay', 'visually', 'impressive', 'but', 'of', 'course', 'this', 'is', 'all', 'about', 'michael', 'jackson', 'so', 'unless', 'you', 'remotely', 'like', 'mj', 'in', 'anyway', 'then', 'you', 'are', 'going', 'to', 'hate', 'this', 'and', 'find', 'it', 'boring', 'some', 'may', 'call', 'mj', 'an', 'egotist', 'for', 'consenting', 'to', 'the', 'making', 'of', 'this', 'movie', 'but', 'mj', 'and', 'most', 'of', 'his', 'fans', 'would', 'say', 'that', 'he', 'made', 'it', 'for', 'the', 'fans', 'which', 'if', 'true', 'is', 'really', 'nice', 'of', 'him', 'the', 'actual', 'feature', 'film', 'bit', 'when', 'it', 'finally', 'starts', 'is', 'only', 'on', 'for', 'minutes', 'or', 'so', 'excluding', 'the', 'smooth', 'criminal', 'sequence', 'and', 'joe', 'pesci', 'is', 'convincing', 'as', 'a', 'psychopathic', 'all', 'powerful', 'drug', 'lord', 'why', 'he', 'wants', 'mj', 'dead', 'so', 'bad', 'is', 'beyond', 'me', 'because', 'mj', 'overheard', 'his', 'plans', 'nah', 'joe', 'pesci', 's', 'character', 'ranted', 'that', 'he', 'wanted', 'people', 'to', 'know', 'it', 'is', 'he', 'who', 'is', 'supplying', 'drugs', 'etc', 'so', 'i', 'dunno', 'maybe', 'he', 'just', 'hates', 'mj', 's', 'music', 'lots', 'of', 'cool', 'things', 'in', 'this', 'like', 'mj', 'turning', 'into', 'a', 'car', 'and', 'a', 'robot', 'and', 'the', 'whole', 'speed', 'demon', 'sequence', 'also', 'the', 'director', 'must', 'have', 'had', 'the', 'patience', 'of', 'a', 'saint', 'when', 'it', 'came', 'to', 'filming', 'the', 'kiddy', 'bad', 'sequence', 'as', 'usually', 'directors', 'hate', 'working', 'with', 'one', 'kid', 'let', 'alone', 'a', 'whole', 'bunch', 'of', 'them', 'performing', 'a', 'complex', 'dance', 'scene', 'bottom', 'line', 'this', 'movie', 'is', 'for', 'people', 'who', 'like', 'mj', 'on', 'one', 'level', 'or', 'another', 'which', 'i', 'think', 'is', 'most', 'people', 'if', 'not', 'then', 'stay', 'away', 'it', 'does', 'try', 'and', 'give', 'off', 'a', 'wholesome', 'message', 'and', 'ironically', 'mj', 's', 'bestest', 'buddy', 'in', 'this', 'movie', 'is', 'a', 'girl', 'michael', 'jackson', 'is', 'truly', 'one', 'of', 'the', 'most', 'talented', 'people', 'ever', 'to', 'grace', 'this', 'planet', 'but', 'is', 'he', 'guilty', 'well', 'with', 'all', 'the', 'attention', 'i', 've', 'gave', 'this', 'subject', 'hmmm', 'well', 'i', 'don', 't', 'know', 'because', 'people', 'can', 'be', 'different', 'behind', 'closed', 'doors', 'i', 'know', 'this', 'for', 'a', 'fact', 'he', 'is', 'either', 'an', 'extremely', 'nice', 'but', 'stupid', 'guy', 'or', 'one', 'of', 'the', 'most', 'sickest', 'liars', 'i', 'hope', 'he', 'is', 'not', 'the', 'latter'], tags=[0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine an example:\n",
    "taggedDocs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec model - Initial pass\n",
    "\n",
    "We are now ready to train the Doc2Vec model.  The process will go something like this:\n",
    "1. Define the Doc2Vec model object\n",
    "2. Build vocabulary from a sequence of sentences (i.e. our reviews)\n",
    "3. Train the Doc2Vec model (Doc2Vec uses a inner shallow neural network used to train the embeddings)\n",
    "4. Create a feature set utilizing the trained Doc2Vec model\n",
    "5. Pass the feature set to the Scikit-learn models for training and evaluation\n",
    "\n",
    "So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Doc2Vec model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:49:26.295251Z",
     "start_time": "2018-11-08T16:49:25.852251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 09:49:26,290 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel = Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary from a sequence of sentences (i.e. our reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:49:28.791835Z",
     "start_time": "2018-11-08T16:49:26.297251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 09:49:26,739 : INFO : collecting all words and their counts\n",
      "2018-11-08 09:49:26,741 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-08 09:49:27,153 : INFO : PROGRESS: at example #10000, processed 2385574 words (5824898/s), 51527 word types, 10000 tags\n",
      "2018-11-08 09:49:27,556 : INFO : PROGRESS: at example #20000, processed 4747503 words (6166701/s), 67813 word types, 20000 tags\n",
      "2018-11-08 09:49:27,750 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-08 09:49:27,751 : INFO : Loading a fresh vocabulary\n",
      "2018-11-08 09:49:27,856 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-08 09:49:27,856 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-08 09:49:27,964 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-08 09:49:27,967 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-08 09:49:27,969 : INFO : downsampling leaves estimated 4416048 word corpus (74.9% of prior 5892845)\n",
      "2018-11-08 09:49:28,114 : INFO : estimated required memory for 46350 words and 50 dimensions: 46715000 bytes\n",
      "2018-11-08 09:49:28,115 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel.build_vocab(taggedDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:52:21.326871Z",
     "start_time": "2018-11-08T16:49:28.794835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 09:49:29,219 : INFO : training model with 3 workers on 46350 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 09:49:30,226 : INFO : EPOCH 1 - PROGRESS: at 23.21% examples, 1044966 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:31,228 : INFO : EPOCH 1 - PROGRESS: at 46.67% examples, 1041765 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:32,261 : INFO : EPOCH 1 - PROGRESS: at 69.90% examples, 1037868 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:33,252 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 1052702 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:33,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:33,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:33,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:33,471 : INFO : EPOCH - 1 : training on 5920713 raw words (4441728 effective words) took 4.2s, 1051443 effective words/s\n",
      "2018-11-08 09:49:34,457 : INFO : EPOCH 2 - PROGRESS: at 23.02% examples, 1035410 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:35,493 : INFO : EPOCH 2 - PROGRESS: at 47.50% examples, 1053423 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:36,496 : INFO : EPOCH 2 - PROGRESS: at 70.78% examples, 1046233 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:37,502 : INFO : EPOCH 2 - PROGRESS: at 95.79% examples, 1057009 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:37,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:37,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:37,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:37,671 : INFO : EPOCH - 2 : training on 5920713 raw words (4441832 effective words) took 4.2s, 1057498 effective words/s\n",
      "2018-11-08 09:49:38,681 : INFO : EPOCH 3 - PROGRESS: at 24.68% examples, 1104757 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:39,685 : INFO : EPOCH 3 - PROGRESS: at 48.90% examples, 1093311 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:40,682 : INFO : EPOCH 3 - PROGRESS: at 72.41% examples, 1076732 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:41,698 : INFO : EPOCH 3 - PROGRESS: at 96.94% examples, 1074774 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:41,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:41,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:41,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:41,822 : INFO : EPOCH - 3 : training on 5920713 raw words (4440899 effective words) took 4.1s, 1073904 effective words/s\n",
      "2018-11-08 09:49:42,829 : INFO : EPOCH 4 - PROGRESS: at 24.85% examples, 1112567 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:43,837 : INFO : EPOCH 4 - PROGRESS: at 49.37% examples, 1098751 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:44,825 : INFO : EPOCH 4 - PROGRESS: at 73.70% examples, 1092507 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:45,843 : INFO : EPOCH 4 - PROGRESS: at 97.78% examples, 1081951 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:45,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:45,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:45,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:45,936 : INFO : EPOCH - 4 : training on 5920713 raw words (4440228 effective words) took 4.1s, 1080408 effective words/s\n",
      "2018-11-08 09:49:46,945 : INFO : EPOCH 5 - PROGRESS: at 23.60% examples, 1057252 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:47,956 : INFO : EPOCH 5 - PROGRESS: at 48.11% examples, 1068692 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:48,952 : INFO : EPOCH 5 - PROGRESS: at 72.11% examples, 1067378 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:49,961 : INFO : EPOCH 5 - PROGRESS: at 96.44% examples, 1065865 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:50,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:50,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:50,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:50,102 : INFO : EPOCH - 5 : training on 5920713 raw words (4442209 effective words) took 4.2s, 1066087 effective words/s\n",
      "2018-11-08 09:49:51,115 : INFO : EPOCH 6 - PROGRESS: at 23.82% examples, 1063949 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:52,097 : INFO : EPOCH 6 - PROGRESS: at 47.00% examples, 1045850 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:53,107 : INFO : EPOCH 6 - PROGRESS: at 70.25% examples, 1039553 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:54,112 : INFO : EPOCH 6 - PROGRESS: at 93.50% examples, 1032764 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:54,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:54,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:54,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:54,396 : INFO : EPOCH - 6 : training on 5920713 raw words (4441626 effective words) took 4.3s, 1030814 effective words/s\n",
      "2018-11-08 09:49:55,417 : INFO : EPOCH 7 - PROGRESS: at 22.90% examples, 1031085 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:56,409 : INFO : EPOCH 7 - PROGRESS: at 46.50% examples, 1034706 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:57,411 : INFO : EPOCH 7 - PROGRESS: at 68.66% examples, 1018071 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:49:58,437 : INFO : EPOCH 7 - PROGRESS: at 91.35% examples, 1013208 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:49:58,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:49:58,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:49:58,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:49:58,791 : INFO : EPOCH - 7 : training on 5920713 raw words (4440778 effective words) took 4.4s, 1017475 effective words/s\n",
      "2018-11-08 09:49:59,785 : INFO : EPOCH 8 - PROGRESS: at 23.60% examples, 1044402 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:00,791 : INFO : EPOCH 8 - PROGRESS: at 47.15% examples, 1043194 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:01,797 : INFO : EPOCH 8 - PROGRESS: at 70.40% examples, 1038985 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:02,798 : INFO : EPOCH 8 - PROGRESS: at 93.85% examples, 1035934 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-08 09:50:03,043 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:03,045 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:03,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:03,048 : INFO : EPOCH - 8 : training on 5920713 raw words (4442270 effective words) took 4.3s, 1038228 effective words/s\n",
      "2018-11-08 09:50:04,083 : INFO : EPOCH 9 - PROGRESS: at 23.21% examples, 1036395 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:05,071 : INFO : EPOCH 9 - PROGRESS: at 46.82% examples, 1038075 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:06,077 : INFO : EPOCH 9 - PROGRESS: at 69.90% examples, 1033290 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-08 09:50:07,080 : INFO : EPOCH 9 - PROGRESS: at 91.71% examples, 1014125 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:07,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:07,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:07,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:07,441 : INFO : EPOCH - 9 : training on 5920713 raw words (4440186 effective words) took 4.4s, 1012167 effective words/s\n",
      "2018-11-08 09:50:08,447 : INFO : EPOCH 10 - PROGRESS: at 23.21% examples, 1046011 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:09,451 : INFO : EPOCH 10 - PROGRESS: at 45.80% examples, 1022626 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:10,459 : INFO : EPOCH 10 - PROGRESS: at 69.44% examples, 1030258 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:11,461 : INFO : EPOCH 10 - PROGRESS: at 92.94% examples, 1030141 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:11,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:11,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:11,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:11,765 : INFO : EPOCH - 10 : training on 5920713 raw words (4441203 effective words) took 4.3s, 1028532 effective words/s\n",
      "2018-11-08 09:50:12,779 : INFO : EPOCH 11 - PROGRESS: at 23.02% examples, 1029649 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:13,784 : INFO : EPOCH 11 - PROGRESS: at 45.80% examples, 1017871 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:14,794 : INFO : EPOCH 11 - PROGRESS: at 69.44% examples, 1025898 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:15,805 : INFO : EPOCH 11 - PROGRESS: at 93.67% examples, 1032168 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:16,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:16,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:16,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:16,075 : INFO : EPOCH - 11 : training on 5920713 raw words (4440770 effective words) took 4.3s, 1031784 effective words/s\n",
      "2018-11-08 09:50:17,087 : INFO : EPOCH 12 - PROGRESS: at 23.60% examples, 1056349 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:18,092 : INFO : EPOCH 12 - PROGRESS: at 46.66% examples, 1037945 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:19,109 : INFO : EPOCH 12 - PROGRESS: at 69.30% examples, 1027976 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:20,108 : INFO : EPOCH 12 - PROGRESS: at 93.67% examples, 1034304 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:20,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:20,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:20,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:20,374 : INFO : EPOCH - 12 : training on 5920713 raw words (4440307 effective words) took 4.3s, 1034515 effective words/s\n",
      "2018-11-08 09:50:21,402 : INFO : EPOCH 13 - PROGRESS: at 24.83% examples, 1112255 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:22,406 : INFO : EPOCH 13 - PROGRESS: at 49.52% examples, 1108212 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:23,403 : INFO : EPOCH 13 - PROGRESS: at 74.40% examples, 1105673 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:24,405 : INFO : EPOCH 13 - PROGRESS: at 99.36% examples, 1101789 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-08 09:50:24,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:24,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:24,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:24,437 : INFO : EPOCH - 13 : training on 5920713 raw words (4442067 effective words) took 4.0s, 1099252 effective words/s\n",
      "2018-11-08 09:50:25,446 : INFO : EPOCH 14 - PROGRESS: at 24.85% examples, 1107204 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:26,451 : INFO : EPOCH 14 - PROGRESS: at 49.52% examples, 1105229 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:27,463 : INFO : EPOCH 14 - PROGRESS: at 74.57% examples, 1104463 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:28,465 : INFO : EPOCH 14 - PROGRESS: at 99.55% examples, 1100610 words/s, in_qsize 3, out_qsize 0\n",
      "2018-11-08 09:50:28,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:28,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:28,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:28,481 : INFO : EPOCH - 14 : training on 5920713 raw words (4440251 effective words) took 4.0s, 1100242 effective words/s\n",
      "2018-11-08 09:50:29,488 : INFO : EPOCH 15 - PROGRESS: at 24.85% examples, 1110242 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:30,497 : INFO : EPOCH 15 - PROGRESS: at 49.85% examples, 1111114 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:31,501 : INFO : EPOCH 15 - PROGRESS: at 73.13% examples, 1082836 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:32,497 : INFO : EPOCH 15 - PROGRESS: at 97.45% examples, 1078910 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:32,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:32,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:32,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:32,606 : INFO : EPOCH - 15 : training on 5920713 raw words (4440032 effective words) took 4.1s, 1077978 effective words/s\n",
      "2018-11-08 09:50:33,607 : INFO : EPOCH 16 - PROGRESS: at 25.01% examples, 1113203 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:34,596 : INFO : EPOCH 16 - PROGRESS: at 49.69% examples, 1108496 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:35,598 : INFO : EPOCH 16 - PROGRESS: at 74.40% examples, 1104179 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:36,606 : INFO : EPOCH 16 - PROGRESS: at 99.64% examples, 1101590 words/s, in_qsize 2, out_qsize 1\n",
      "2018-11-08 09:50:36,609 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:36,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:36,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:36,614 : INFO : EPOCH - 16 : training on 5920713 raw words (4440571 effective words) took 4.0s, 1103018 effective words/s\n",
      "2018-11-08 09:50:37,623 : INFO : EPOCH 17 - PROGRESS: at 24.85% examples, 1110695 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:38,658 : INFO : EPOCH 17 - PROGRESS: at 49.69% examples, 1106630 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:39,649 : INFO : EPOCH 17 - PROGRESS: at 74.57% examples, 1104829 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:40,669 : INFO : EPOCH 17 - PROGRESS: at 99.73% examples, 1102158 words/s, in_qsize 2, out_qsize 1\n",
      "2018-11-08 09:50:40,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:40,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:40,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:40,669 : INFO : EPOCH - 17 : training on 5920713 raw words (4442393 effective words) took 4.0s, 1101831 effective words/s\n",
      "2018-11-08 09:50:41,682 : INFO : EPOCH 18 - PROGRESS: at 24.68% examples, 1103775 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:42,682 : INFO : EPOCH 18 - PROGRESS: at 49.22% examples, 1098158 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:43,685 : INFO : EPOCH 18 - PROGRESS: at 73.88% examples, 1095744 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:44,701 : INFO : EPOCH 18 - PROGRESS: at 98.47% examples, 1090407 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:44,748 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:44,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:44,748 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:44,763 : INFO : EPOCH - 18 : training on 5920713 raw words (4441563 effective words) took 4.1s, 1089554 effective words/s\n",
      "2018-11-08 09:50:45,754 : INFO : EPOCH 19 - PROGRESS: at 23.40% examples, 1038401 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:46,762 : INFO : EPOCH 19 - PROGRESS: at 47.00% examples, 1039250 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:47,768 : INFO : EPOCH 19 - PROGRESS: at 68.96% examples, 1017346 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:48,779 : INFO : EPOCH 19 - PROGRESS: at 91.53% examples, 1008928 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:49,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 09:50:49,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:49,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:49,148 : INFO : EPOCH - 19 : training on 5920713 raw words (4439618 effective words) took 4.4s, 1007323 effective words/s\n",
      "2018-11-08 09:50:50,155 : INFO : EPOCH 20 - PROGRESS: at 21.34% examples, 965084 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:51,157 : INFO : EPOCH 20 - PROGRESS: at 43.44% examples, 972487 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:52,183 : INFO : EPOCH 20 - PROGRESS: at 66.02% examples, 982439 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:53,184 : INFO : EPOCH 20 - PROGRESS: at 91.01% examples, 1012528 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:53,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:53,543 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:53,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:53,543 : INFO : EPOCH - 20 : training on 5920713 raw words (4442357 effective words) took 4.4s, 1016600 effective words/s\n",
      "2018-11-08 09:50:54,562 : INFO : EPOCH 21 - PROGRESS: at 25.17% examples, 1113914 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:55,570 : INFO : EPOCH 21 - PROGRESS: at 50.01% examples, 1111366 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:56,571 : INFO : EPOCH 21 - PROGRESS: at 75.05% examples, 1109894 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:50:57,573 : INFO : EPOCH 21 - PROGRESS: at 99.55% examples, 1099368 words/s, in_qsize 3, out_qsize 0\n",
      "2018-11-08 09:50:57,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:50:57,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:50:57,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:50:57,589 : INFO : EPOCH - 21 : training on 5920713 raw words (4440389 effective words) took 4.0s, 1099029 effective words/s\n",
      "2018-11-08 09:50:58,576 : INFO : EPOCH 22 - PROGRESS: at 23.40% examples, 1052182 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:50:59,594 : INFO : EPOCH 22 - PROGRESS: at 46.97% examples, 1040261 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:00,634 : INFO : EPOCH 22 - PROGRESS: at 70.92% examples, 1045071 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:01,606 : INFO : EPOCH 22 - PROGRESS: at 94.30% examples, 1040555 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:01,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:01,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:01,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:01,856 : INFO : EPOCH - 22 : training on 5920713 raw words (4442308 effective words) took 4.3s, 1042563 effective words/s\n",
      "2018-11-08 09:51:02,841 : INFO : EPOCH 23 - PROGRESS: at 23.60% examples, 1060734 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:03,845 : INFO : EPOCH 23 - PROGRESS: at 46.16% examples, 1029774 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:04,847 : INFO : EPOCH 23 - PROGRESS: at 69.59% examples, 1034196 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:05,848 : INFO : EPOCH 23 - PROGRESS: at 92.76% examples, 1029704 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:06,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:06,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:06,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:06,159 : INFO : EPOCH - 23 : training on 5920713 raw words (4440810 effective words) took 4.3s, 1028293 effective words/s\n",
      "2018-11-08 09:51:07,164 : INFO : EPOCH 24 - PROGRESS: at 23.02% examples, 1038555 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:08,178 : INFO : EPOCH 24 - PROGRESS: at 46.16% examples, 1027960 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:09,182 : INFO : EPOCH 24 - PROGRESS: at 70.40% examples, 1042420 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-08 09:51:10,190 : INFO : EPOCH 24 - PROGRESS: at 92.24% examples, 1019675 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:10,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:10,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:10,546 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:10,549 : INFO : EPOCH - 24 : training on 5920713 raw words (4442450 effective words) took 4.4s, 1012801 effective words/s\n",
      "2018-11-08 09:51:11,559 : INFO : EPOCH 25 - PROGRESS: at 21.80% examples, 984012 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:12,570 : INFO : EPOCH 25 - PROGRESS: at 44.68% examples, 992015 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:13,593 : INFO : EPOCH 25 - PROGRESS: at 66.48% examples, 984601 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:14,597 : INFO : EPOCH 25 - PROGRESS: at 90.34% examples, 1000783 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:14,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:14,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:14,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:14,984 : INFO : EPOCH - 25 : training on 5920713 raw words (4440849 effective words) took 4.4s, 1006980 effective words/s\n",
      "2018-11-08 09:51:16,001 : INFO : EPOCH 26 - PROGRESS: at 23.99% examples, 1060014 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:17,018 : INFO : EPOCH 26 - PROGRESS: at 48.77% examples, 1079116 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:18,019 : INFO : EPOCH 26 - PROGRESS: at 73.41% examples, 1082513 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:19,022 : INFO : EPOCH 26 - PROGRESS: at 98.47% examples, 1084479 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:19,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:19,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:19,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:19,085 : INFO : EPOCH - 26 : training on 5920713 raw words (4440967 effective words) took 4.1s, 1083741 effective words/s\n",
      "2018-11-08 09:51:20,103 : INFO : EPOCH 27 - PROGRESS: at 24.83% examples, 1111048 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:21,106 : INFO : EPOCH 27 - PROGRESS: at 48.90% examples, 1092534 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:22,109 : INFO : EPOCH 27 - PROGRESS: at 73.70% examples, 1095480 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:23,089 : INFO : EPOCH 27 - PROGRESS: at 98.85% examples, 1094292 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:23,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:23,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:23,158 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:23,158 : INFO : EPOCH - 27 : training on 5920713 raw words (4441792 effective words) took 4.1s, 1092834 effective words/s\n",
      "2018-11-08 09:51:24,177 : INFO : EPOCH 28 - PROGRESS: at 24.68% examples, 1093204 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:25,166 : INFO : EPOCH 28 - PROGRESS: at 49.37% examples, 1093077 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:26,183 : INFO : EPOCH 28 - PROGRESS: at 74.26% examples, 1096297 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:27,184 : INFO : EPOCH 28 - PROGRESS: at 99.04% examples, 1092681 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:27,231 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:27,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:27,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:27,231 : INFO : EPOCH - 28 : training on 5920713 raw words (4439915 effective words) took 4.1s, 1091834 effective words/s\n",
      "2018-11-08 09:51:28,239 : INFO : EPOCH 29 - PROGRESS: at 24.85% examples, 1111440 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:29,237 : INFO : EPOCH 29 - PROGRESS: at 49.37% examples, 1104301 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:30,243 : INFO : EPOCH 29 - PROGRESS: at 74.40% examples, 1102664 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:31,258 : INFO : EPOCH 29 - PROGRESS: at 98.67% examples, 1091646 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:31,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:31,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:31,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:31,305 : INFO : EPOCH - 29 : training on 5920713 raw words (4441553 effective words) took 4.1s, 1091091 effective words/s\n",
      "2018-11-08 09:51:32,321 : INFO : EPOCH 30 - PROGRESS: at 25.17% examples, 1118910 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:33,324 : INFO : EPOCH 30 - PROGRESS: at 49.69% examples, 1108245 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:34,326 : INFO : EPOCH 30 - PROGRESS: at 74.40% examples, 1102301 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:35,329 : INFO : EPOCH 30 - PROGRESS: at 98.67% examples, 1090969 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:35,376 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:35,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:35,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:35,391 : INFO : EPOCH - 30 : training on 5920713 raw words (4441374 effective words) took 4.1s, 1089134 effective words/s\n",
      "2018-11-08 09:51:36,394 : INFO : EPOCH 31 - PROGRESS: at 23.02% examples, 1032981 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:37,397 : INFO : EPOCH 31 - PROGRESS: at 47.00% examples, 1047289 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:38,386 : INFO : EPOCH 31 - PROGRESS: at 68.96% examples, 1022314 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:39,392 : INFO : EPOCH 31 - PROGRESS: at 91.53% examples, 1014229 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:39,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:39,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:39,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:39,893 : INFO : EPOCH - 31 : training on 5920713 raw words (4440844 effective words) took 4.5s, 982472 effective words/s\n",
      "2018-11-08 09:51:40,917 : INFO : EPOCH 32 - PROGRESS: at 18.10% examples, 805814 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:41,920 : INFO : EPOCH 32 - PROGRESS: at 36.88% examples, 821702 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:42,924 : INFO : EPOCH 32 - PROGRESS: at 55.83% examples, 828583 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:43,924 : INFO : EPOCH 32 - PROGRESS: at 69.91% examples, 776412 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:44,926 : INFO : EPOCH 32 - PROGRESS: at 84.12% examples, 746279 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:45,932 : INFO : EPOCH 32 - PROGRESS: at 99.55% examples, 732973 words/s, in_qsize 3, out_qsize 0\n",
      "2018-11-08 09:51:45,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:45,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:45,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:45,953 : INFO : EPOCH - 32 : training on 5920713 raw words (4439816 effective words) took 6.1s, 733679 effective words/s\n",
      "2018-11-08 09:51:46,965 : INFO : EPOCH 33 - PROGRESS: at 22.50% examples, 1009809 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:47,965 : INFO : EPOCH 33 - PROGRESS: at 45.04% examples, 1002874 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:48,965 : INFO : EPOCH 33 - PROGRESS: at 67.85% examples, 1007698 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:49,975 : INFO : EPOCH 33 - PROGRESS: at 89.84% examples, 996525 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:50,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:50,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:50,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:50,434 : INFO : EPOCH - 33 : training on 5920713 raw words (4441674 effective words) took 4.5s, 992468 effective words/s\n",
      "2018-11-08 09:51:51,444 : INFO : EPOCH 34 - PROGRESS: at 22.71% examples, 1018657 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:52,447 : INFO : EPOCH 34 - PROGRESS: at 45.31% examples, 1009709 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:53,449 : INFO : EPOCH 34 - PROGRESS: at 67.68% examples, 1004052 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:54,456 : INFO : EPOCH 34 - PROGRESS: at 90.50% examples, 1003826 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:54,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:54,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:54,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:54,878 : INFO : EPOCH - 34 : training on 5920713 raw words (4441549 effective words) took 4.4s, 1000631 effective words/s\n",
      "2018-11-08 09:51:55,885 : INFO : EPOCH 35 - PROGRESS: at 22.90% examples, 1029362 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:51:56,892 : INFO : EPOCH 35 - PROGRESS: at 45.97% examples, 1023967 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:57,899 : INFO : EPOCH 35 - PROGRESS: at 68.01% examples, 1006741 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:58,903 : INFO : EPOCH 35 - PROGRESS: at 90.34% examples, 1000816 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:51:59,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:51:59,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:51:59,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:51:59,332 : INFO : EPOCH - 35 : training on 5920713 raw words (4440442 effective words) took 4.4s, 997925 effective words/s\n",
      "2018-11-08 09:52:00,339 : INFO : EPOCH 36 - PROGRESS: at 21.80% examples, 985252 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:01,346 : INFO : EPOCH 36 - PROGRESS: at 44.68% examples, 994960 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:02,356 : INFO : EPOCH 36 - PROGRESS: at 67.85% examples, 1003494 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:03,357 : INFO : EPOCH 36 - PROGRESS: at 90.83% examples, 1006706 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:03,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:52:03,747 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:52:03,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:52:03,751 : INFO : EPOCH - 36 : training on 5920713 raw words (4440874 effective words) took 4.4s, 1006315 effective words/s\n",
      "2018-11-08 09:52:04,767 : INFO : EPOCH 37 - PROGRESS: at 22.33% examples, 998467 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:05,767 : INFO : EPOCH 37 - PROGRESS: at 44.68% examples, 993634 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:06,777 : INFO : EPOCH 37 - PROGRESS: at 64.58% examples, 953733 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:07,781 : INFO : EPOCH 37 - PROGRESS: at 87.67% examples, 972362 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:08,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:52:08,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:52:08,299 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:52:08,301 : INFO : EPOCH - 37 : training on 5920713 raw words (4441087 effective words) took 4.5s, 977107 effective words/s\n",
      "2018-11-08 09:52:09,315 : INFO : EPOCH 38 - PROGRESS: at 23.60% examples, 1050401 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 09:52:10,321 : INFO : EPOCH 38 - PROGRESS: at 46.50% examples, 1031317 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:11,333 : INFO : EPOCH 38 - PROGRESS: at 69.73% examples, 1029420 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:12,336 : INFO : EPOCH 38 - PROGRESS: at 92.76% examples, 1023864 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:12,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:52:12,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:52:12,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:52:12,637 : INFO : EPOCH - 38 : training on 5920713 raw words (4440659 effective words) took 4.3s, 1025080 effective words/s\n",
      "2018-11-08 09:52:13,644 : INFO : EPOCH 39 - PROGRESS: at 21.80% examples, 986072 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:14,647 : INFO : EPOCH 39 - PROGRESS: at 43.44% examples, 971084 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:15,656 : INFO : EPOCH 39 - PROGRESS: at 66.48% examples, 985550 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:16,657 : INFO : EPOCH 39 - PROGRESS: at 89.68% examples, 995077 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:17,075 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:52:17,077 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:52:17,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:52:17,087 : INFO : EPOCH - 39 : training on 5920713 raw words (4440317 effective words) took 4.4s, 999066 effective words/s\n",
      "2018-11-08 09:52:18,092 : INFO : EPOCH 40 - PROGRESS: at 23.60% examples, 1060886 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:19,103 : INFO : EPOCH 40 - PROGRESS: at 47.00% examples, 1044722 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:20,109 : INFO : EPOCH 40 - PROGRESS: at 70.92% examples, 1049827 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 09:52:21,116 : INFO : EPOCH 40 - PROGRESS: at 95.13% examples, 1051265 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 09:52:21,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 09:52:21,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 09:52:21,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 09:52:21,320 : INFO : EPOCH - 40 : training on 5920713 raw words (4439946 effective words) took 4.2s, 1050072 effective words/s\n",
      "2018-11-08 09:52:21,322 : INFO : training on a 236828520 raw words (177642503 effective words) took 172.1s, 1032204 effective words/s\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick visual inspection of the document vector created by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:52:21.761871Z",
     "start_time": "2018-11-08T16:52:21.328871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5997561e-01,  1.7838972e+00, -6.1637288e-01,  2.4644056e-01,\n",
       "       -1.2331752e+00,  5.8049954e-02,  1.7367197e+00, -5.5887252e-01,\n",
       "        1.6684380e+00,  7.2999865e-01, -3.6999774e+00,  5.2697855e-01,\n",
       "        1.2054617e+00,  1.9833222e-01, -1.1332304e-01,  2.9486263e-01,\n",
       "        1.2692857e+00, -1.5175811e+00,  1.7063432e+00, -3.0820298e-01,\n",
       "        9.1671062e-01, -5.5909568e-01,  2.7152622e-01,  3.2423854e-01,\n",
       "       -6.7020398e-01, -8.5734850e-01,  2.0997808e+00, -3.0700572e+00,\n",
       "        2.6324701e+00,  7.0944178e-01,  6.1826450e-01, -1.8692477e+00,\n",
       "       -1.3357389e+00,  1.2652332e-01,  1.0606683e+00,  1.5548224e+00,\n",
       "       -1.2767829e+00, -5.1909101e-01,  1.5628880e-03, -1.0368673e+00,\n",
       "        9.4668019e-01, -1.3571483e+00, -3.5316312e-01, -2.6158001e+00,\n",
       "        6.3104153e-01,  5.3967124e-01, -1.1993488e+00, -3.6817062e-01,\n",
       "       -9.6663392e-01,  4.8223326e-01], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vecModel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a feature set utilizing the trained Doc2Vec model\n",
    "\n",
    "The `docvecs` property of the Doc2Vec model contains the calculated vectors for each document.  Since they are numerical arrays in essence we can treat these as our training data and pass them to Scikit-learn models.  Let's do some inspections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:52:22.191871Z",
     "start_time": "2018-11-08T16:52:21.763871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vecModel.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:52:22.621871Z",
     "start_time": "2018-11-08T16:52:22.193871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5997561e-01,  1.7838972e+00, -6.1637288e-01,  2.4644056e-01,\n",
       "       -1.2331752e+00,  5.8049954e-02,  1.7367197e+00, -5.5887252e-01,\n",
       "        1.6684380e+00,  7.2999865e-01, -3.6999774e+00,  5.2697855e-01,\n",
       "        1.2054617e+00,  1.9833222e-01, -1.1332304e-01,  2.9486263e-01,\n",
       "        1.2692857e+00, -1.5175811e+00,  1.7063432e+00, -3.0820298e-01,\n",
       "        9.1671062e-01, -5.5909568e-01,  2.7152622e-01,  3.2423854e-01,\n",
       "       -6.7020398e-01, -8.5734850e-01,  2.0997808e+00, -3.0700572e+00,\n",
       "        2.6324701e+00,  7.0944178e-01,  6.1826450e-01, -1.8692477e+00,\n",
       "       -1.3357389e+00,  1.2652332e-01,  1.0606683e+00,  1.5548224e+00,\n",
       "       -1.2767829e+00, -5.1909101e-01,  1.5628880e-03, -1.0368673e+00,\n",
       "        9.4668019e-01, -1.3571483e+00, -3.5316312e-01, -2.6158001e+00,\n",
       "        6.3104153e-01,  5.3967124e-01, -1.1993488e+00, -3.6817062e-01,\n",
       "       -9.6663392e-01,  4.8223326e-01], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vecModel.docvecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass the feature set to the Scikit-learn models for training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle model\n",
    "\n",
    "First we'll evalute the Kaggle model.  Notice how we assign the `docvec` values to the variable `xTrain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:54:37.319871Z",
     "start_time": "2018-11-08T16:52:22.622871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.81464</td>\n",
       "      <td>0.008312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy    StdDev\n",
       "0  RandomForestClassifier   0.81464  0.008312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init vars and params\n",
    "eFolds = 10\n",
    "eSeed = 10\n",
    "\n",
    "# Use accuracy since this is a classification problem\n",
    "eScore = 'accuracy'\n",
    "\n",
    "modelName = 'RandomForestClassifier'\n",
    "RandomForestClassifier(n_estimators = 100)\n",
    "xTrain = doc2vecModel.docvecs\n",
    "yTrain = df.iloc[:, 1]\n",
    "\n",
    "_DF = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "_Results = {}\n",
    "_model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "kFold = KFold(n_splits = eFolds, random_state = eSeed)\n",
    "_Results[modelName] = cross_val_score(_model, xTrain, yTrain, cv = kFold, scoring = eScore)\n",
    "\n",
    "_DF.loc[len(_DF)] = list(['RandomForestClassifier', _Results[modelName].mean(), _Results[modelName].std()])\n",
    "display(_DF.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard write-up models\n",
    "\n",
    "Next we'll train the standard set of models (LR, LDA, etc.) we use in the majority of our write-ups for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:03:26.617385Z",
     "start_time": "2018-11-08T16:54:37.321871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training KNN ....\n",
      "Training CART ....\n",
      "Training NB ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "5   SVM   0.84312  0.008798\n",
      "0    LR   0.83892  0.009675\n",
      "1   LDA   0.83812  0.009423\n",
      "4    NB   0.79136  0.008274\n",
      "2   KNN   0.78140  0.011958\n",
      "3  CART   0.69828  0.008404\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAGQCAYAAAC6b4m/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAH6NJREFUeJzt3X+0XWV95/H3xyBga4NJE1sl/KqmNIgdqFfGzvjbYim1xVarSbVKJyP9MdAWbSsWuoh0XLWzaql1oS1WpDhtIqVS06kOdpZopYOVm5qiQYHwQ4nQ8VKC+JNffuePs6+cXO7NPUlO7jlP7vu11lk5e+9nP/fZm8P5nOfZz9knVYUkSWrXY0bdAEmStG8Mc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGudSoJEcnqSQHDVD29CTXLES7BpVkQ5L/Oep2SAcCw1xaAEluT/JAkhUz1m/tAvno0bRslw8FX+setyc5Z0RtmPeDiaRHM8ylhXMbsG56IcnTgceNrjmP8oSqejzwcuB3k5w86gZJGoxhLi2c9wGv6Vt+LXBZf4EkhyW5LMlUki8kOS/JY7ptS5L8YZK7k9wK/OQs+74nyV1JvpTkvydZsqeNrKpJYBtwQl/dT07yN127bkvya33bTkoymeS+JP8vyR9165+fZMeMNt6e5Mdm+bP/2P17bzc68KNJnprk40m+0h3z+/f0WKTFwjCXFs4ngaVJ1nQh+0pg5jXjdwCHAT8API9e+P9it+11wEuAE4EJej3ofn8BPAQ8tSvzYuC/7mkjkzwLOB7Y3i0/Bvg74F+Bw4EXAb+R5Me7Xd4OvL2qlgJPAS7f078JPLf79wlV9fiquhb4PeAjwDJgFb1zI2kWhrm0sKZ75ycDnwe+NL2hL+DfVFVfrarbgbcBv9AVeQXwx1V1R1XdA/x+377fB/wE8BtV9fWq+jJwIbB2D9p2d5JvAtcC7wT+tlv/TGBlVV1QVQ9U1a3Au/vqfhB4apIVVfW1qvrkHvzN3XkQOAp4clV9q6rGagKfNE4Mc2lhvQ/4eeB0ZgyxAyuAg4Ev9K37Ar3eMMCTgTtmbJt2FPBY4K4k9ya5F/gz4Il70LYVwOOB3wSe39U3XfeTp+vt6v4d4Pu67euBHwQ+n+S6JC/Zg7+5O78NBPhUkm1J/suQ6pUOOM4clRZQVX0hyW3AqfRCsN/dPNIbvaFbdySP9N7vAo7oK39k3/M7gPuBFVX10D6072HgbUl+BvhV4I+7um+rqtVz7HMzsK4bjv9Z4Iok3wt8Hfiu6XLdyMPKuf70LPX+G71LCyR5NvB/kvxjVW3f2+OTDlT2zKWFtx54YVV9vX9lF6SXA29J8j1JjgJezyPX1S8Hfi3JqiTLgHP69r2L3vXltyVZmuQxSZ6S5Hl72ca3Ar+d5FDgU8B9Sd6Y5HHdRLzjkzwTIMmrk6ysqm8D93b7PwzcBBya5CeTPBY4Dzhkjr83BXyb3lwBunp/LsmqbnEnvcB/eC+PRzqgGebSAquqW7oZ47M5i16P9lbgGuCvgEu6be8GrqI3Ee1fgA/M2Pc19Ibpb6AXflcAT9rLZv59V8frug8ZP0Vvdvtt9EYQ/pzeRD2AU4BtSb5GbzLc2u4a91fo9e7/nN7owteBXWa3T6uqbwBvAf6pG8p/Fr1r9f/c1bsZ+PWqum0vj0c6oKXqUaNbkiSpIfbMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY07aNQN2BMrVqyoo48+etTNkCRpQWzZsuXuqlo5X7mmwvzoo49mcnJy1M2QJGlBJPnCIOUcZpckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS45r6oRVJkvZGkqHVVVVDq2tYDHNJ0gFvkABOMpZBPQiH2SVJapxhLklS4wxzSZIaN1CYJzklyY1Jtic5Z5btRya5Osmnk1yf5NRu/dFJvplka/f40759npHkM12df5Jhzk4YkiRDe0iStL/MOwEuyRLgIuBkYAdwXZLNVXVDX7HzgMur6l1JjgM+BBzdbbulqk6Ypep3AWcAn+zKnwJ8eG8PZH840CdMSJIODIP0zE8CtlfVrVX1ALAJOG1GmQKWds8PA+7cXYVJngQsraprq5eElwEv3aOWS5IkYLAwPxy4o295R7eu3wbg1Ul20Otln9W37Zhu+P3jSZ7TV+eOeeoEIMkZSSaTTE5NTQ3QXC20YV6O8JKEpD2xfPnyob73DKuu5cuXL+h5GOR75rO9u84cV14HXFpVb0vyo8D7khwP3AUcWVX/nuQZwN8medqAdfZWVl0MXAwwMTHhePYY8nKEpFHZuXPnWL63LHTHZJAw3wEc0be8ikcPo6+nd82bqro2yaHAiqr6MnB/t35LkluAH+zqXDVPnZIkaQCDDLNfB6xOckySg4G1wOYZZb4IvAggyRrgUGAqycpuAh1JfgBYDdxaVXcBX03yrG4W+2uADw7liCRJWmTm7ZlX1UNJzgSuApYAl1TVtiQXAJNVtRl4A/DuJGfTGy4/vaoqyXOBC5I8BDwM/HJV3dNV/SvApcDj6M1iH6uZ7JIktSLjeK1hLhMTEzU5OTnqZuzCa8GD8TxJ2h/G9b1lWO1KsqWqJuYr5x3gJElqnGEuSVLjFuVPoC5fvpydO3cOrb5hfQVh2bJl3HPPPfMXlCSpz6IMc7+XKEk6kDjMLklS4wxzSZIatyiH2TW4Yc4vcG6BpGGr85fChsNG3YxHqfOXzl9oiAxz7dY4zi9wboGkaXnzfWP3HgXd98w3LNzfc5hdkqTG2TPXbo3jENZCD19J0rgzzLVb4ziEtdDDV5I07hZlmI9jbxPscUqS9s6iDPNx7G2CPU5J0t5xApwkSY0zzCVJapxhLklS4wxzSZIatygnwEmSDhzjeFfIZcuWLejfM8wlSc0a5jeTkozlN50G4TC7JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUuEU7m92vMkiSDhSLMsz9KoMk6UDiMLskSY1blD1z7ZlxuyTh5QhJ2pVhrt0a1iUEL0dI0v7jMLskSY0zzCVJapxhLklS4wxzSZIaZ5hLktQ4w1ySpMYZ5pIkNW6gME9ySpIbk2xPcs4s249McnWSTye5Psmp3fqTk2xJ8pnu3xf27fOxrs6t3eOJwzssSZIWj3lvGpNkCXARcDKwA7guyeaquqGv2HnA5VX1riTHAR8CjgbuBn6qqu5McjxwFXB4336vqqrJ4RyKJEmL0yA985OA7VV1a1U9AGwCTptRpoCl3fPDgDsBqurTVXVnt34bcGiSQ/a92ZIkadogYX44cEff8g527V0DbABenWQHvV75WbPU8zLg01V1f9+693ZD7L+bOW4AnuSMJJNJJqempgZoriRJi8sgYT5byM68yfY64NKqWgWcCrwvyXfqTvI04A+AX+rb51VV9XTgOd3jF2b741V1cVVNVNXEypUrB2iuJEm7SjLvY0/KjZtBwnwHcETf8iq6YfQ+64HLAarqWuBQYAVAklXAlcBrquqW6R2q6kvdv18F/orecL4kSUNXVUN7jKNBwvw6YHWSY5IcDKwFNs8o80XgRQBJ1tAL86kkTwD+HnhTVf3TdOEkByWZDvvHAi8BPruvByNJ0mI0b5hX1UPAmfRmon+O3qz1bUkuSPLTXbE3AK9L8q/ARuD06n18ORN4KvC7M76CdghwVZLrga3Al4B3D/vgJElaDDKuQwazmZiYqMnJ8fomm7/TzdCvIS328ylJ05JsqaqJ+crN+z1zaT6GrySNlrdzlSSpcYa5JEmNc5h9Nwa9FjxIOYeiJUn7i2G+GwawJKkFDrNLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIaZ5hLktS4g0bdAEnS3kky1Pqqaqj1aeEY5pLUqEHDN4lBfYBzmF2SpMYZ5pIkNc4wlySpcQOFeZJTktyYZHuSc2bZfmSSq5N8Osn1SU7t2/ambr8bk/z4oHVKkqTBzBvmSZYAFwE/ARwHrEty3Ixi5wGXV9WJwFrgnd2+x3XLTwNOAd6ZZMmAdUqSpAEM0jM/CdheVbdW1QPAJuC0GWUKWNo9Pwy4s3t+GrCpqu6vqtuA7V19g9QpSZIGMEiYHw7c0be8o1vXbwPw6iQ7gA8BZ82z7yB1ApDkjCSTSSanpqYGaK4kSYvLIGE+210JZn5hcR1waVWtAk4F3pfkMbvZd5A6eyurLq6qiaqaWLly5QDNlSRpcRnkpjE7gCP6llfxyDD6tPX0rolTVdcmORRYMc++89UpSZIGMEjP/DpgdZJjkhxMb0Lb5hllvgi8CCDJGuBQYKortzbJIUmOAVYDnxqwTkmSNIB5e+ZV9VCSM4GrgCXAJVW1LckFwGRVbQbeALw7ydn0hstPr969A7cluRy4AXgI+G9V9TDAbHXuh+OTJOmAl5bu1zsxMVGTk5OjboYkNcV7s7cryZaqmpivnHeAk6QxtHz5cpIM5QEMpZ7ly5eP+KxoLv5qmrSAhvmTlfa0Dmw7d+4cu//Gw/7JVQ2PYS4toEHenB0SlbSnHGaXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIa52x2SRpDdf5S2HDYqJuxizp/6fyFNBKGuSSNobz5vrH7imISasOoW6HZOMwuDYF365I0SvbMpSHwbl2SRsmeuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapy3c5WkMTVut+RdtmzZqJugORjmkjSGhnmv/yRj99sBGi6H2SVJapxhLklS4wxzSZIa5zVzaQjq/KWw4bBRN2MXdf7SUTdB0gIxzKUhyJvvG7sJRkmoDaNuhaSF4DC7JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTG+dU0aUj8UQxJozJQmCc5BXg7sAT486p664ztFwIv6Ba/C3hiVT0hyQuAC/uK/hCwtqr+NsmlwPOAr3TbTq+qrXt9JNII+aMYGoU9+QA5SFlfd+2aN8yTLAEuAk4GdgDXJdlcVTdMl6mqs/vKnwWc2K2/GjihW78c2A58pK/636qqK4ZwHJK06Bi+mjbINfOTgO1VdWtVPQBsAk7bTfl1wMZZ1r8c+HBVfWPPmylJkuYySJgfDtzRt7yjW/coSY4CjgE+OsvmtTw65N+S5PokFyY5ZI46z0gymWRyampqgOZKkrS4DBLms11omWtsZy1wRVU9vEsFyZOApwNX9a1+E71r6M8ElgNvnK3Cqrq4qiaqamLlypUDNFeSpMVlkDDfARzRt7wKuHOOsrP1vgFeAVxZVQ9Or6iqu6rnfuC99IbzJUnSHhokzK8DVic5JsnB9AJ788xCSY4FlgHXzlLHo66jd7110pti+VLgs3vWdEmSBAPMZq+qh5KcSW+IfAlwSVVtS3IBMFlV08G+DthUM6ZXJjmaXs/+4zOq/sskK+kN428FfnlfDkSSpMUqLX21YWJioiYnJ0fdDGm/8nvmkqYl2VJVE/OV83aukiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJatxBo26AtJgkGVq5qtrX5kg6QBjm0gIygCXtDw6zS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjRsozJOckuTGJNuTnDPL9guTbO0eNyW5t2/bw33bNvetPybJPye5Ocn7kxw8nEOSJGlxmTfMkywBLgJ+AjgOWJfkuP4yVXV2VZ1QVScA7wA+0Lf5m9Pbquqn+9b/AXBhVa0GdgLr9/FYJElalAbpmZ8EbK+qW6vqAWATcNpuyq8DNu6uwvTuiPFC4Ipu1V8ALx2gLZIkaYZBwvxw4I6+5R3dukdJchRwDPDRvtWHJplM8skk04H9vcC9VfXQAHWe0e0/OTU1NUBzJUlaXAa5A9xs95Wc6zZWa4ErqurhvnVHVtWdSX4A+GiSzwD3DVpnVV0MXAwwMTHh7bMkSZphkJ75DuCIvuVVwJ1zlF3LjCH2qrqz+/dW4GPAicDdwBOSTH+Y2F2dkiRpNwYJ8+uA1d3s84PpBfbmmYWSHAssA67tW7csySHd8xXAfwZuqN4Nqq8GXt4VfS3wwX05EEmSFqt5w7y7rn0mcBXwOeDyqtqW5IIk/bPT1wGbatdfklgDTCb5V3rh/daquqHb9kbg9Um207uG/p59PxxJkhaftPQrThMTEzU5OTnqZkiStCCSbKmqifnKeQc4SZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDVuoDBPckqSG5NsT3LOLNsvTLK1e9yU5N5u/QlJrk2yLcn1SV7Zt8+lSW7r2++E4R2WJEmLx0HzFUiyBLgIOBnYAVyXZHNV3TBdpqrO7it/FnBit/gN4DVVdXOSJwNbklxVVfd223+rqq4Y0rFIkrQoDdIzPwnYXlW3VtUDwCbgtN2UXwdsBKiqm6rq5u75ncCXgZX71mRJktRvkDA/HLijb3lHt+5RkhwFHAN8dJZtJwEHA7f0rX5LN/x+YZJD5qjzjCSTSSanpqYGaK4kSYvLIGGeWdbVHGXXAldU1cO7VJA8CXgf8ItV9e1u9ZuAHwKeCSwH3jhbhVV1cVVNVNXEypV26iVJmmmQMN8BHNG3vAq4c46ya+mG2KclWQr8PXBeVX1yen1V3VU99wPvpTecL0mS9tAgYX4dsDrJMUkOphfYm2cWSnIssAy4tm/dwcCVwGVV9dczyj+p+zfAS4HP7u1BSJK0mM07m72qHkpyJnAVsAS4pKq2JbkAmKyq6WBfB2yqqv4h+FcAzwW+N8np3brTq2or8JdJVtIbxt8K/PJQjkiSpEUmu2bveJuYmKjJyclRN0OSpAWRZEtVTcxXzjvASZLUOMNckqTGGeaSJDXOMJfUlI0bN3L88cezZMkSjj/+eDZu3Dj/TtIBbt7Z7JI0LjZu3Mi5557Le97zHp797GdzzTXXsH79egDWrVs34tZJo+NsdknNOP7443nHO97BC17wgu+su/rqqznrrLP47Ge9VYUOPIPOZjfMJTVjyZIlfOtb3+Kxj33sd9Y9+OCDHHrooTz88MO72VNqk19Nk3TAWbNmDddcc80u66655hrWrFkzohZJ48Ewl9SMc889l/Xr13P11Vfz4IMPcvXVV7N+/XrOPffcUTdNGiknwElqxvQkt7POOovPfe5zrFmzhre85S1OftOi5zVzSZLGlNfMJUlaJAxzSZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcYa5JEmNM8wlSWqcYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXGGuSRJjTPMJUlqnGEuSVLjDHNJkhpnmEuS1LiDRt0ASZopyVDrq6qh1ieNG8Nc0tgZJHyTGNJSx2F2SZIaZ5hLktQ4w1ySpMYNFOZJTklyY5LtSc6ZZfuFSbZ2j5uS3Nu37bVJbu4er+1b/4wkn+nq/JMMe8aLJEmLxLwT4JIsAS4CTgZ2ANcl2VxVN0yXqaqz+8qfBZzYPV8OnA9MAAVs6fbdCbwLOAP4JPAh4BTgw0M6Lkljavny5ezcuXModQ2rD7Bs2TLuueeeodQljcIgPfOTgO1VdWtVPQBsAk7bTfl1wMbu+Y8D/1BV93QB/g/AKUmeBCytqmurNx31MuCle30Ukpqxc+dOqmqsHsP6cCGNyiBhfjhwR9/yjm7doyQ5CjgG+Og8+x7ePZ+3TkmStHuDhPls41hzfblzLXBFVT08z74D15nkjCSTSSanpqbmbawkSYvNIGG+Aziib3kVcOccZdfyyBD77vbd0T2ft86quriqJqpqYuXKlQM0V5KkxWWQML8OWJ3kmCQH0wvszTMLJTkWWAZc27f6KuDFSZYlWQa8GLiqqu4CvprkWd0s9tcAH9zHY5EkaVGadzZ7VT2U5Ex6wbwEuKSqtiW5AJisqulgXwdsqr77K1bVPUl+j94HAoALqmp6yuivAJcCj6M3i92Z7JIk7YW0dG/jiYmJmpycHHUzJO2Dcbyn+ji2SQJIsqWqJuYr5x3gJElqnL+aJmlB1flLYcNho27GLur8paNugrRPDHNJCypvvm/shrSTUBtG3Qpp7znMLklS4wxzSZIaZ5hLktQ4r5lLWnDj9ovHy5YtG3UTpH1imEtaUMOa/OZ3w6VHOMwuSVLjDHNJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapw3jZE0dga9Q9yg5by5jA50hrmksWP4SnvGYXZJkhpnmEuS1DjDXJKkxhnmkiQ1zjCXJKlxhrkkSY0zzCVJapxhLklS4wxzSZIaZ5hLktQ4w1ySpMYZ5pIkNc4wlySpcWnp14mSTAFfGHU7ZlgB3D3qRjTA8zQ4z9VgPE+D81wNZhzP01FVtXK+Qk2F+ThKMllVE6Nux7jzPA3OczUYz9PgPFeDafk8OcwuSVLjDHNJkhpnmO+7i0fdgEZ4ngbnuRqM52lwnqvBNHuevGYuSVLj7JlLktQ4w1ySpMYZ5nsgyddmWbchyZeSbE1yQ5J1o2jbKA1wXm5O8oEkx80oszLJg0l+aeFaOzr95ynJqd15ObI7V99I8sQ5ylaSt/Ut/2aSDQvW8AWS5PuTbEpyS/f/0oeS/GC37ewk30pyWF/55yf5SpJPJ/l8kj/s1v9i97rbmuSBJJ/pnr91VMe2EHb3Opnx/+Pnk7wryaJ6/09ybpJtSa7vzsOHk/z+jDInJPlc9/z2JJ+YsX1rks8uZLsHtaj+Y+5HF1bVCcBpwJ8leeyoGzQmLqyqE6pqNfB+4KNJ+m9+8HPAJ4FF9QEoyYuAdwCnVNUXu9V3A2+YY5f7gZ9NsmIh2jcKSQJcCXysqp5SVccBvwN8X1dkHXAd8DMzdv1EVZ0InAi8JMl/rqr3dq+7E4A7gRd0y+cszNGMzHyvk+n3qeOApwPPW7CWjViSHwVeAvxIVf0w8GPAW4FXzii6FvirvuXvSXJEV8eahWjr3jLMh6iqbga+ASwbdVvGTVW9H/gI8PN9q9fRC7BVSQ4fScMWWJLnAO8GfrKqbunbdAnwyiTLZ9ntIXqzbM9egCaOyguAB6vqT6dXVNXWqvpEkqcAjwfOY44PflX1TWArsCheR3MY9HVyMHAosHO/t2h8PAm4u6ruB6iqu6vq48C9Sf5jX7lXAJv6li/nkcBfB2xciMbuDcN8iJL8CHBzVX151G0ZU/8C/BBA92n3+6vqU+z6P8yB7BDgg8BLq+rzM7Z9jV6g//oc+14EvKp/mPkAczywZY5t02+inwCO7b8cMS3JMmA18I/7rYVt2N3r5OwkW4G7gJuqauvCNm2kPgIckeSmJO9MMj0qsZFeb5wkzwL+veuUTbsC+Nnu+U8Bf7dQDd5ThvlwnJ3kRuCfgQ0jbss4S9/ztfRCHHqfhBfDUPuDwP8F1s+x/U+A1yZZOnNDVd0HXAb82v5r3thaC2yqqm8DH6B3eWbac5JcD/wb8L+q6t9G0cBxMc/rZHqY/YnAdydZu6CNG6Gq+hrwDOAMYAp4f5LT6b33vLybP7CWR/e87wF2dufqc/RGXseSYT4cF1bVsfR6l5clOXTUDRpTJ9L7HwJ64X16ktuBzcB/SLJ6VA1bIN+mN4z3zCS/M3NjVd1L73rdr86x/x/T+yDw3futhaOzjd6b7S6S/DC9Hvc/dK+Vtez6we8T3TXQpwO/kuSEBWjruNvt66SqHgT+N/DchWzUqFXVw1X1sao6HzgTeFlV3QHcTm/+wMt4pIPR7/30RjzGdogdDPOhqqoPAJPAa0fdlnGT5GXAi4GNSY4FvruqDq+qo6vqaOD36Ya7DmRV9Q16E3FelWS2HvofAb8EHDTLvvfQe7OZq2ffso8ChyR53fSKJM8E3g5smH6dVNWTgcOTHNW/c1XdRO819MaFbPQ4mu910k02/E/ALbNtPxAlOXZGZ+EEHvkFzo3AhcAtVbVjlt2vBP4HcNX+beW+Mcz3zHcl2dH3eP0sZS4AXr/IvvYx13k5e/qracCrgRdW1RS9ntWVM+r4GxbHUPv0m+0pwHlJTpux7W565+aQOXZ/G72faTygVO9WlD8DnNx9NW0bvUtWz+fRr5Urmf2D358Cz01yzH5saitme51MXzP/LL0Pi+9c8FaNzuOBv+i+8ng9vRn9G7ptfw08jV0nvn1HVX21qv6gqh5YkJbuJW/nKklS4xZT71GSpAOSYS5JUuMMc0mSGmeYS5LUOMNckqTGGeaSJDXOMJckqXH/H1bbTyfJcN8DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, _df = trainModels(doc2vecModel.docvecs, df.iloc[:, 1], modelsToRun = 'all')\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard model comments\n",
    "\n",
    "The first thing I noticed right away is how much faster training the set of models was.  Training wrapped up in about 9 mins compared to the sometimes hours required in previous write-ups.  Accuracy was also high being only two percentage points less then the baseline model:\n",
    "\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|-------------------|--------|-----------------------------------|\n",
    "|LR (baseline)      |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid       |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec        |84.31%  |Scikit-learn defaults              |\n",
    "<div style=\"clear:both\"></div>\n",
    "\n",
    "Clearly for very large data sets the small drop in accuracy might be more than offset by the greatly reduced training time required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Doc2Vec\n",
    "\n",
    "Let's run through the steps above again, but this time we'll see if we can tune the Doc2Vec model and increase performance.  Clearly we could spend much time on tuning parameters, and so to get a head start I pulled some initial values based on some successful recommendation found on the Internet.  Two very helpful resources were:\n",
    "\n",
    "1. [The original paper itself](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "2. [Gensim's Doc2Vec Tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb)\n",
    "\n",
    "One note however:  During my research I came across some discussion/controversy about the validity of the final accuracy score in the original paper.  This also included skepticism voiced by one of the paper's authors, Mikilov.  As such we won't try to replicate the paper's accuracy metrics exactly, as there is some question as to whether that is possible or not on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "## Create the model, build the vocab, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:04:29.203583Z",
     "start_time": "2018-11-08T17:03:26.618385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:03:27,095 : INFO : collecting all words and their counts\n",
      "2018-11-08 10:03:27,105 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-08 10:03:27,450 : INFO : PROGRESS: at example #10000, processed 2385574 words (6791428/s), 51527 word types, 10000 tags\n",
      "2018-11-08 10:03:27,824 : INFO : PROGRESS: at example #20000, processed 4747503 words (6461464/s), 67813 word types, 20000 tags\n",
      "2018-11-08 10:03:27,998 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-08 10:03:27,998 : INFO : Loading a fresh vocabulary\n",
      "2018-11-08 10:03:28,200 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-08 10:03:28,200 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-08 10:03:28,300 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-08 10:03:28,310 : INFO : sample=0 downsamples 0 most-common words\n",
      "2018-11-08 10:03:28,310 : INFO : downsampling leaves estimated 5892845 word corpus (100.0% of prior 5892845)\n",
      "2018-11-08 10:03:28,433 : INFO : estimated required memory for 46350 words and 100 dimensions: 70255000 bytes\n",
      "2018-11-08 10:03:28,443 : INFO : resetting layer weights\n",
      "2018-11-08 10:03:29,130 : INFO : training model with 4 workers on 46350 vocabulary and 100 features, using sg=1 hs=0 sample=0 negative=5 window=5\n",
      "2018-11-08 10:03:30,143 : INFO : EPOCH 1 - PROGRESS: at 33.68% examples, 2007354 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:03:31,150 : INFO : EPOCH 1 - PROGRESS: at 67.85% examples, 2008378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:32,070 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:32,080 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:32,080 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:32,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:32,090 : INFO : EPOCH - 1 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2007064 effective words/s\n",
      "2018-11-08 10:03:33,096 : INFO : EPOCH 2 - PROGRESS: at 34.18% examples, 2034611 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:34,099 : INFO : EPOCH 2 - PROGRESS: at 68.33% examples, 2027814 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:35,002 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:35,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:35,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:35,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:35,022 : INFO : EPOCH - 2 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2022791 effective words/s\n",
      "2018-11-08 10:03:36,036 : INFO : EPOCH 3 - PROGRESS: at 34.51% examples, 2040142 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:37,035 : INFO : EPOCH 3 - PROGRESS: at 68.80% examples, 2034852 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:37,933 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:37,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:37,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:37,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:37,953 : INFO : EPOCH - 3 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2020005 effective words/s\n",
      "2018-11-08 10:03:38,962 : INFO : EPOCH 4 - PROGRESS: at 34.34% examples, 2045145 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:39,963 : INFO : EPOCH 4 - PROGRESS: at 68.52% examples, 2029059 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:03:40,892 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:40,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:40,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:40,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:40,912 : INFO : EPOCH - 4 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2006459 effective words/s\n",
      "2018-11-08 10:03:41,912 : INFO : EPOCH 5 - PROGRESS: at 34.34% examples, 2047233 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:42,922 : INFO : EPOCH 5 - PROGRESS: at 68.52% examples, 2031662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:43,816 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:43,826 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:43,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:43,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:43,836 : INFO : EPOCH - 5 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2023078 effective words/s\n",
      "2018-11-08 10:03:44,831 : INFO : EPOCH 6 - PROGRESS: at 34.18% examples, 2040141 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:45,833 : INFO : EPOCH 6 - PROGRESS: at 68.33% examples, 2030060 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:46,740 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:46,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:46,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:46,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:46,756 : INFO : EPOCH - 6 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2022915 effective words/s\n",
      "2018-11-08 10:03:47,764 : INFO : EPOCH 7 - PROGRESS: at 33.17% examples, 1980394 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:48,770 : INFO : EPOCH 7 - PROGRESS: at 66.48% examples, 1970654 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:49,721 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:49,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:49,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:49,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:49,742 : INFO : EPOCH - 7 : training on 5920713 raw words (5917845 effective words) took 3.0s, 1986373 effective words/s\n",
      "2018-11-08 10:03:50,753 : INFO : EPOCH 8 - PROGRESS: at 34.51% examples, 2049331 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:03:51,753 : INFO : EPOCH 8 - PROGRESS: at 69.14% examples, 2050476 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:03:52,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:52,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:52,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:52,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:52,643 : INFO : EPOCH - 8 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2043337 effective words/s\n",
      "2018-11-08 10:03:53,661 : INFO : EPOCH 9 - PROGRESS: at 34.51% examples, 2037788 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:54,666 : INFO : EPOCH 9 - PROGRESS: at 69.30% examples, 2044844 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:55,532 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:55,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:55,545 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:55,549 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:55,550 : INFO : EPOCH - 9 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2040089 effective words/s\n",
      "2018-11-08 10:03:56,559 : INFO : EPOCH 10 - PROGRESS: at 34.67% examples, 2063959 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:57,564 : INFO : EPOCH 10 - PROGRESS: at 69.14% examples, 2048111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:03:58,439 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:03:58,447 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:03:58,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:03:58,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:03:58,453 : INFO : EPOCH - 10 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2042383 effective words/s\n",
      "2018-11-08 10:03:59,462 : INFO : EPOCH 11 - PROGRESS: at 34.50% examples, 2054888 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:04:00,463 : INFO : EPOCH 11 - PROGRESS: at 69.14% examples, 2052727 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:01,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:01,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:01,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:01,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:01,357 : INFO : EPOCH - 11 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2042024 effective words/s\n",
      "2018-11-08 10:04:02,363 : INFO : EPOCH 12 - PROGRESS: at 30.52% examples, 1824352 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:03,372 : INFO : EPOCH 12 - PROGRESS: at 61.93% examples, 1836301 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:04:04,377 : INFO : EPOCH 12 - PROGRESS: at 92.24% examples, 1814330 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:04,633 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:04,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:04,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:04,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:04,650 : INFO : EPOCH - 12 : training on 5920713 raw words (5917845 effective words) took 3.3s, 1800201 effective words/s\n",
      "2018-11-08 10:04:05,663 : INFO : EPOCH 13 - PROGRESS: at 28.04% examples, 1666147 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:06,663 : INFO : EPOCH 13 - PROGRESS: at 58.89% examples, 1749618 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:07,665 : INFO : EPOCH 13 - PROGRESS: at 92.58% examples, 1823647 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:07,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:07,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:07,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:07,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:07,914 : INFO : EPOCH - 13 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1822193 effective words/s\n",
      "2018-11-08 10:04:08,920 : INFO : EPOCH 14 - PROGRESS: at 34.18% examples, 2039029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:09,925 : INFO : EPOCH 14 - PROGRESS: at 68.17% examples, 2025631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:10,838 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:10,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:10,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:10,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:10,858 : INFO : EPOCH - 14 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2017893 effective words/s\n",
      "2018-11-08 10:04:11,864 : INFO : EPOCH 15 - PROGRESS: at 32.52% examples, 1929710 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:04:12,879 : INFO : EPOCH 15 - PROGRESS: at 66.35% examples, 1958839 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:13,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:13,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:13,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:13,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:13,861 : INFO : EPOCH - 15 : training on 5920713 raw words (5917845 effective words) took 3.0s, 1971001 effective words/s\n",
      "2018-11-08 10:04:14,876 : INFO : EPOCH 16 - PROGRESS: at 33.85% examples, 1999576 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:15,883 : INFO : EPOCH 16 - PROGRESS: at 66.18% examples, 1953158 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:16,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:16,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:16,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:16,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:16,864 : INFO : EPOCH - 16 : training on 5920713 raw words (5917845 effective words) took 3.0s, 1975205 effective words/s\n",
      "2018-11-08 10:04:17,859 : INFO : EPOCH 17 - PROGRESS: at 26.63% examples, 1586561 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:18,865 : INFO : EPOCH 17 - PROGRESS: at 59.41% examples, 1764289 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:19,879 : INFO : EPOCH 17 - PROGRESS: at 92.24% examples, 1816555 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:20,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:20,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:20,092 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:20,096 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:20,098 : INFO : EPOCH - 17 : training on 5920713 raw words (5917845 effective words) took 3.2s, 1825911 effective words/s\n",
      "2018-11-08 10:04:21,111 : INFO : EPOCH 18 - PROGRESS: at 32.18% examples, 1923327 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:22,117 : INFO : EPOCH 18 - PROGRESS: at 65.84% examples, 1956107 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:23,119 : INFO : EPOCH 18 - PROGRESS: at 99.55% examples, 1958358 words/s, in_qsize 3, out_qsize 1\n",
      "2018-11-08 10:04:23,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:23,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:23,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:23,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:23,133 : INFO : EPOCH - 18 : training on 5920713 raw words (5917845 effective words) took 3.0s, 1958337 effective words/s\n",
      "2018-11-08 10:04:24,143 : INFO : EPOCH 19 - PROGRESS: at 32.52% examples, 1941940 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:25,132 : INFO : EPOCH 19 - PROGRESS: at 64.52% examples, 1917490 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:04:26,134 : INFO : EPOCH 19 - PROGRESS: at 97.12% examples, 1916827 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:26,222 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:04:26,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:26,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:26,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:26,232 : INFO : EPOCH - 19 : training on 5920713 raw words (5917845 effective words) took 3.1s, 1915123 effective words/s\n",
      "2018-11-08 10:04:27,242 : INFO : EPOCH 20 - PROGRESS: at 33.52% examples, 2000049 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:28,243 : INFO : EPOCH 20 - PROGRESS: at 67.68% examples, 2008350 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:04:29,151 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:04:29,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:04:29,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:04:29,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:04:29,193 : INFO : EPOCH - 20 : training on 5920713 raw words (5917845 effective words) took 2.9s, 2007782 effective words/s\n",
      "2018-11-08 10:04:29,193 : INFO : training on a 118414260 raw words (118356900 effective words) took 60.1s, 1970803 effective words/s\n"
     ]
    }
   ],
   "source": [
    "doc2vecModel = Doc2Vec(dm = 0, vector_size = 100, negative = 5, hs = 0, min_count = 2, sample = 0, epochs = 20, workers = cores)\n",
    "doc2vecModel.build_vocab(taggedDocs)\n",
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:13:43.050070Z",
     "start_time": "2018-11-08T17:04:29.203583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training KNN ....\n",
      "Training CART ....\n",
      "Training NB ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "5   SVM   0.88716  0.006895\n",
      "0    LR   0.88460  0.006398\n",
      "1   LDA   0.88448  0.006888\n",
      "4    NB   0.85340  0.006517\n",
      "2   KNN   0.81540  0.010377\n",
      "3  CART   0.69372  0.011037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, _df = trainModels(doc2vecModel.docvecs, df.iloc[:, 1], modelsToRun = 'all')\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Things are clearly off to a good start with tuning.  We picked up four percentage points from our first Doc2Vec model, achieved the best performing model to date, and still maintained the speed increases we enjoyed above.  \n",
    "\n",
    "Comparison table for reference:\n",
    "\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|--------------------------|--------|-----------------------------------|\n",
    "|LR (baseline)             |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid              |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec               |84.48%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec Init tuning   |88.71%  |dm0, vs100, ng5, hs0, mc2, sm0, e20|\n",
    "\n",
    "<div style=\"clear:both\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Doc2Vec models\n",
    "\n",
    "Another method we can explore is combining the outputs of two Doc2Vec models similar to an pseudo-ensemble.  This can be done by using `np.hstack` to concatenate the document vectors from the two (or more) models.  The output will be one combined vector per review, and this can be fed into the Scikit-lern evaluations as the feature set.\n",
    "\n",
    "Let's create three Doc2Vec models, train them, make a few feature set combinations, and see if we realize any improvement in accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Doc2Vec models, build vocabulary, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:18:46.094941Z",
     "start_time": "2018-11-08T17:13:43.050070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:13:43,506 : INFO : using concatenative 1100-dimensional layer1\n",
      "2018-11-08 10:13:43,506 : INFO : collecting all words and their counts\n",
      "2018-11-08 10:13:43,506 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-08 10:13:43,881 : INFO : PROGRESS: at example #10000, processed 2385574 words (6622587/s), 51527 word types, 10000 tags\n",
      "2018-11-08 10:13:44,207 : INFO : PROGRESS: at example #20000, processed 4747503 words (6722481/s), 67813 word types, 20000 tags\n",
      "2018-11-08 10:13:44,407 : INFO : collected 74218 word types and 25000 unique tags from a corpus of 25000 examples and 5920713 words\n",
      "2018-11-08 10:13:44,409 : INFO : Loading a fresh vocabulary\n",
      "2018-11-08 10:13:44,612 : INFO : effective_min_count=2 retains 46350 unique words (62% of original 74218, drops 27868)\n",
      "2018-11-08 10:13:44,612 : INFO : effective_min_count=2 leaves 5892845 word corpus (99% of original 5920713, drops 27868)\n",
      "2018-11-08 10:13:44,742 : INFO : deleting the raw counts dictionary of 74218 items\n",
      "2018-11-08 10:13:44,742 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-08 10:13:44,742 : INFO : downsampling leaves estimated 4416048 word corpus (74.9% of prior 5892845)\n",
      "2018-11-08 10:13:44,869 : INFO : estimated required memory for 46350 words and 100 dimensions: 255655000 bytes\n",
      "2018-11-08 10:13:44,869 : INFO : resetting layer weights\n",
      "2018-11-08 10:13:45,550 : INFO : resetting layer weights\n",
      "2018-11-08 10:13:46,222 : INFO : resetting layer weights\n",
      "2018-11-08 10:13:46,884 : INFO : training model with 4 workers on 46351 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 10:13:47,921 : INFO : EPOCH 1 - PROGRESS: at 11.39% examples, 499337 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:48,925 : INFO : EPOCH 1 - PROGRESS: at 22.33% examples, 498969 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:13:49,924 : INFO : EPOCH 1 - PROGRESS: at 33.85% examples, 498800 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:13:50,958 : INFO : EPOCH 1 - PROGRESS: at 45.49% examples, 501791 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:51,959 : INFO : EPOCH 1 - PROGRESS: at 57.24% examples, 506261 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:52,972 : INFO : EPOCH 1 - PROGRESS: at 69.30% examples, 507934 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:54,004 : INFO : EPOCH 1 - PROGRESS: at 81.44% examples, 510871 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:13:54,993 : INFO : EPOCH 1 - PROGRESS: at 93.50% examples, 513196 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:13:55,497 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:13:55,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:13:55,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:13:55,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:13:55,512 : INFO : EPOCH - 1 : training on 5920713 raw words (4442230 effective words) took 8.6s, 515257 effective words/s\n",
      "2018-11-08 10:13:56,574 : INFO : EPOCH 2 - PROGRESS: at 12.08% examples, 514042 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:57,578 : INFO : EPOCH 2 - PROGRESS: at 23.82% examples, 514804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:58,596 : INFO : EPOCH 2 - PROGRESS: at 35.44% examples, 517350 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:13:59,614 : INFO : EPOCH 2 - PROGRESS: at 46.82% examples, 510192 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:14:00,610 : INFO : EPOCH 2 - PROGRESS: at 58.67% examples, 515083 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:01,622 : INFO : EPOCH 2 - PROGRESS: at 70.92% examples, 517775 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:02,652 : INFO : EPOCH 2 - PROGRESS: at 83.16% examples, 520176 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:03,668 : INFO : EPOCH 2 - PROGRESS: at 95.48% examples, 521846 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:03,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:03,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:04,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:04,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:04,011 : INFO : EPOCH - 2 : training on 5920713 raw words (4441157 effective words) took 8.5s, 522950 effective words/s\n",
      "2018-11-08 10:14:05,031 : INFO : EPOCH 3 - PROGRESS: at 11.90% examples, 529428 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:06,045 : INFO : EPOCH 3 - PROGRESS: at 23.21% examples, 518290 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:14:07,059 : INFO : EPOCH 3 - PROGRESS: at 34.82% examples, 515704 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:14:08,038 : INFO : EPOCH 3 - PROGRESS: at 46.16% examples, 511245 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:09,068 : INFO : EPOCH 3 - PROGRESS: at 57.92% examples, 514511 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:10,078 : INFO : EPOCH 3 - PROGRESS: at 70.09% examples, 517389 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:14:11,083 : INFO : EPOCH 3 - PROGRESS: at 82.65% examples, 521639 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:12,083 : INFO : EPOCH 3 - PROGRESS: at 94.97% examples, 523741 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:12,473 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:12,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:12,504 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:12,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:12,520 : INFO : EPOCH - 3 : training on 5920713 raw words (4441844 effective words) took 8.5s, 522868 effective words/s\n",
      "2018-11-08 10:14:13,531 : INFO : EPOCH 4 - PROGRESS: at 11.08% examples, 493109 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:14,543 : INFO : EPOCH 4 - PROGRESS: at 22.83% examples, 507673 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:14:15,544 : INFO : EPOCH 4 - PROGRESS: at 35.25% examples, 521700 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:16,582 : INFO : EPOCH 4 - PROGRESS: at 46.67% examples, 513720 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:17,607 : INFO : EPOCH 4 - PROGRESS: at 58.67% examples, 517715 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:18,623 : INFO : EPOCH 4 - PROGRESS: at 70.58% examples, 516628 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:14:19,605 : INFO : EPOCH 4 - PROGRESS: at 82.19% examples, 515470 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:14:20,612 : INFO : EPOCH 4 - PROGRESS: at 94.47% examples, 518399 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:21,084 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:21,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:21,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:21,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:21,115 : INFO : EPOCH - 4 : training on 5920713 raw words (4439654 effective words) took 8.6s, 516458 effective words/s\n",
      "2018-11-08 10:14:22,132 : INFO : EPOCH 5 - PROGRESS: at 10.38% examples, 460862 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:23,129 : INFO : EPOCH 5 - PROGRESS: at 21.80% examples, 487946 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:24,144 : INFO : EPOCH 5 - PROGRESS: at 33.52% examples, 494876 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:25,144 : INFO : EPOCH 5 - PROGRESS: at 45.18% examples, 500052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:26,175 : INFO : EPOCH 5 - PROGRESS: at 56.69% examples, 503807 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:27,191 : INFO : EPOCH 5 - PROGRESS: at 69.44% examples, 511766 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:28,172 : INFO : EPOCH 5 - PROGRESS: at 81.25% examples, 511999 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:14:29,189 : INFO : EPOCH 5 - PROGRESS: at 92.58% examples, 509772 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:29,772 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:29,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:29,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:29,789 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:29,789 : INFO : EPOCH - 5 : training on 5920713 raw words (4441422 effective words) took 8.7s, 512110 effective words/s\n",
      "2018-11-08 10:14:30,805 : INFO : EPOCH 6 - PROGRESS: at 11.90% examples, 530397 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:31,822 : INFO : EPOCH 6 - PROGRESS: at 23.99% examples, 535248 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:32,825 : INFO : EPOCH 6 - PROGRESS: at 36.38% examples, 541760 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:33,843 : INFO : EPOCH 6 - PROGRESS: at 49.05% examples, 543984 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:34,841 : INFO : EPOCH 6 - PROGRESS: at 61.45% examples, 543825 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:35,865 : INFO : EPOCH 6 - PROGRESS: at 74.06% examples, 545501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:36,884 : INFO : EPOCH 6 - PROGRESS: at 86.71% examples, 547094 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:37,876 : INFO : EPOCH 6 - PROGRESS: at 99.55% examples, 547639 words/s, in_qsize 3, out_qsize 1\n",
      "2018-11-08 10:14:37,892 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:37,892 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:37,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:37,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:37,907 : INFO : EPOCH - 6 : training on 5920713 raw words (4441757 effective words) took 8.1s, 548844 effective words/s\n",
      "2018-11-08 10:14:38,920 : INFO : EPOCH 7 - PROGRESS: at 12.06% examples, 532864 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:39,924 : INFO : EPOCH 7 - PROGRESS: at 24.50% examples, 545050 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:40,923 : INFO : EPOCH 7 - PROGRESS: at 36.85% examples, 548859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:41,942 : INFO : EPOCH 7 - PROGRESS: at 49.52% examples, 550339 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:42,940 : INFO : EPOCH 7 - PROGRESS: at 62.18% examples, 551658 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:43,943 : INFO : EPOCH 7 - PROGRESS: at 74.57% examples, 551562 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:44,953 : INFO : EPOCH 7 - PROGRESS: at 87.32% examples, 553059 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:45,884 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:45,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:45,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:45,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:45,921 : INFO : EPOCH - 7 : training on 5920713 raw words (4441518 effective words) took 8.0s, 554669 effective words/s\n",
      "2018-11-08 10:14:46,901 : INFO : EPOCH 8 - PROGRESS: at 12.24% examples, 544928 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:14:47,917 : INFO : EPOCH 8 - PROGRESS: at 25.01% examples, 558605 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:48,941 : INFO : EPOCH 8 - PROGRESS: at 37.23% examples, 549492 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 10:14:49,951 : INFO : EPOCH 8 - PROGRESS: at 49.37% examples, 545257 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:50,965 : INFO : EPOCH 8 - PROGRESS: at 62.18% examples, 548105 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:51,979 : INFO : EPOCH 8 - PROGRESS: at 74.73% examples, 549230 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:14:52,980 : INFO : EPOCH 8 - PROGRESS: at 87.50% examples, 551384 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:14:53,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:14:53,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:14:53,937 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:14:53,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:14:53,937 : INFO : EPOCH - 8 : training on 5920713 raw words (4439869 effective words) took 8.0s, 553636 effective words/s\n",
      "2018-11-08 10:14:54,952 : INFO : EPOCH 9 - PROGRESS: at 12.55% examples, 559498 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:55,958 : INFO : EPOCH 9 - PROGRESS: at 25.17% examples, 557604 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:14:56,976 : INFO : EPOCH 9 - PROGRESS: at 37.78% examples, 558427 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:57,981 : INFO : EPOCH 9 - PROGRESS: at 50.54% examples, 560383 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:14:59,014 : INFO : EPOCH 9 - PROGRESS: at 63.64% examples, 560713 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:00,015 : INFO : EPOCH 9 - PROGRESS: at 76.66% examples, 562720 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:01,017 : INFO : EPOCH 9 - PROGRESS: at 89.51% examples, 563058 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:01,812 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:01,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:01,812 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:01,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:01,828 : INFO : EPOCH - 9 : training on 5920713 raw words (4440990 effective words) took 7.9s, 563638 effective words/s\n",
      "2018-11-08 10:15:02,849 : INFO : EPOCH 10 - PROGRESS: at 12.72% examples, 552974 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:03,850 : INFO : EPOCH 10 - PROGRESS: at 25.63% examples, 566603 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:04,854 : INFO : EPOCH 10 - PROGRESS: at 38.09% examples, 563907 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:05,876 : INFO : EPOCH 10 - PROGRESS: at 51.24% examples, 565301 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:06,892 : INFO : EPOCH 10 - PROGRESS: at 64.36% examples, 567118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:07,901 : INFO : EPOCH 10 - PROGRESS: at 77.32% examples, 567459 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:08,935 : INFO : EPOCH 10 - PROGRESS: at 90.16% examples, 565300 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:09,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:09,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:09,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:09,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:09,702 : INFO : EPOCH - 10 : training on 5920713 raw words (4440985 effective words) took 7.9s, 563559 effective words/s\n",
      "2018-11-08 10:15:10,711 : INFO : EPOCH 11 - PROGRESS: at 11.26% examples, 493023 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:15:11,747 : INFO : EPOCH 11 - PROGRESS: at 23.99% examples, 527681 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:12,757 : INFO : EPOCH 11 - PROGRESS: at 36.38% examples, 536820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:13,755 : INFO : EPOCH 11 - PROGRESS: at 48.59% examples, 537107 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:14,773 : INFO : EPOCH 11 - PROGRESS: at 61.45% examples, 543952 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:15,780 : INFO : EPOCH 11 - PROGRESS: at 74.57% examples, 548563 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:16,805 : INFO : EPOCH 11 - PROGRESS: at 87.67% examples, 552179 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:17,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:17,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:17,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:15:17,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:17,701 : INFO : EPOCH - 11 : training on 5920713 raw words (4442269 effective words) took 8.0s, 555865 effective words/s\n",
      "2018-11-08 10:15:18,727 : INFO : EPOCH 12 - PROGRESS: at 12.72% examples, 561740 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:19,722 : INFO : EPOCH 12 - PROGRESS: at 25.63% examples, 570722 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:20,740 : INFO : EPOCH 12 - PROGRESS: at 38.60% examples, 569898 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:21,729 : INFO : EPOCH 12 - PROGRESS: at 51.17% examples, 567204 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:22,776 : INFO : EPOCH 12 - PROGRESS: at 62.62% examples, 552569 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:23,796 : INFO : EPOCH 12 - PROGRESS: at 75.94% examples, 556096 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:24,790 : INFO : EPOCH 12 - PROGRESS: at 89.30% examples, 560455 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:25,578 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:25,579 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:25,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:25,579 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:25,581 : INFO : EPOCH - 12 : training on 5920713 raw words (4441301 effective words) took 7.9s, 562641 effective words/s\n",
      "2018-11-08 10:15:26,595 : INFO : EPOCH 13 - PROGRESS: at 12.72% examples, 564366 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:27,616 : INFO : EPOCH 13 - PROGRESS: at 25.97% examples, 573770 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:15:28,648 : INFO : EPOCH 13 - PROGRESS: at 39.13% examples, 577331 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:29,627 : INFO : EPOCH 13 - PROGRESS: at 52.03% examples, 576578 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:30,633 : INFO : EPOCH 13 - PROGRESS: at 65.40% examples, 578351 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:31,641 : INFO : EPOCH 13 - PROGRESS: at 78.67% examples, 579389 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:32,666 : INFO : EPOCH 13 - PROGRESS: at 92.24% examples, 579914 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:33,188 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:33,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:33,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:33,242 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:33,242 : INFO : EPOCH - 13 : training on 5920713 raw words (4441322 effective words) took 7.6s, 581684 effective words/s\n",
      "2018-11-08 10:15:34,258 : INFO : EPOCH 14 - PROGRESS: at 12.89% examples, 573225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:35,247 : INFO : EPOCH 14 - PROGRESS: at 26.16% examples, 580821 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:36,280 : INFO : EPOCH 14 - PROGRESS: at 39.32% examples, 580043 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:37,290 : INFO : EPOCH 14 - PROGRESS: at 52.48% examples, 581733 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:38,305 : INFO : EPOCH 14 - PROGRESS: at 66.02% examples, 582797 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:39,317 : INFO : EPOCH 14 - PROGRESS: at 79.40% examples, 582924 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:15:40,326 : INFO : EPOCH 14 - PROGRESS: at 92.94% examples, 584232 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:40,801 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:40,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:40,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:40,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:40,843 : INFO : EPOCH - 14 : training on 5920713 raw words (4441819 effective words) took 7.6s, 585558 effective words/s\n",
      "2018-11-08 10:15:41,863 : INFO : EPOCH 15 - PROGRESS: at 13.23% examples, 580764 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:42,860 : INFO : EPOCH 15 - PROGRESS: at 26.29% examples, 583405 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:43,856 : INFO : EPOCH 15 - PROGRESS: at 39.13% examples, 579605 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:44,850 : INFO : EPOCH 15 - PROGRESS: at 52.35% examples, 581530 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:45,866 : INFO : EPOCH 15 - PROGRESS: at 65.69% examples, 582853 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:46,868 : INFO : EPOCH 15 - PROGRESS: at 78.86% examples, 582606 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:47,886 : INFO : EPOCH 15 - PROGRESS: at 92.41% examples, 584144 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:48,389 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:48,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:48,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:48,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:48,406 : INFO : EPOCH - 15 : training on 5920713 raw words (4441546 effective words) took 7.6s, 585488 effective words/s\n",
      "2018-11-08 10:15:49,422 : INFO : EPOCH 16 - PROGRESS: at 12.06% examples, 539196 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:50,439 : INFO : EPOCH 16 - PROGRESS: at 24.85% examples, 555619 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:51,442 : INFO : EPOCH 16 - PROGRESS: at 38.26% examples, 571241 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:52,436 : INFO : EPOCH 16 - PROGRESS: at 51.52% examples, 574771 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:53,452 : INFO : EPOCH 16 - PROGRESS: at 65.07% examples, 578649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:54,465 : INFO : EPOCH 16 - PROGRESS: at 78.52% examples, 580908 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:55,463 : INFO : EPOCH 16 - PROGRESS: at 91.89% examples, 582089 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:56,020 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:15:56,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:15:56,037 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:15:56,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:15:56,037 : INFO : EPOCH - 16 : training on 5920713 raw words (4441380 effective words) took 7.6s, 583079 effective words/s\n",
      "2018-11-08 10:15:57,066 : INFO : EPOCH 17 - PROGRESS: at 13.36% examples, 580864 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:15:58,075 : INFO : EPOCH 17 - PROGRESS: at 26.78% examples, 591452 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:15:59,085 : INFO : EPOCH 17 - PROGRESS: at 40.37% examples, 595596 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:00,113 : INFO : EPOCH 17 - PROGRESS: at 53.56% examples, 592491 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:01,130 : INFO : EPOCH 17 - PROGRESS: at 67.50% examples, 592275 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:02,145 : INFO : EPOCH 17 - PROGRESS: at 81.30% examples, 594239 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:03,160 : INFO : EPOCH 17 - PROGRESS: at 94.97% examples, 594134 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:03,491 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:03,506 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:03,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:03,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:03,522 : INFO : EPOCH - 17 : training on 5920713 raw words (4441063 effective words) took 7.5s, 595107 effective words/s\n",
      "2018-11-08 10:16:04,540 : INFO : EPOCH 18 - PROGRESS: at 13.36% examples, 585181 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:05,546 : INFO : EPOCH 18 - PROGRESS: at 26.63% examples, 589466 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:16:06,547 : INFO : EPOCH 18 - PROGRESS: at 40.37% examples, 596681 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:07,579 : INFO : EPOCH 18 - PROGRESS: at 53.74% examples, 594062 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:08,583 : INFO : EPOCH 18 - PROGRESS: at 67.16% examples, 592627 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:09,600 : INFO : EPOCH 18 - PROGRESS: at 80.78% examples, 592291 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:10,611 : INFO : EPOCH 18 - PROGRESS: at 94.64% examples, 593927 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:10,963 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:10,979 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:10,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:10,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:10,994 : INFO : EPOCH - 18 : training on 5920713 raw words (4441804 effective words) took 7.5s, 594611 effective words/s\n",
      "2018-11-08 10:16:12,025 : INFO : EPOCH 19 - PROGRESS: at 13.36% examples, 586160 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:16:13,058 : INFO : EPOCH 19 - PROGRESS: at 26.48% examples, 575921 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:14,055 : INFO : EPOCH 19 - PROGRESS: at 39.71% examples, 579978 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:15,057 : INFO : EPOCH 19 - PROGRESS: at 52.93% examples, 583915 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:16,076 : INFO : EPOCH 19 - PROGRESS: at 66.66% examples, 586378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:17,104 : INFO : EPOCH 19 - PROGRESS: at 80.12% examples, 584579 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:18,106 : INFO : EPOCH 19 - PROGRESS: at 92.94% examples, 581702 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:18,562 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:18,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:18,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:18,609 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:18,609 : INFO : EPOCH - 19 : training on 5920713 raw words (4440868 effective words) took 7.6s, 583820 effective words/s\n",
      "2018-11-08 10:16:19,642 : INFO : EPOCH 20 - PROGRESS: at 13.36% examples, 584624 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:16:20,659 : INFO : EPOCH 20 - PROGRESS: at 27.12% examples, 595863 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:21,664 : INFO : EPOCH 20 - PROGRESS: at 40.53% examples, 594788 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:22,702 : INFO : EPOCH 20 - PROGRESS: at 53.40% examples, 584358 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:16:23,690 : INFO : EPOCH 20 - PROGRESS: at 66.02% examples, 578076 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:24,715 : INFO : EPOCH 20 - PROGRESS: at 79.56% examples, 581112 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:25,710 : INFO : EPOCH 20 - PROGRESS: at 93.50% examples, 583916 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:26,177 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:26,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:26,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:26,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:26,177 : INFO : EPOCH - 20 : training on 5920713 raw words (4441468 effective words) took 7.6s, 586879 effective words/s\n",
      "2018-11-08 10:16:26,177 : INFO : training on a 118414260 raw words (88826266 effective words) took 159.3s, 557641 effective words/s\n",
      "2018-11-08 10:16:26,177 : INFO : training model with 4 workers on 46351 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 10:16:27,193 : INFO : EPOCH 1 - PROGRESS: at 35.00% examples, 1565271 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:28,193 : INFO : EPOCH 1 - PROGRESS: at 69.59% examples, 1550044 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:29,053 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:29,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:29,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:29,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:29,068 : INFO : EPOCH - 1 : training on 5920713 raw words (4440504 effective words) took 2.9s, 1543550 effective words/s\n",
      "2018-11-08 10:16:30,070 : INFO : EPOCH 2 - PROGRESS: at 34.51% examples, 1546444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:31,074 : INFO : EPOCH 2 - PROGRESS: at 67.50% examples, 1504575 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:31,997 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:32,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:32,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:32,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:32,013 : INFO : EPOCH - 2 : training on 5920713 raw words (4440818 effective words) took 2.9s, 1509958 effective words/s\n",
      "2018-11-08 10:16:33,031 : INFO : EPOCH 3 - PROGRESS: at 35.10% examples, 1563895 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:34,025 : INFO : EPOCH 3 - PROGRESS: at 69.91% examples, 1550769 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:34,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:34,881 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:34,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:34,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:34,897 : INFO : EPOCH - 3 : training on 5920713 raw words (4442477 effective words) took 2.9s, 1545816 effective words/s\n",
      "2018-11-08 10:16:35,900 : INFO : EPOCH 4 - PROGRESS: at 35.10% examples, 1571549 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:36,902 : INFO : EPOCH 4 - PROGRESS: at 70.25% examples, 1560782 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:37,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:37,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:37,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:37,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:37,761 : INFO : EPOCH - 4 : training on 5920713 raw words (4441597 effective words) took 2.9s, 1554558 effective words/s\n",
      "2018-11-08 10:16:38,763 : INFO : EPOCH 5 - PROGRESS: at 35.10% examples, 1573180 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:39,781 : INFO : EPOCH 5 - PROGRESS: at 69.59% examples, 1543400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:40,611 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:40,611 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:40,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:40,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:40,642 : INFO : EPOCH - 5 : training on 5920713 raw words (4441838 effective words) took 2.9s, 1543380 effective words/s\n",
      "2018-11-08 10:16:41,644 : INFO : EPOCH 6 - PROGRESS: at 35.00% examples, 1560882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:42,648 : INFO : EPOCH 6 - PROGRESS: at 69.58% examples, 1548573 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:43,508 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:43,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:16:43,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:43,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:43,523 : INFO : EPOCH - 6 : training on 5920713 raw words (4440696 effective words) took 2.9s, 1540574 effective words/s\n",
      "2018-11-08 10:16:44,542 : INFO : EPOCH 7 - PROGRESS: at 35.00% examples, 1566768 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:45,544 : INFO : EPOCH 7 - PROGRESS: at 69.59% examples, 1549219 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:46,389 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:46,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:46,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:46,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:46,405 : INFO : EPOCH - 7 : training on 5920713 raw words (4441582 effective words) took 2.9s, 1546610 effective words/s\n",
      "2018-11-08 10:16:47,410 : INFO : EPOCH 8 - PROGRESS: at 35.10% examples, 1573072 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:48,411 : INFO : EPOCH 8 - PROGRESS: at 69.90% examples, 1559440 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:49,270 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:49,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:49,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:49,286 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:49,301 : INFO : EPOCH - 8 : training on 5920713 raw words (4441573 effective words) took 2.9s, 1540569 effective words/s\n",
      "2018-11-08 10:16:50,304 : INFO : EPOCH 9 - PROGRESS: at 33.17% examples, 1478767 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:16:51,307 : INFO : EPOCH 9 - PROGRESS: at 67.68% examples, 1505532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:52,215 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:52,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:52,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:52,216 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:52,216 : INFO : EPOCH - 9 : training on 5920713 raw words (4440543 effective words) took 2.9s, 1516797 effective words/s\n",
      "2018-11-08 10:16:53,230 : INFO : EPOCH 10 - PROGRESS: at 35.10% examples, 1570171 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:54,230 : INFO : EPOCH 10 - PROGRESS: at 69.59% examples, 1550486 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:55,098 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:55,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:55,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:55,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:55,113 : INFO : EPOCH - 10 : training on 5920713 raw words (4440539 effective words) took 2.9s, 1543792 effective words/s\n",
      "2018-11-08 10:16:56,112 : INFO : EPOCH 11 - PROGRESS: at 35.10% examples, 1566724 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:57,120 : INFO : EPOCH 11 - PROGRESS: at 69.91% examples, 1554749 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:57,965 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:16:57,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:16:57,966 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:16:57,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:16:57,966 : INFO : EPOCH - 11 : training on 5920713 raw words (4440960 effective words) took 2.9s, 1550140 effective words/s\n",
      "2018-11-08 10:16:58,970 : INFO : EPOCH 12 - PROGRESS: at 35.10% examples, 1565155 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:16:59,990 : INFO : EPOCH 12 - PROGRESS: at 68.33% examples, 1516813 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:00,930 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:00,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:00,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:00,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:00,945 : INFO : EPOCH - 12 : training on 5920713 raw words (4440915 effective words) took 3.0s, 1498359 effective words/s\n",
      "2018-11-08 10:17:01,937 : INFO : EPOCH 13 - PROGRESS: at 31.18% examples, 1387905 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:02,969 : INFO : EPOCH 13 - PROGRESS: at 63.47% examples, 1409806 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:03,945 : INFO : EPOCH 13 - PROGRESS: at 87.67% examples, 1297890 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:04,339 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:04,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:04,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:04,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:04,356 : INFO : EPOCH - 13 : training on 5920713 raw words (4441162 effective words) took 3.4s, 1296110 effective words/s\n",
      "2018-11-08 10:17:05,390 : INFO : EPOCH 14 - PROGRESS: at 33.68% examples, 1498473 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:06,395 : INFO : EPOCH 14 - PROGRESS: at 67.68% examples, 1500111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:07,334 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:07,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:07,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:07,349 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:07,349 : INFO : EPOCH - 14 : training on 5920713 raw words (4441815 effective words) took 3.0s, 1493065 effective words/s\n",
      "2018-11-08 10:17:08,353 : INFO : EPOCH 15 - PROGRESS: at 34.18% examples, 1526848 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:09,348 : INFO : EPOCH 15 - PROGRESS: at 66.35% examples, 1476578 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:10,355 : INFO : EPOCH 15 - PROGRESS: at 93.31% examples, 1377375 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:10,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:10,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:10,621 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:10,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:10,624 : INFO : EPOCH - 15 : training on 5920713 raw words (4441684 effective words) took 3.3s, 1352854 effective words/s\n",
      "2018-11-08 10:17:11,659 : INFO : EPOCH 16 - PROGRESS: at 29.86% examples, 1335119 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:12,639 : INFO : EPOCH 16 - PROGRESS: at 62.98% examples, 1402382 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:13,642 : INFO : EPOCH 16 - PROGRESS: at 93.85% examples, 1386000 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:13,823 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:13,824 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:13,824 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:13,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:13,824 : INFO : EPOCH - 16 : training on 5920713 raw words (4441741 effective words) took 3.2s, 1392208 effective words/s\n",
      "2018-11-08 10:17:14,832 : INFO : EPOCH 17 - PROGRESS: at 32.68% examples, 1458593 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:15,832 : INFO : EPOCH 17 - PROGRESS: at 59.41% examples, 1325774 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:16,860 : INFO : EPOCH 17 - PROGRESS: at 92.24% examples, 1363534 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:17:17,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:17,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:17,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:17,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:17,081 : INFO : EPOCH - 17 : training on 5920713 raw words (4441351 effective words) took 3.2s, 1375103 effective words/s\n",
      "2018-11-08 10:17:18,083 : INFO : EPOCH 18 - PROGRESS: at 34.51% examples, 1541784 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:19,085 : INFO : EPOCH 18 - PROGRESS: at 69.59% examples, 1548530 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:19,942 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:19,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:19,942 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:19,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:19,942 : INFO : EPOCH - 18 : training on 5920713 raw words (4440682 effective words) took 2.9s, 1542540 effective words/s\n",
      "2018-11-08 10:17:20,968 : INFO : EPOCH 19 - PROGRESS: at 33.34% examples, 1486079 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:21,984 : INFO : EPOCH 19 - PROGRESS: at 68.33% examples, 1518075 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:22,861 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:22,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:22,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:22,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:22,877 : INFO : EPOCH - 19 : training on 5920713 raw words (4441336 effective words) took 2.9s, 1526852 effective words/s\n",
      "2018-11-08 10:17:23,879 : INFO : EPOCH 20 - PROGRESS: at 30.37% examples, 1361708 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:24,874 : INFO : EPOCH 20 - PROGRESS: at 65.07% examples, 1440978 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:25,898 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:25,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:25,898 : INFO : EPOCH 20 - PROGRESS: at 99.82% examples, 1470260 words/s, in_qsize 1, out_qsize 1\n",
      "2018-11-08 10:17:25,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:25,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:25,898 : INFO : EPOCH - 20 : training on 5920713 raw words (4441608 effective words) took 3.0s, 1469216 effective words/s\n",
      "2018-11-08 10:17:25,898 : INFO : training on a 118414260 raw words (88825421 effective words) took 59.7s, 1487309 effective words/s\n",
      "2018-11-08 10:17:25,913 : INFO : training model with 4 workers on 46351 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 10:17:26,919 : INFO : EPOCH 1 - PROGRESS: at 25.17% examples, 1125168 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:27,918 : INFO : EPOCH 1 - PROGRESS: at 50.01% examples, 1119324 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:28,920 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 1121439 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:29,859 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:29,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:29,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:29,874 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:29,874 : INFO : EPOCH - 1 : training on 5920713 raw words (4442082 effective words) took 4.0s, 1120514 effective words/s\n",
      "2018-11-08 10:17:30,892 : INFO : EPOCH 2 - PROGRESS: at 25.34% examples, 1132039 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:31,871 : INFO : EPOCH 2 - PROGRESS: at 50.01% examples, 1115251 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:32,895 : INFO : EPOCH 2 - PROGRESS: at 75.23% examples, 1115860 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:33,834 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:33,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:33,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:33,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:33,865 : INFO : EPOCH - 2 : training on 5920713 raw words (4441933 effective words) took 4.0s, 1117770 effective words/s\n",
      "2018-11-08 10:17:34,867 : INFO : EPOCH 3 - PROGRESS: at 24.50% examples, 1096875 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:35,878 : INFO : EPOCH 3 - PROGRESS: at 49.22% examples, 1096687 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:36,868 : INFO : EPOCH 3 - PROGRESS: at 74.22% examples, 1101193 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:37,876 : INFO : EPOCH 3 - PROGRESS: at 99.38% examples, 1099751 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-08 10:17:37,876 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:37,892 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:37,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:37,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:37,907 : INFO : EPOCH - 3 : training on 5920713 raw words (4440774 effective words) took 4.0s, 1098990 effective words/s\n",
      "2018-11-08 10:17:38,907 : INFO : EPOCH 4 - PROGRESS: at 24.85% examples, 1107680 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:39,909 : INFO : EPOCH 4 - PROGRESS: at 49.85% examples, 1113549 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:40,926 : INFO : EPOCH 4 - PROGRESS: at 75.23% examples, 1112015 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:41,882 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:41,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:41,882 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:41,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:41,898 : INFO : EPOCH - 4 : training on 5920713 raw words (4439294 effective words) took 4.0s, 1114584 effective words/s\n",
      "2018-11-08 10:17:42,901 : INFO : EPOCH 5 - PROGRESS: at 25.34% examples, 1129758 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:43,904 : INFO : EPOCH 5 - PROGRESS: at 50.69% examples, 1127688 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:44,907 : INFO : EPOCH 5 - PROGRESS: at 75.23% examples, 1113299 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:45,861 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:45,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:45,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:45,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:45,877 : INFO : EPOCH - 5 : training on 5920713 raw words (4441037 effective words) took 4.0s, 1115543 effective words/s\n",
      "2018-11-08 10:17:46,891 : INFO : EPOCH 6 - PROGRESS: at 25.34% examples, 1127043 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:47,892 : INFO : EPOCH 6 - PROGRESS: at 50.54% examples, 1123124 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:48,907 : INFO : EPOCH 6 - PROGRESS: at 75.94% examples, 1121444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:49,895 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:17:49,911 : INFO : EPOCH 6 - PROGRESS: at 99.73% examples, 1098281 words/s, in_qsize 1, out_qsize 3\n",
      "2018-11-08 10:17:49,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:49,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:49,926 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:49,926 : INFO : EPOCH - 6 : training on 5920713 raw words (4439483 effective words) took 4.0s, 1098649 effective words/s\n",
      "2018-11-08 10:17:50,926 : INFO : EPOCH 7 - PROGRESS: at 25.34% examples, 1129489 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:51,914 : INFO : EPOCH 7 - PROGRESS: at 50.19% examples, 1119067 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:52,939 : INFO : EPOCH 7 - PROGRESS: at 75.42% examples, 1116264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:53,877 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:53,892 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:53,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:53,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:53,908 : INFO : EPOCH - 7 : training on 5920713 raw words (4441261 effective words) took 4.0s, 1116946 effective words/s\n",
      "2018-11-08 10:17:54,915 : INFO : EPOCH 8 - PROGRESS: at 25.34% examples, 1130454 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:55,918 : INFO : EPOCH 8 - PROGRESS: at 50.54% examples, 1125305 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:17:56,920 : INFO : EPOCH 8 - PROGRESS: at 75.94% examples, 1125612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:57,850 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:17:57,866 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:17:57,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:17:57,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:17:57,882 : INFO : EPOCH - 8 : training on 5920713 raw words (4441490 effective words) took 4.0s, 1119841 effective words/s\n",
      "2018-11-08 10:17:58,883 : INFO : EPOCH 9 - PROGRESS: at 25.34% examples, 1131305 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:17:59,902 : INFO : EPOCH 9 - PROGRESS: at 49.85% examples, 1105499 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:00,902 : INFO : EPOCH 9 - PROGRESS: at 73.41% examples, 1084713 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:01,904 : INFO : EPOCH 9 - PROGRESS: at 99.04% examples, 1092030 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 10:18:01,935 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:01,935 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:01,935 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:01,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:01,951 : INFO : EPOCH - 9 : training on 5920713 raw words (4440119 effective words) took 4.1s, 1091358 effective words/s\n",
      "2018-11-08 10:18:02,962 : INFO : EPOCH 10 - PROGRESS: at 24.68% examples, 1102335 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:03,963 : INFO : EPOCH 10 - PROGRESS: at 49.85% examples, 1110261 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:04,957 : INFO : EPOCH 10 - PROGRESS: at 75.23% examples, 1110149 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:05,976 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:05,976 : INFO : EPOCH 10 - PROGRESS: at 99.73% examples, 1099312 words/s, in_qsize 2, out_qsize 1\n",
      "2018-11-08 10:18:05,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:05,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:05,992 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:05,992 : INFO : EPOCH - 10 : training on 5920713 raw words (4441285 effective words) took 4.0s, 1100397 effective words/s\n",
      "2018-11-08 10:18:07,011 : INFO : EPOCH 11 - PROGRESS: at 25.34% examples, 1118085 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:18:08,017 : INFO : EPOCH 11 - PROGRESS: at 50.54% examples, 1118807 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:09,017 : INFO : EPOCH 11 - PROGRESS: at 75.42% examples, 1113354 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:09,972 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:09,987 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:09,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:09,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:09,987 : INFO : EPOCH - 11 : training on 5920713 raw words (4440488 effective words) took 4.0s, 1112134 effective words/s\n",
      "2018-11-08 10:18:11,002 : INFO : EPOCH 12 - PROGRESS: at 25.34% examples, 1127857 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:12,004 : INFO : EPOCH 12 - PROGRESS: at 50.69% examples, 1128863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:13,004 : INFO : EPOCH 12 - PROGRESS: at 75.24% examples, 1115210 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:14,001 : INFO : EPOCH 12 - PROGRESS: at 98.67% examples, 1091963 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:14,029 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:14,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:14,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:14,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:14,044 : INFO : EPOCH - 12 : training on 5920713 raw words (4440686 effective words) took 4.1s, 1090311 effective words/s\n",
      "2018-11-08 10:18:15,075 : INFO : EPOCH 13 - PROGRESS: at 24.85% examples, 1109586 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:16,077 : INFO : EPOCH 13 - PROGRESS: at 49.85% examples, 1109696 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:18:17,096 : INFO : EPOCH 13 - PROGRESS: at 75.23% examples, 1112935 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:18,035 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:18,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:18,051 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:18,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:18,051 : INFO : EPOCH - 13 : training on 5920713 raw words (4441731 effective words) took 4.0s, 1115473 effective words/s\n",
      "2018-11-08 10:18:19,069 : INFO : EPOCH 14 - PROGRESS: at 25.34% examples, 1123479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:20,076 : INFO : EPOCH 14 - PROGRESS: at 50.69% examples, 1127249 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:21,065 : INFO : EPOCH 14 - PROGRESS: at 76.28% examples, 1129025 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:21,989 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:21,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:22,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:22,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:22,012 : INFO : EPOCH - 14 : training on 5920713 raw words (4439582 effective words) took 4.0s, 1116299 effective words/s\n",
      "2018-11-08 10:18:23,042 : INFO : EPOCH 15 - PROGRESS: at 25.01% examples, 1115296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:24,051 : INFO : EPOCH 15 - PROGRESS: at 47.31% examples, 1053656 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:25,054 : INFO : EPOCH 15 - PROGRESS: at 72.79% examples, 1079764 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:26,056 : INFO : EPOCH 15 - PROGRESS: at 98.28% examples, 1088559 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:26,102 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:26,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:26,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:26,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:26,134 : INFO : EPOCH - 15 : training on 5920713 raw words (4440168 effective words) took 4.1s, 1085659 effective words/s\n",
      "2018-11-08 10:18:27,135 : INFO : EPOCH 16 - PROGRESS: at 24.68% examples, 1097864 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:18:28,146 : INFO : EPOCH 16 - PROGRESS: at 49.22% examples, 1097685 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:29,149 : INFO : EPOCH 16 - PROGRESS: at 74.57% examples, 1104577 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:30,122 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:30,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:30,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:30,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:30,123 : INFO : EPOCH - 16 : training on 5920713 raw words (4441399 effective words) took 4.0s, 1108990 effective words/s\n",
      "2018-11-08 10:18:31,142 : INFO : EPOCH 17 - PROGRESS: at 25.17% examples, 1123670 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:18:32,144 : INFO : EPOCH 17 - PROGRESS: at 50.54% examples, 1128576 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:33,163 : INFO : EPOCH 17 - PROGRESS: at 75.94% examples, 1121582 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:34,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:34,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:34,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:34,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:34,103 : INFO : EPOCH - 17 : training on 5920713 raw words (4440678 effective words) took 4.0s, 1121414 effective words/s\n",
      "2018-11-08 10:18:35,122 : INFO : EPOCH 18 - PROGRESS: at 25.50% examples, 1136820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:36,127 : INFO : EPOCH 18 - PROGRESS: at 50.01% examples, 1113768 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:37,117 : INFO : EPOCH 18 - PROGRESS: at 75.77% examples, 1122618 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:38,056 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:38,071 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:38,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:38,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:38,087 : INFO : EPOCH - 18 : training on 5920713 raw words (4441185 effective words) took 4.0s, 1118017 effective words/s\n",
      "2018-11-08 10:18:39,090 : INFO : EPOCH 19 - PROGRESS: at 25.34% examples, 1127084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:40,107 : INFO : EPOCH 19 - PROGRESS: at 50.69% examples, 1124573 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:41,100 : INFO : EPOCH 19 - PROGRESS: at 75.94% examples, 1116780 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:42,046 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:42,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:42,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:42,061 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:42,061 : INFO : EPOCH - 19 : training on 5920713 raw words (4442323 effective words) took 4.0s, 1115589 effective words/s\n",
      "2018-11-08 10:18:43,080 : INFO : EPOCH 20 - PROGRESS: at 25.34% examples, 1130450 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:44,083 : INFO : EPOCH 20 - PROGRESS: at 50.54% examples, 1126462 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:18:45,088 : INFO : EPOCH 20 - PROGRESS: at 75.94% examples, 1124855 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:18:46,063 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:18:46,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:18:46,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:18:46,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:18:46,079 : INFO : EPOCH - 20 : training on 5920713 raw words (4441223 effective words) took 4.0s, 1109397 effective words/s\n",
      "2018-11-08 10:18:46,079 : INFO : training on a 118414260 raw words (88818221 effective words) took 80.2s, 1107880 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m2 = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m3 = Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m1.build_vocab(taggedDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "m3.reset_from(m1)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "# Train each model on the labeled training data\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m3.train(taggedDocs, total_examples = m3.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination one:  Train and assess classifiers\n",
    "\n",
    "Notice below how we iterate through the document vectors from both models and combine them with `np.hstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:30:27.244600Z",
     "start_time": "2018-11-08T17:18:46.094941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(xTrain) 25000\n",
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "0    LR   0.88624  0.007783\n",
      "1   LDA   0.88556  0.005966\n",
      "2   SVM   0.88464  0.008174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "xTrain = []\n",
    "\n",
    "for i in range(0, len(taggedDocs)):\n",
    "    xTrain.append(np.hstack((m1.docvecs[i], m2.docvecs[i])))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))\n",
    "\n",
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination two:  Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:42:03.840443Z",
     "start_time": "2018-11-08T17:30:27.246600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(xTrain) 25000\n",
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "2   SVM   0.88676  0.006982\n",
      "1   LDA   0.88548  0.006833\n",
      "0    LR   0.88536  0.007341\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m2 and m3)\n",
    "xTrain = []\n",
    "\n",
    "for i in range(0, len(taggedDocs)):\n",
    "    xTrain.append(np.hstack((m2.docvecs[i], m3.docvecs[i])))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))\n",
    "\n",
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "We actually dropped a tiny amount in of accuracy from the previous section although it doesn't appear to be statistically significant.  Let's try again, but now we'll expand the corpus the models have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increased vocabulary and combined Doc2Vec models\n",
    "\n",
    "What if we increase the size of the vocabulary the Doc2Vec model has access to?  In order to do this we'll feed all the review text we have--labeled and unlabeled--into the model's and then train and evaluate as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and combine unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:42:05.134619Z",
     "start_time": "2018-11-08T17:42:03.840443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in the unlabeled data since it can also be utilized by Doc2Vec when building the vocab\n",
    "unlabeledTrainData = os.path.join(dataPath, 'unlabeledTrainData.tsv')\n",
    "dfUn = pd.read_csv(unlabeledTrainData, sep = '\\t', header = 0, quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:43:21.571881Z",
     "start_time": "2018-11-08T17:42:05.134619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an all document object we can pass to the models\n",
    "allDocs = taggedDocs.copy()\n",
    "\n",
    "for s in dfUn.iloc[:,1]:\n",
    "    clean = cleanReview(s)\n",
    "    i = len(allDocs)\n",
    "    allDocs.append(TaggedDocument(clean, [i]))    \n",
    "                   \n",
    "len(allDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Doc2Vec models, build vocabulary, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:48:51.959629Z",
     "start_time": "2018-11-08T17:43:21.573881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:43:22,058 : INFO : using concatenative 1100-dimensional layer1\n",
      "2018-11-08 10:43:22,105 : INFO : collecting all words and their counts\n",
      "2018-11-08 10:43:22,105 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-08 10:43:22,542 : INFO : PROGRESS: at example #10000, processed 2385574 words (5529162/s), 51527 word types, 10000 tags\n",
      "2018-11-08 10:43:22,973 : INFO : PROGRESS: at example #20000, processed 4747503 words (5514805/s), 67813 word types, 20000 tags\n",
      "2018-11-08 10:43:23,410 : INFO : PROGRESS: at example #30000, processed 7100124 words (5438152/s), 81670 word types, 30000 tags\n",
      "2018-11-08 10:43:23,879 : INFO : PROGRESS: at example #40000, processed 9467843 words (5051349/s), 93389 word types, 40000 tags\n",
      "2018-11-08 10:43:24,362 : INFO : PROGRESS: at example #50000, processed 11865784 words (4970663/s), 103474 word types, 50000 tags\n",
      "2018-11-08 10:43:24,864 : INFO : PROGRESS: at example #60000, processed 14248889 words (4732126/s), 112175 word types, 60000 tags\n",
      "2018-11-08 10:43:25,363 : INFO : PROGRESS: at example #70000, processed 16609485 words (4733765/s), 119831 word types, 70000 tags\n",
      "2018-11-08 10:43:25,597 : INFO : collected 123504 word types and 75000 unique tags from a corpus of 75000 examples and 17797887 words\n",
      "2018-11-08 10:43:25,612 : INFO : Loading a fresh vocabulary\n",
      "2018-11-08 10:43:26,053 : INFO : effective_min_count=2 retains 74452 unique words (60% of original 123504, drops 49052)\n",
      "2018-11-08 10:43:26,053 : INFO : effective_min_count=2 leaves 17748835 word corpus (99% of original 17797887, drops 49052)\n",
      "2018-11-08 10:43:26,271 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2018-11-08 10:43:26,287 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-08 10:43:26,287 : INFO : downsampling leaves estimated 13317683 word corpus (75.0% of prior 17748835)\n",
      "2018-11-08 10:43:26,569 : INFO : estimated required memory for 74452 words and 100 dimensions: 424595600 bytes\n",
      "2018-11-08 10:43:26,569 : INFO : resetting layer weights\n",
      "2018-11-08 10:43:28,250 : INFO : resetting layer weights\n",
      "2018-11-08 10:43:29,909 : INFO : resetting layer weights\n",
      "2018-11-08 10:43:31,606 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 10:43:32,656 : INFO : EPOCH 1 - PROGRESS: at 2.31% examples, 301163 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:43:33,707 : INFO : EPOCH 1 - PROGRESS: at 5.01% examples, 324201 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:34,742 : INFO : EPOCH 1 - PROGRESS: at 7.75% examples, 334961 words/s, in_qsize 4, out_qsize 3\n",
      "2018-11-08 10:43:35,767 : INFO : EPOCH 1 - PROGRESS: at 11.06% examples, 359463 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:36,772 : INFO : EPOCH 1 - PROGRESS: at 14.83% examples, 386954 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:37,775 : INFO : EPOCH 1 - PROGRESS: at 18.30% examples, 400501 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:38,787 : INFO : EPOCH 1 - PROGRESS: at 22.12% examples, 414168 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:39,793 : INFO : EPOCH 1 - PROGRESS: at 25.49% examples, 418245 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:40,835 : INFO : EPOCH 1 - PROGRESS: at 29.34% examples, 427560 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:41,808 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:43:41,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:43:41,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:43:41,823 : INFO : EPOCH 1 - PROGRESS: at 33.33% examples, 436005 words/s, in_qsize 0, out_qsize 1\n",
      "2018-11-08 10:43:41,839 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:43:41,839 : INFO : EPOCH - 1 : training on 5920713 raw words (4453454 effective words) took 10.2s, 435849 effective words/s\n",
      "2018-11-08 10:43:41,839 : WARNING : EPOCH - 1 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:43:42,854 : INFO : EPOCH 2 - PROGRESS: at 3.80% examples, 503573 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:43,853 : INFO : EPOCH 2 - PROGRESS: at 7.63% examples, 512447 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:44,870 : INFO : EPOCH 2 - PROGRESS: at 11.33% examples, 505534 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:45,888 : INFO : EPOCH 2 - PROGRESS: at 15.16% examples, 504411 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:46,898 : INFO : EPOCH 2 - PROGRESS: at 18.84% examples, 502170 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:43:47,913 : INFO : EPOCH 2 - PROGRESS: at 22.72% examples, 502575 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:48,928 : INFO : EPOCH 2 - PROGRESS: at 26.71% examples, 504505 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:49,946 : INFO : EPOCH 2 - PROGRESS: at 30.63% examples, 506325 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:50,586 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:43:50,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:43:50,587 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:43:50,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:43:50,591 : INFO : EPOCH - 2 : training on 5920713 raw words (4455143 effective words) took 8.8s, 507912 effective words/s\n",
      "2018-11-08 10:43:50,592 : WARNING : EPOCH - 2 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:43:51,634 : INFO : EPOCH 3 - PROGRESS: at 3.58% examples, 474918 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:43:52,668 : INFO : EPOCH 3 - PROGRESS: at 7.06% examples, 470809 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 10:43:53,667 : INFO : EPOCH 3 - PROGRESS: at 10.78% examples, 478174 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:54,677 : INFO : EPOCH 3 - PROGRESS: at 14.53% examples, 483304 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:55,677 : INFO : EPOCH 3 - PROGRESS: at 18.30% examples, 487882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:43:56,702 : INFO : EPOCH 3 - PROGRESS: at 22.16% examples, 489962 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:43:57,754 : INFO : EPOCH 3 - PROGRESS: at 26.06% examples, 490285 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 10:43:58,761 : INFO : EPOCH 3 - PROGRESS: at 30.05% examples, 494794 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:43:59,495 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:43:59,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:43:59,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:43:59,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:43:59,541 : INFO : EPOCH - 3 : training on 5920713 raw words (4453845 effective words) took 8.9s, 498887 effective words/s\n",
      "2018-11-08 10:43:59,541 : WARNING : EPOCH - 3 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:00,566 : INFO : EPOCH 4 - PROGRESS: at 3.80% examples, 509126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:01,557 : INFO : EPOCH 4 - PROGRESS: at 7.67% examples, 519591 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:02,587 : INFO : EPOCH 4 - PROGRESS: at 11.50% examples, 512544 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:03,603 : INFO : EPOCH 4 - PROGRESS: at 15.39% examples, 511785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:04,624 : INFO : EPOCH 4 - PROGRESS: at 19.31% examples, 512708 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:05,620 : INFO : EPOCH 4 - PROGRESS: at 23.30% examples, 514709 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:06,629 : INFO : EPOCH 4 - PROGRESS: at 27.40% examples, 517988 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:07,660 : INFO : EPOCH 4 - PROGRESS: at 31.34% examples, 517271 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:08,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:08,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:08,159 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:08,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:08,175 : INFO : EPOCH - 4 : training on 5920713 raw words (4454084 effective words) took 8.6s, 517106 effective words/s\n",
      "2018-11-08 10:44:08,175 : WARNING : EPOCH - 4 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:09,219 : INFO : EPOCH 5 - PROGRESS: at 3.81% examples, 493142 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:10,218 : INFO : EPOCH 5 - PROGRESS: at 7.67% examples, 509589 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:11,220 : INFO : EPOCH 5 - PROGRESS: at 11.50% examples, 508940 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:12,230 : INFO : EPOCH 5 - PROGRESS: at 15.39% examples, 511073 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:44:13,236 : INFO : EPOCH 5 - PROGRESS: at 19.40% examples, 517004 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:14,241 : INFO : EPOCH 5 - PROGRESS: at 23.47% examples, 520221 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:15,248 : INFO : EPOCH 5 - PROGRESS: at 27.02% examples, 512509 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:16,287 : INFO : EPOCH 5 - PROGRESS: at 31.04% examples, 512783 words/s, in_qsize 7, out_qsize 2\n",
      "2018-11-08 10:44:16,817 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:16,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:16,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:16,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:16,864 : INFO : EPOCH - 5 : training on 5920713 raw words (4454181 effective words) took 8.7s, 513130 effective words/s\n",
      "2018-11-08 10:44:16,864 : WARNING : EPOCH - 5 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:17,894 : INFO : EPOCH 6 - PROGRESS: at 3.52% examples, 461617 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:18,910 : INFO : EPOCH 6 - PROGRESS: at 7.22% examples, 482237 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:19,910 : INFO : EPOCH 6 - PROGRESS: at 11.28% examples, 501212 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:20,917 : INFO : EPOCH 6 - PROGRESS: at 15.32% examples, 510356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:21,909 : INFO : EPOCH 6 - PROGRESS: at 19.19% examples, 512759 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:44:22,926 : INFO : EPOCH 6 - PROGRESS: at 23.30% examples, 517462 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:23,944 : INFO : EPOCH 6 - PROGRESS: at 27.39% examples, 518772 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:44:24,959 : INFO : EPOCH 6 - PROGRESS: at 31.61% examples, 522413 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:25,349 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:25,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:25,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:25,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:25,365 : INFO : EPOCH - 6 : training on 5920713 raw words (4454282 effective words) took 8.5s, 524073 effective words/s\n",
      "2018-11-08 10:44:25,365 : WARNING : EPOCH - 6 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:26,382 : INFO : EPOCH 7 - PROGRESS: at 3.85% examples, 513921 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:27,440 : INFO : EPOCH 7 - PROGRESS: at 7.67% examples, 503789 words/s, in_qsize 8, out_qsize 3\n",
      "2018-11-08 10:44:28,460 : INFO : EPOCH 7 - PROGRESS: at 11.56% examples, 506836 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:44:29,488 : INFO : EPOCH 7 - PROGRESS: at 15.56% examples, 509986 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:30,475 : INFO : EPOCH 7 - PROGRESS: at 19.31% examples, 509595 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:31,479 : INFO : EPOCH 7 - PROGRESS: at 23.26% examples, 511778 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:32,498 : INFO : EPOCH 7 - PROGRESS: at 26.53% examples, 499414 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:33,534 : INFO : EPOCH 7 - PROGRESS: at 30.34% examples, 498910 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:34,236 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:34,252 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:34,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:34,268 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:34,268 : INFO : EPOCH - 7 : training on 5920713 raw words (4455444 effective words) took 8.9s, 501327 effective words/s\n",
      "2018-11-08 10:44:34,268 : WARNING : EPOCH - 7 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:35,274 : INFO : EPOCH 8 - PROGRESS: at 3.69% examples, 495507 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:36,278 : INFO : EPOCH 8 - PROGRESS: at 7.63% examples, 516224 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:37,290 : INFO : EPOCH 8 - PROGRESS: at 11.56% examples, 516927 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:38,326 : INFO : EPOCH 8 - PROGRESS: at 15.56% examples, 517291 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:39,330 : INFO : EPOCH 8 - PROGRESS: at 19.19% examples, 512065 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:40,331 : INFO : EPOCH 8 - PROGRESS: at 22.99% examples, 510064 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:41,338 : INFO : EPOCH 8 - PROGRESS: at 27.04% examples, 512941 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:42,350 : INFO : EPOCH 8 - PROGRESS: at 30.87% examples, 511362 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:44:42,913 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:42,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:42,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:42,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:42,929 : INFO : EPOCH - 8 : training on 5920713 raw words (4455027 effective words) took 8.7s, 514805 effective words/s\n",
      "2018-11-08 10:44:42,929 : WARNING : EPOCH - 8 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:43,942 : INFO : EPOCH 9 - PROGRESS: at 3.97% examples, 532600 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:44,956 : INFO : EPOCH 9 - PROGRESS: at 7.94% examples, 528616 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:45,990 : INFO : EPOCH 9 - PROGRESS: at 11.70% examples, 518728 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:47,015 : INFO : EPOCH 9 - PROGRESS: at 15.67% examples, 516719 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:48,009 : INFO : EPOCH 9 - PROGRESS: at 19.75% examples, 523648 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:49,053 : INFO : EPOCH 9 - PROGRESS: at 23.96% examples, 527115 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:50,065 : INFO : EPOCH 9 - PROGRESS: at 28.15% examples, 530047 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:51,061 : INFO : EPOCH 9 - PROGRESS: at 32.15% examples, 529016 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:51,357 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:44:51,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:44:51,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:44:51,373 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:44:51,373 : INFO : EPOCH - 9 : training on 5920713 raw words (4453743 effective words) took 8.4s, 527524 effective words/s\n",
      "2018-11-08 10:44:51,373 : WARNING : EPOCH - 9 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:44:52,404 : INFO : EPOCH 10 - PROGRESS: at 3.69% examples, 488406 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:44:53,407 : INFO : EPOCH 10 - PROGRESS: at 7.22% examples, 486835 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:54,404 : INFO : EPOCH 10 - PROGRESS: at 11.06% examples, 494412 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 10:44:55,406 : INFO : EPOCH 10 - PROGRESS: at 14.89% examples, 498011 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:44:56,417 : INFO : EPOCH 10 - PROGRESS: at 18.78% examples, 504220 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:44:57,431 : INFO : EPOCH 10 - PROGRESS: at 22.67% examples, 504100 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 10:44:58,445 : INFO : EPOCH 10 - PROGRESS: at 26.76% examples, 507309 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:44:59,459 : INFO : EPOCH 10 - PROGRESS: at 30.51% examples, 505960 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:00,163 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:00,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:00,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:00,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:00,209 : INFO : EPOCH - 10 : training on 5920713 raw words (4453607 effective words) took 8.8s, 505069 effective words/s\n",
      "2018-11-08 10:45:00,209 : WARNING : EPOCH - 10 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:01,224 : INFO : EPOCH 11 - PROGRESS: at 3.80% examples, 503145 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:02,249 : INFO : EPOCH 11 - PROGRESS: at 7.44% examples, 501004 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:03,253 : INFO : EPOCH 11 - PROGRESS: at 11.28% examples, 503725 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:04,276 : INFO : EPOCH 11 - PROGRESS: at 15.15% examples, 503625 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:45:05,296 : INFO : EPOCH 11 - PROGRESS: at 19.08% examples, 507032 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:45:06,314 : INFO : EPOCH 11 - PROGRESS: at 22.94% examples, 506638 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:07,315 : INFO : EPOCH 11 - PROGRESS: at 27.15% examples, 512926 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:08,321 : INFO : EPOCH 11 - PROGRESS: at 31.11% examples, 514201 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:08,831 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:08,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:08,863 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:08,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:08,863 : INFO : EPOCH - 11 : training on 5920713 raw words (4454185 effective words) took 8.6s, 516029 effective words/s\n",
      "2018-11-08 10:45:08,863 : WARNING : EPOCH - 11 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:09,875 : INFO : EPOCH 12 - PROGRESS: at 3.52% examples, 471616 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:10,892 : INFO : EPOCH 12 - PROGRESS: at 7.01% examples, 471339 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:45:11,900 : INFO : EPOCH 12 - PROGRESS: at 10.78% examples, 479066 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:45:12,915 : INFO : EPOCH 12 - PROGRESS: at 14.77% examples, 492081 words/s, in_qsize 6, out_qsize 2\n",
      "2018-11-08 10:45:13,910 : INFO : EPOCH 12 - PROGRESS: at 18.66% examples, 497363 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:45:14,929 : INFO : EPOCH 12 - PROGRESS: at 22.62% examples, 500767 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:15,936 : INFO : EPOCH 12 - PROGRESS: at 26.29% examples, 497267 words/s, in_qsize 4, out_qsize 3\n",
      "2018-11-08 10:45:16,937 : INFO : EPOCH 12 - PROGRESS: at 29.95% examples, 496128 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:45:17,939 : INFO : EPOCH 12 - PROGRESS: at 33.01% examples, 485277 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 10:45:17,963 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:17,991 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:18,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:18,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:18,027 : INFO : EPOCH - 12 : training on 5920713 raw words (4454864 effective words) took 9.2s, 485178 effective words/s\n",
      "2018-11-08 10:45:18,049 : WARNING : EPOCH - 12 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:19,080 : INFO : EPOCH 13 - PROGRESS: at 2.70% examples, 360407 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:45:20,163 : INFO : EPOCH 13 - PROGRESS: at 5.81% examples, 383422 words/s, in_qsize 4, out_qsize 4\n",
      "2018-11-08 10:45:21,178 : INFO : EPOCH 13 - PROGRESS: at 9.74% examples, 425643 words/s, in_qsize 4, out_qsize 6\n",
      "2018-11-08 10:45:22,186 : INFO : EPOCH 13 - PROGRESS: at 13.77% examples, 453192 words/s, in_qsize 7, out_qsize 3\n",
      "2018-11-08 10:45:23,216 : INFO : EPOCH 13 - PROGRESS: at 17.85% examples, 469857 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 10:45:24,243 : INFO : EPOCH 13 - PROGRESS: at 21.79% examples, 475965 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:25,289 : INFO : EPOCH 13 - PROGRESS: at 25.77% examples, 480897 words/s, in_qsize 6, out_qsize 2\n",
      "2018-11-08 10:45:26,300 : INFO : EPOCH 13 - PROGRESS: at 29.95% examples, 489037 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:27,024 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:27,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:27,055 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:27,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:27,055 : INFO : EPOCH - 13 : training on 5920713 raw words (4454380 effective words) took 9.0s, 496605 effective words/s\n",
      "2018-11-08 10:45:27,055 : WARNING : EPOCH - 13 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:28,063 : INFO : EPOCH 14 - PROGRESS: at 4.02% examples, 540617 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:45:29,055 : INFO : EPOCH 14 - PROGRESS: at 8.23% examples, 551980 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:30,100 : INFO : EPOCH 14 - PROGRESS: at 12.35% examples, 551121 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:31,090 : INFO : EPOCH 14 - PROGRESS: at 16.04% examples, 533781 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:32,112 : INFO : EPOCH 14 - PROGRESS: at 19.96% examples, 531022 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:33,136 : INFO : EPOCH 14 - PROGRESS: at 23.30% examples, 516502 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:34,167 : INFO : EPOCH 14 - PROGRESS: at 26.86% examples, 507274 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:35,184 : INFO : EPOCH 14 - PROGRESS: at 30.80% examples, 508135 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:35,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:35,739 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:35,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:35,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:35,770 : INFO : EPOCH - 14 : training on 5920713 raw words (4453413 effective words) took 8.7s, 511866 effective words/s\n",
      "2018-11-08 10:45:35,770 : WARNING : EPOCH - 14 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:36,786 : INFO : EPOCH 15 - PROGRESS: at 4.14% examples, 548773 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:37,805 : INFO : EPOCH 15 - PROGRESS: at 8.11% examples, 540755 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:38,819 : INFO : EPOCH 15 - PROGRESS: at 12.17% examples, 543375 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:45:39,830 : INFO : EPOCH 15 - PROGRESS: at 16.26% examples, 539569 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:40,860 : INFO : EPOCH 15 - PROGRESS: at 20.32% examples, 537749 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:45:41,867 : INFO : EPOCH 15 - PROGRESS: at 24.42% examples, 538859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:42,870 : INFO : EPOCH 15 - PROGRESS: at 28.48% examples, 538659 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:43,880 : INFO : EPOCH 15 - PROGRESS: at 32.76% examples, 540588 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:43,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:43,989 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:44,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:44,005 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:44,005 : INFO : EPOCH - 15 : training on 5920713 raw words (4454005 effective words) took 8.2s, 541347 effective words/s\n",
      "2018-11-08 10:45:44,005 : WARNING : EPOCH - 15 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:45,014 : INFO : EPOCH 16 - PROGRESS: at 4.02% examples, 537618 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:46,021 : INFO : EPOCH 16 - PROGRESS: at 8.17% examples, 548226 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:47,026 : INFO : EPOCH 16 - PROGRESS: at 12.19% examples, 547245 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:48,029 : INFO : EPOCH 16 - PROGRESS: at 16.41% examples, 549965 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:49,030 : INFO : EPOCH 16 - PROGRESS: at 20.53% examples, 550443 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:50,052 : INFO : EPOCH 16 - PROGRESS: at 24.86% examples, 553188 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:51,077 : INFO : EPOCH 16 - PROGRESS: at 29.00% examples, 551748 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:45:52,030 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:45:52,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:45:52,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:45:52,061 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:45:52,061 : INFO : EPOCH - 16 : training on 5920713 raw words (4454273 effective words) took 8.1s, 553160 effective words/s\n",
      "2018-11-08 10:45:52,061 : WARNING : EPOCH - 16 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:45:53,096 : INFO : EPOCH 17 - PROGRESS: at 4.14% examples, 544118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:45:54,096 : INFO : EPOCH 17 - PROGRESS: at 7.94% examples, 528530 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:55,089 : INFO : EPOCH 17 - PROGRESS: at 11.75% examples, 524598 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:45:56,116 : INFO : EPOCH 17 - PROGRESS: at 15.83% examples, 526387 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:57,141 : INFO : EPOCH 17 - PROGRESS: at 19.96% examples, 530069 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:58,187 : INFO : EPOCH 17 - PROGRESS: at 23.53% examples, 517504 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:45:59,201 : INFO : EPOCH 17 - PROGRESS: at 27.55% examples, 518699 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:00,205 : INFO : EPOCH 17 - PROGRESS: at 31.87% examples, 524266 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:46:00,502 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:00,517 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:00,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:00,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:00,517 : INFO : EPOCH - 17 : training on 5920713 raw words (4453612 effective words) took 8.4s, 527081 effective words/s\n",
      "2018-11-08 10:46:00,517 : WARNING : EPOCH - 17 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:01,541 : INFO : EPOCH 18 - PROGRESS: at 4.24% examples, 563290 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:02,548 : INFO : EPOCH 18 - PROGRESS: at 8.45% examples, 564385 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:03,548 : INFO : EPOCH 18 - PROGRESS: at 12.35% examples, 552099 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:04,565 : INFO : EPOCH 18 - PROGRESS: at 16.56% examples, 553959 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:05,556 : INFO : EPOCH 18 - PROGRESS: at 20.73% examples, 553879 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 10:46:06,573 : INFO : EPOCH 18 - PROGRESS: at 25.08% examples, 556944 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:07,595 : INFO : EPOCH 18 - PROGRESS: at 29.46% examples, 559351 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:08,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:08,457 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:08,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:08,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:08,457 : INFO : EPOCH - 18 : training on 5920713 raw words (4453979 effective words) took 7.9s, 561764 effective words/s\n",
      "2018-11-08 10:46:08,457 : WARNING : EPOCH - 18 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:09,475 : INFO : EPOCH 19 - PROGRESS: at 4.24% examples, 562552 words/s, in_qsize 7, out_qsize 2\n",
      "2018-11-08 10:46:10,496 : INFO : EPOCH 19 - PROGRESS: at 8.61% examples, 571984 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:11,498 : INFO : EPOCH 19 - PROGRESS: at 12.87% examples, 572034 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:12,513 : INFO : EPOCH 19 - PROGRESS: at 17.08% examples, 567201 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 10:46:13,511 : INFO : EPOCH 19 - PROGRESS: at 21.33% examples, 567434 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:14,518 : INFO : EPOCH 19 - PROGRESS: at 25.19% examples, 558627 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:15,564 : INFO : EPOCH 19 - PROGRESS: at 28.95% examples, 547490 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:16,564 : INFO : EPOCH 19 - PROGRESS: at 32.94% examples, 543729 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:16,611 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:16,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:16,627 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:16,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:16,627 : INFO : EPOCH - 19 : training on 5920713 raw words (4453882 effective words) took 8.2s, 545385 effective words/s\n",
      "2018-11-08 10:46:16,627 : WARNING : EPOCH - 19 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:17,619 : INFO : EPOCH 20 - PROGRESS: at 4.03% examples, 540431 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:18,643 : INFO : EPOCH 20 - PROGRESS: at 8.00% examples, 537521 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:19,628 : INFO : EPOCH 20 - PROGRESS: at 11.75% examples, 527933 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:20,660 : INFO : EPOCH 20 - PROGRESS: at 15.98% examples, 535340 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:21,688 : INFO : EPOCH 20 - PROGRESS: at 20.26% examples, 539443 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:22,708 : INFO : EPOCH 20 - PROGRESS: at 24.69% examples, 547085 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:23,716 : INFO : EPOCH 20 - PROGRESS: at 29.11% examples, 552240 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:24,637 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:24,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:24,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:24,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:46:24,669 : INFO : EPOCH - 20 : training on 5920713 raw words (4454510 effective words) took 8.0s, 554805 effective words/s\n",
      "2018-11-08 10:46:24,669 : WARNING : EPOCH - 20 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:24,669 : INFO : training on a 118414260 raw words (89083913 effective words) took 173.1s, 514755 effective words/s\n",
      "2018-11-08 10:46:24,669 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 10:46:25,684 : INFO : EPOCH 1 - PROGRESS: at 10.58% examples, 1418053 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:26,684 : INFO : EPOCH 1 - PROGRESS: at 21.58% examples, 1444106 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:27,683 : INFO : EPOCH 1 - PROGRESS: at 32.15% examples, 1429501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:27,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:27,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:27,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:27,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:27,793 : INFO : EPOCH - 1 : training on 5920713 raw words (4454752 effective words) took 3.1s, 1428090 effective words/s\n",
      "2018-11-08 10:46:27,808 : WARNING : EPOCH - 1 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:28,808 : INFO : EPOCH 2 - PROGRESS: at 11.23% examples, 1511662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:29,826 : INFO : EPOCH 2 - PROGRESS: at 22.22% examples, 1483216 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:30,825 : INFO : EPOCH 2 - PROGRESS: at 33.06% examples, 1460597 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 10:46:30,841 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:30,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:30,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:30,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:30,856 : INFO : EPOCH - 2 : training on 5920713 raw words (4454360 effective words) took 3.1s, 1459210 effective words/s\n",
      "2018-11-08 10:46:30,856 : WARNING : EPOCH - 2 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:31,877 : INFO : EPOCH 3 - PROGRESS: at 10.84% examples, 1445993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:32,882 : INFO : EPOCH 3 - PROGRESS: at 20.99% examples, 1399925 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:33,883 : INFO : EPOCH 3 - PROGRESS: at 30.80% examples, 1366591 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:34,086 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:34,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:34,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:34,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:34,101 : INFO : EPOCH - 3 : training on 5920713 raw words (4455344 effective words) took 3.2s, 1374284 effective words/s\n",
      "2018-11-08 10:46:34,101 : WARNING : EPOCH - 3 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:35,117 : INFO : EPOCH 4 - PROGRESS: at 11.28% examples, 1519013 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:36,118 : INFO : EPOCH 4 - PROGRESS: at 22.62% examples, 1513788 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:37,070 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:37,070 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:37,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:37,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:37,086 : INFO : EPOCH - 4 : training on 5920713 raw words (4454212 effective words) took 3.0s, 1500619 effective words/s\n",
      "2018-11-08 10:46:37,086 : WARNING : EPOCH - 4 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:38,089 : INFO : EPOCH 5 - PROGRESS: at 11.11% examples, 1491095 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:39,092 : INFO : EPOCH 5 - PROGRESS: at 22.39% examples, 1497604 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:40,047 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:40,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:40,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:40,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:40,062 : INFO : EPOCH - 5 : training on 5920713 raw words (4454234 effective words) took 3.0s, 1498541 effective words/s\n",
      "2018-11-08 10:46:40,062 : WARNING : EPOCH - 5 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:41,074 : INFO : EPOCH 6 - PROGRESS: at 11.28% examples, 1518479 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:42,076 : INFO : EPOCH 6 - PROGRESS: at 22.50% examples, 1507935 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:43,060 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:43,075 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:43,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:43,075 : INFO : EPOCH 6 - PROGRESS: at 33.33% examples, 1482069 words/s, in_qsize 0, out_qsize 1\n",
      "2018-11-08 10:46:43,075 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:43,075 : INFO : EPOCH - 6 : training on 5920713 raw words (4452805 effective words) took 3.0s, 1479986 effective words/s\n",
      "2018-11-08 10:46:43,075 : WARNING : EPOCH - 6 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:44,091 : INFO : EPOCH 7 - PROGRESS: at 11.11% examples, 1500566 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:45,093 : INFO : EPOCH 7 - PROGRESS: at 22.12% examples, 1485152 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:46,080 : INFO : EPOCH 7 - PROGRESS: at 33.12% examples, 1474176 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-08 10:46:46,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:46,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:46,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:46,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:46,112 : INFO : EPOCH - 7 : training on 5920713 raw words (4455022 effective words) took 3.0s, 1469909 effective words/s\n",
      "2018-11-08 10:46:46,112 : WARNING : EPOCH - 7 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:47,128 : INFO : EPOCH 8 - PROGRESS: at 10.95% examples, 1471306 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:48,131 : INFO : EPOCH 8 - PROGRESS: at 21.90% examples, 1467664 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:49,133 : INFO : EPOCH 8 - PROGRESS: at 32.89% examples, 1460822 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:49,165 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:49,165 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:49,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:49,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:49,180 : INFO : EPOCH - 8 : training on 5920713 raw words (4454374 effective words) took 3.1s, 1459246 effective words/s\n",
      "2018-11-08 10:46:49,180 : WARNING : EPOCH - 8 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:50,184 : INFO : EPOCH 9 - PROGRESS: at 11.23% examples, 1515251 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:51,191 : INFO : EPOCH 9 - PROGRESS: at 22.21% examples, 1492654 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:46:52,192 : INFO : EPOCH 9 - PROGRESS: at 32.95% examples, 1465686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:52,208 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:52,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:52,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:52,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:52,224 : INFO : EPOCH - 9 : training on 5920713 raw words (4454321 effective words) took 3.0s, 1465960 effective words/s\n",
      "2018-11-08 10:46:52,224 : WARNING : EPOCH - 9 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:53,241 : INFO : EPOCH 10 - PROGRESS: at 9.46% examples, 1275069 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:54,245 : INFO : EPOCH 10 - PROGRESS: at 19.96% examples, 1340898 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:46:55,234 : INFO : EPOCH 10 - PROGRESS: at 30.86% examples, 1373592 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:55,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:55,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:55,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:55,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:55,468 : INFO : EPOCH - 10 : training on 5920713 raw words (4453750 effective words) took 3.2s, 1375779 effective words/s\n",
      "2018-11-08 10:46:55,468 : WARNING : EPOCH - 10 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:56,483 : INFO : EPOCH 11 - PROGRESS: at 10.41% examples, 1396701 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:57,490 : INFO : EPOCH 11 - PROGRESS: at 21.53% examples, 1436829 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:58,502 : INFO : EPOCH 11 - PROGRESS: at 32.59% examples, 1444649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:46:58,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:46:58,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:46:58,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:46:58,558 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:46:58,573 : INFO : EPOCH - 11 : training on 5920713 raw words (4454640 effective words) took 3.1s, 1442260 effective words/s\n",
      "2018-11-08 10:46:58,573 : WARNING : EPOCH - 11 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:46:59,551 : INFO : EPOCH 12 - PROGRESS: at 10.58% examples, 1423871 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:00,558 : INFO : EPOCH 12 - PROGRESS: at 21.39% examples, 1432291 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:01,580 : INFO : EPOCH 12 - PROGRESS: at 32.20% examples, 1432243 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:47:01,657 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:01,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:01,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:01,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:01,672 : INFO : EPOCH - 12 : training on 5920713 raw words (4454412 effective words) took 3.1s, 1426417 effective words/s\n",
      "2018-11-08 10:47:01,674 : WARNING : EPOCH - 12 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:02,682 : INFO : EPOCH 13 - PROGRESS: at 10.53% examples, 1415348 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:03,699 : INFO : EPOCH 13 - PROGRESS: at 21.05% examples, 1411954 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:04,715 : INFO : EPOCH 13 - PROGRESS: at 32.21% examples, 1432093 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:04,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:04,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:04,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:04,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:04,809 : INFO : EPOCH - 13 : training on 5920713 raw words (4453943 effective words) took 3.1s, 1430407 effective words/s\n",
      "2018-11-08 10:47:04,809 : WARNING : EPOCH - 13 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:05,813 : INFO : EPOCH 14 - PROGRESS: at 11.28% examples, 1503546 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:06,833 : INFO : EPOCH 14 - PROGRESS: at 21.21% examples, 1415679 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:07,845 : INFO : EPOCH 14 - PROGRESS: at 32.25% examples, 1430754 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:07,930 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:07,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:07,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:07,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:07,946 : INFO : EPOCH - 14 : training on 5920713 raw words (4454243 effective words) took 3.1s, 1426993 effective words/s\n",
      "2018-11-08 10:47:07,946 : WARNING : EPOCH - 14 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:08,963 : INFO : EPOCH 15 - PROGRESS: at 11.23% examples, 1500847 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:09,957 : INFO : EPOCH 15 - PROGRESS: at 21.53% examples, 1437082 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:10,961 : INFO : EPOCH 15 - PROGRESS: at 32.14% examples, 1425558 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:47:11,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:11,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:11,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:11,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:11,080 : INFO : EPOCH - 15 : training on 5920713 raw words (4454323 effective words) took 3.1s, 1424878 effective words/s\n",
      "2018-11-08 10:47:11,080 : WARNING : EPOCH - 15 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:12,090 : INFO : EPOCH 16 - PROGRESS: at 11.23% examples, 1510166 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:13,092 : INFO : EPOCH 16 - PROGRESS: at 22.44% examples, 1503331 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:14,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:14,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:14,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:14,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:14,049 : INFO : EPOCH - 16 : training on 5920713 raw words (4454337 effective words) took 3.0s, 1501161 effective words/s\n",
      "2018-11-08 10:47:14,049 : WARNING : EPOCH - 16 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:15,050 : INFO : EPOCH 17 - PROGRESS: at 11.28% examples, 1514323 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:16,065 : INFO : EPOCH 17 - PROGRESS: at 21.90% examples, 1463438 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:17,075 : INFO : EPOCH 17 - PROGRESS: at 33.12% examples, 1470445 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-08 10:47:17,075 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:17,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:17,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:47:17,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:17,090 : INFO : EPOCH - 17 : training on 5920713 raw words (4454241 effective words) took 3.0s, 1468099 effective words/s\n",
      "2018-11-08 10:47:17,090 : WARNING : EPOCH - 17 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:18,108 : INFO : EPOCH 18 - PROGRESS: at 11.23% examples, 1508614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:19,098 : INFO : EPOCH 18 - PROGRESS: at 22.34% examples, 1489748 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:20,067 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:20,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:20,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:20,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:20,098 : INFO : EPOCH - 18 : training on 5920713 raw words (4453888 effective words) took 3.0s, 1489971 effective words/s\n",
      "2018-11-08 10:47:20,098 : WARNING : EPOCH - 18 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:21,097 : INFO : EPOCH 19 - PROGRESS: at 11.28% examples, 1516902 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:22,100 : INFO : EPOCH 19 - PROGRESS: at 22.44% examples, 1503717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:23,056 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:23,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:23,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:23,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:23,071 : INFO : EPOCH - 19 : training on 5920713 raw words (4453257 effective words) took 3.0s, 1498520 effective words/s\n",
      "2018-11-08 10:47:23,071 : WARNING : EPOCH - 19 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:24,090 : INFO : EPOCH 20 - PROGRESS: at 11.28% examples, 1511374 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:25,091 : INFO : EPOCH 20 - PROGRESS: at 22.56% examples, 1506006 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:26,008 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:26,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:26,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:26,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:26,023 : INFO : EPOCH - 20 : training on 5920713 raw words (4453620 effective words) took 3.0s, 1501373 effective words/s\n",
      "2018-11-08 10:47:26,026 : WARNING : EPOCH - 20 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:26,028 : INFO : training on a 118414260 raw words (89084078 effective words) took 61.4s, 1451499 effective words/s\n",
      "2018-11-08 10:47:26,029 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 10:47:27,058 : INFO : EPOCH 1 - PROGRESS: at 8.23% examples, 1103225 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:28,061 : INFO : EPOCH 1 - PROGRESS: at 16.41% examples, 1100025 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:29,070 : INFO : EPOCH 1 - PROGRESS: at 24.57% examples, 1097597 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:30,074 : INFO : EPOCH 1 - PROGRESS: at 32.82% examples, 1094333 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:30,106 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:30,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:30,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:30,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:30,123 : INFO : EPOCH - 1 : training on 5920713 raw words (4454124 effective words) took 4.1s, 1093421 effective words/s\n",
      "2018-11-08 10:47:30,139 : WARNING : EPOCH - 1 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:31,155 : INFO : EPOCH 2 - PROGRESS: at 7.67% examples, 1024806 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:32,174 : INFO : EPOCH 2 - PROGRESS: at 16.04% examples, 1060895 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:47:33,176 : INFO : EPOCH 2 - PROGRESS: at 24.32% examples, 1074251 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:47:34,176 : INFO : EPOCH 2 - PROGRESS: at 31.55% examples, 1044031 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:34,379 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:34,395 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:34,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:34,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:34,395 : INFO : EPOCH - 2 : training on 5920713 raw words (4455101 effective words) took 4.3s, 1045005 effective words/s\n",
      "2018-11-08 10:47:34,395 : WARNING : EPOCH - 2 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:35,385 : INFO : EPOCH 3 - PROGRESS: at 7.22% examples, 982193 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:36,391 : INFO : EPOCH 3 - PROGRESS: at 15.22% examples, 1020887 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:37,409 : INFO : EPOCH 3 - PROGRESS: at 22.99% examples, 1021326 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:38,420 : INFO : EPOCH 3 - PROGRESS: at 30.69% examples, 1018315 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:38,751 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:38,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:38,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:38,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:38,761 : INFO : EPOCH - 3 : training on 5920713 raw words (4453652 effective words) took 4.4s, 1017566 effective words/s\n",
      "2018-11-08 10:47:38,762 : WARNING : EPOCH - 3 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:39,771 : INFO : EPOCH 4 - PROGRESS: at 7.94% examples, 1067884 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:40,783 : INFO : EPOCH 4 - PROGRESS: at 15.16% examples, 1012921 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:47:41,783 : INFO : EPOCH 4 - PROGRESS: at 23.15% examples, 1031935 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:42,787 : INFO : EPOCH 4 - PROGRESS: at 30.45% examples, 1015199 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:43,187 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:43,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:43,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:43,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:43,212 : INFO : EPOCH - 4 : training on 5920713 raw words (4454364 effective words) took 4.4s, 1002281 effective words/s\n",
      "2018-11-08 10:47:43,213 : WARNING : EPOCH - 4 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:44,225 : INFO : EPOCH 5 - PROGRESS: at 7.27% examples, 984170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:45,236 : INFO : EPOCH 5 - PROGRESS: at 14.47% examples, 967813 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:47:46,238 : INFO : EPOCH 5 - PROGRESS: at 21.33% examples, 950068 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:47,241 : INFO : EPOCH 5 - PROGRESS: at 28.70% examples, 957640 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:47,878 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:47,886 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:47,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:47,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:47,896 : INFO : EPOCH - 5 : training on 5920713 raw words (4454040 effective words) took 4.7s, 952458 effective words/s\n",
      "2018-11-08 10:47:47,898 : WARNING : EPOCH - 5 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:48,906 : INFO : EPOCH 6 - PROGRESS: at 7.44% examples, 1011422 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:49,906 : INFO : EPOCH 6 - PROGRESS: at 14.27% examples, 960336 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:50,915 : INFO : EPOCH 6 - PROGRESS: at 21.74% examples, 969899 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:47:51,916 : INFO : EPOCH 6 - PROGRESS: at 28.43% examples, 950749 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:52,633 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:52,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:52,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:52,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:52,650 : INFO : EPOCH - 6 : training on 5920713 raw words (4453798 effective words) took 4.7s, 938646 effective words/s\n",
      "2018-11-08 10:47:52,652 : WARNING : EPOCH - 6 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:53,667 : INFO : EPOCH 7 - PROGRESS: at 6.79% examples, 917827 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:54,677 : INFO : EPOCH 7 - PROGRESS: at 14.65% examples, 979315 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:55,678 : INFO : EPOCH 7 - PROGRESS: at 22.16% examples, 987241 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:56,710 : INFO : EPOCH 7 - PROGRESS: at 29.46% examples, 982820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:57,152 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:47:57,157 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:47:57,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:47:57,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:47:57,173 : INFO : EPOCH - 7 : training on 5920713 raw words (4454453 effective words) took 4.5s, 987119 effective words/s\n",
      "2018-11-08 10:47:57,175 : WARNING : EPOCH - 7 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:47:58,194 : INFO : EPOCH 8 - PROGRESS: at 7.67% examples, 1028027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:47:59,214 : INFO : EPOCH 8 - PROGRESS: at 15.38% examples, 1026694 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:00,226 : INFO : EPOCH 8 - PROGRESS: at 22.56% examples, 1003665 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:01,206 : INFO : EPOCH 8 - PROGRESS: at 30.51% examples, 1015615 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:01,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:01,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:01,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:01,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:01,589 : INFO : EPOCH - 8 : training on 5920713 raw words (4453550 effective words) took 4.4s, 1013816 effective words/s\n",
      "2018-11-08 10:48:01,604 : WARNING : EPOCH - 8 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:02,604 : INFO : EPOCH 9 - PROGRESS: at 8.23% examples, 1103333 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:03,605 : INFO : EPOCH 9 - PROGRESS: at 16.35% examples, 1098023 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:04,610 : INFO : EPOCH 9 - PROGRESS: at 24.47% examples, 1093863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:05,620 : INFO : EPOCH 9 - PROGRESS: at 32.82% examples, 1092867 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:05,660 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:05,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:05,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:05,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:05,675 : INFO : EPOCH - 9 : training on 5920713 raw words (4454986 effective words) took 4.1s, 1092276 effective words/s\n",
      "2018-11-08 10:48:05,675 : WARNING : EPOCH - 9 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:06,684 : INFO : EPOCH 10 - PROGRESS: at 8.06% examples, 1085436 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:07,701 : INFO : EPOCH 10 - PROGRESS: at 16.24% examples, 1092166 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:08,692 : INFO : EPOCH 10 - PROGRESS: at 24.52% examples, 1096929 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:09,694 : INFO : EPOCH 10 - PROGRESS: at 32.71% examples, 1092471 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:09,756 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:09,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:09,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:09,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:09,772 : INFO : EPOCH - 10 : training on 5920713 raw words (4453637 effective words) took 4.1s, 1092120 effective words/s\n",
      "2018-11-08 10:48:09,772 : WARNING : EPOCH - 10 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:10,788 : INFO : EPOCH 11 - PROGRESS: at 8.23% examples, 1095483 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:48:11,790 : INFO : EPOCH 11 - PROGRESS: at 16.41% examples, 1096883 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:12,792 : INFO : EPOCH 11 - PROGRESS: at 24.52% examples, 1092599 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:13,785 : INFO : EPOCH 11 - PROGRESS: at 32.76% examples, 1088609 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:13,842 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:13,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:13,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:13,873 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:13,873 : INFO : EPOCH - 11 : training on 5920713 raw words (4455580 effective words) took 4.1s, 1088885 effective words/s\n",
      "2018-11-08 10:48:13,873 : WARNING : EPOCH - 11 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:14,891 : INFO : EPOCH 12 - PROGRESS: at 8.23% examples, 1095161 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:15,868 : INFO : EPOCH 12 - PROGRESS: at 15.66% examples, 1045848 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 10:48:16,901 : INFO : EPOCH 12 - PROGRESS: at 23.86% examples, 1061672 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:17,904 : INFO : EPOCH 12 - PROGRESS: at 32.08% examples, 1066901 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:18,038 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:18,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:18,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:18,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:18,054 : INFO : EPOCH - 12 : training on 5920713 raw words (4454171 effective words) took 4.2s, 1065693 effective words/s\n",
      "2018-11-08 10:48:18,054 : WARNING : EPOCH - 12 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:19,057 : INFO : EPOCH 13 - PROGRESS: at 8.00% examples, 1078281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:20,076 : INFO : EPOCH 13 - PROGRESS: at 16.20% examples, 1086172 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 10:48:21,076 : INFO : EPOCH 13 - PROGRESS: at 24.42% examples, 1084204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:22,099 : INFO : EPOCH 13 - PROGRESS: at 32.71% examples, 1085464 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:22,131 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:22,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:22,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:22,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:22,142 : INFO : EPOCH - 13 : training on 5920713 raw words (4454197 effective words) took 4.1s, 1085534 effective words/s\n",
      "2018-11-08 10:48:22,175 : WARNING : EPOCH - 13 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:23,164 : INFO : EPOCH 14 - PROGRESS: at 8.23% examples, 1107562 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:24,168 : INFO : EPOCH 14 - PROGRESS: at 16.46% examples, 1099117 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:25,173 : INFO : EPOCH 14 - PROGRESS: at 24.69% examples, 1097595 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:26,174 : INFO : EPOCH 14 - PROGRESS: at 32.76% examples, 1089256 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:26,243 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:26,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:26,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:26,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:26,244 : INFO : EPOCH - 14 : training on 5920713 raw words (4454436 effective words) took 4.1s, 1088734 effective words/s\n",
      "2018-11-08 10:48:26,244 : WARNING : EPOCH - 14 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:27,271 : INFO : EPOCH 15 - PROGRESS: at 7.67% examples, 1041093 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:28,280 : INFO : EPOCH 15 - PROGRESS: at 15.61% examples, 1049296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:29,288 : INFO : EPOCH 15 - PROGRESS: at 23.30% examples, 1042973 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:30,285 : INFO : EPOCH 15 - PROGRESS: at 31.49% examples, 1050828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:30,488 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:30,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:30,519 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:30,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:30,535 : INFO : EPOCH - 15 : training on 5920713 raw words (4454383 effective words) took 4.3s, 1045929 effective words/s\n",
      "2018-11-08 10:48:30,535 : WARNING : EPOCH - 15 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:31,553 : INFO : EPOCH 16 - PROGRESS: at 6.58% examples, 890318 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:32,570 : INFO : EPOCH 16 - PROGRESS: at 14.48% examples, 969882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:33,572 : INFO : EPOCH 16 - PROGRESS: at 22.21% examples, 990315 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:34,556 : INFO : EPOCH 16 - PROGRESS: at 29.11% examples, 971598 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:35,066 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:35,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:35,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:35,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:35,068 : INFO : EPOCH - 16 : training on 5920713 raw words (4454811 effective words) took 4.5s, 982043 effective words/s\n",
      "2018-11-08 10:48:35,069 : WARNING : EPOCH - 16 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:36,098 : INFO : EPOCH 17 - PROGRESS: at 7.74% examples, 1044200 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:37,111 : INFO : EPOCH 17 - PROGRESS: at 15.88% examples, 1062397 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:38,115 : INFO : EPOCH 17 - PROGRESS: at 23.09% examples, 1030047 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:39,117 : INFO : EPOCH 17 - PROGRESS: at 30.45% examples, 1015932 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:39,430 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:39,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:39,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:39,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:39,445 : INFO : EPOCH - 17 : training on 5920713 raw words (4453569 effective words) took 4.4s, 1018943 effective words/s\n",
      "2018-11-08 10:48:39,447 : WARNING : EPOCH - 17 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:40,464 : INFO : EPOCH 18 - PROGRESS: at 7.74% examples, 1039110 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:41,483 : INFO : EPOCH 18 - PROGRESS: at 15.77% examples, 1051432 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:42,499 : INFO : EPOCH 18 - PROGRESS: at 23.59% examples, 1047554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:43,501 : INFO : EPOCH 18 - PROGRESS: at 31.88% examples, 1058307 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:43,661 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:43,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:43,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:43,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:43,676 : INFO : EPOCH - 18 : training on 5920713 raw words (4452922 effective words) took 4.2s, 1058950 effective words/s\n",
      "2018-11-08 10:48:43,676 : WARNING : EPOCH - 18 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:44,682 : INFO : EPOCH 19 - PROGRESS: at 8.17% examples, 1098406 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:45,683 : INFO : EPOCH 19 - PROGRESS: at 16.41% examples, 1095579 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:46,698 : INFO : EPOCH 19 - PROGRESS: at 24.69% examples, 1099438 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:47,713 : INFO : EPOCH 19 - PROGRESS: at 32.82% examples, 1092624 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:47,744 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:47,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:47,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:47,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:47,760 : INFO : EPOCH - 19 : training on 5920713 raw words (4455297 effective words) took 4.1s, 1091770 effective words/s\n",
      "2018-11-08 10:48:47,775 : WARNING : EPOCH - 19 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:48,778 : INFO : EPOCH 20 - PROGRESS: at 8.11% examples, 1087709 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:49,796 : INFO : EPOCH 20 - PROGRESS: at 15.83% examples, 1052653 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 10:48:50,814 : INFO : EPOCH 20 - PROGRESS: at 24.01% examples, 1063891 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 10:48:51,819 : INFO : EPOCH 20 - PROGRESS: at 32.31% examples, 1070312 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 10:48:51,928 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 10:48:51,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 10:48:51,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 10:48:51,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 10:48:51,928 : INFO : EPOCH - 20 : training on 5920713 raw words (4454345 effective words) took 4.2s, 1070643 effective words/s\n",
      "2018-11-08 10:48:51,944 : WARNING : EPOCH - 20 : supplied example count (25000) did not equal expected count (75000)\n",
      "2018-11-08 10:48:51,944 : INFO : training on a 118414260 raw words (89085416 effective words) took 85.9s, 1037253 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m2 = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m3 = Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab with first model using all documents\n",
    "m1.build_vocab(allDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "m3.reset_from(m1)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "# Train each model on the labeled training data\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m3.train(taggedDocs, total_examples = m3.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination one:  Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T17:59:54.290018Z",
     "start_time": "2018-11-08T17:48:51.959629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(xTrain) 25000\n",
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "1   LDA   0.88760  0.006350\n",
      "0    LR   0.88688  0.007797\n",
      "2   SVM   0.88684  0.007620\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "xTrain = []\n",
    "\n",
    "for i in range(0, len(taggedDocs)):\n",
    "    xTrain.append(np.hstack((m1.docvecs[i], m2.docvecs[i])))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))\n",
    "\n",
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Two:  Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T18:10:53.616908Z",
     "start_time": "2018-11-08T17:59:54.292018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 147061.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(xTrain) 25000\n",
      "Training LR ....\n",
      "Training LDA ....\n",
      "Training SVM ....\n",
      "  Model  Accuracy    StdDev\n",
      "1   LDA   0.88708  0.007432\n",
      "0    LR   0.88632  0.007589\n",
      "2   SVM   0.88556  0.007856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m2 and m3)\n",
    "xTrain = []\n",
    "\n",
    "for i in tqdm(range(0, len(taggedDocs))):\n",
    "    xTrain.append(np.hstack((m2.docvecs[i], m3.docvecs[i])))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))\n",
    "\n",
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "We picked up less than a full percentage point of accuracy, so it doesn't appear this method provides meaningful gains to the classification task at hand.  Let's continue and try another implementation strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual training and feature set creation utilizing combined Doc2Vec models\n",
    "\n",
    "Next we'll try the same three Doc2Vec models we utilized before with a vocabulary created from the full suite of review text.  The training process will be implemented manually, we'll adjust the alpha value it epoch, and we'll train the models on the entire review corpus.  Once this is done we'll utilize the `infer_vector` method of the models to manually create the labeled document vectors (i.e. our feature set), since the `docvecs` property will now contain a mix of labeled and un-labeled document vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Doc2Vec models, build vocabulary, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 11:10:54,023 : INFO : using concatenative 1100-dimensional layer1\n",
      "2018-11-08 11:10:54,117 : INFO : collecting all words and their counts\n",
      "2018-11-08 11:10:54,117 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-08 11:10:54,444 : INFO : PROGRESS: at example #10000, processed 2385574 words (7078959/s), 51527 word types, 10000 tags\n",
      "2018-11-08 11:10:54,803 : INFO : PROGRESS: at example #20000, processed 4747503 words (6860859/s), 67813 word types, 20000 tags\n",
      "2018-11-08 11:10:55,146 : INFO : PROGRESS: at example #30000, processed 7100124 words (6861757/s), 81670 word types, 30000 tags\n",
      "2018-11-08 11:10:55,491 : INFO : PROGRESS: at example #40000, processed 9467843 words (6707616/s), 93389 word types, 40000 tags\n",
      "2018-11-08 11:10:55,853 : INFO : PROGRESS: at example #50000, processed 11865784 words (6703472/s), 103474 word types, 50000 tags\n",
      "2018-11-08 11:10:56,212 : INFO : PROGRESS: at example #60000, processed 14248889 words (6787555/s), 112175 word types, 60000 tags\n",
      "2018-11-08 11:10:56,557 : INFO : PROGRESS: at example #70000, processed 16609485 words (6756118/s), 119831 word types, 70000 tags\n",
      "2018-11-08 11:10:56,730 : INFO : collected 123504 word types and 75000 unique tags from a corpus of 75000 examples and 17797887 words\n",
      "2018-11-08 11:10:56,730 : INFO : Loading a fresh vocabulary\n",
      "2018-11-08 11:10:56,855 : INFO : effective_min_count=2 retains 74452 unique words (60% of original 123504, drops 49052)\n",
      "2018-11-08 11:10:56,855 : INFO : effective_min_count=2 leaves 17748835 word corpus (99% of original 17797887, drops 49052)\n",
      "2018-11-08 11:10:57,042 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2018-11-08 11:10:57,042 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-11-08 11:10:57,042 : INFO : downsampling leaves estimated 13317683 word corpus (75.0% of prior 17748835)\n",
      "2018-11-08 11:10:57,323 : INFO : estimated required memory for 74452 words and 100 dimensions: 424595600 bytes\n",
      "2018-11-08 11:10:57,323 : INFO : resetting layer weights\n",
      "2018-11-08 11:10:58,736 : INFO : resetting layer weights\n",
      "2018-11-08 11:11:00,143 : INFO : resetting layer weights\n",
      "2018-11-08 11:11:01,611 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:11:02,623 : INFO : EPOCH 1 - PROGRESS: at 3.55% examples, 471337 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:03,623 : INFO : EPOCH 1 - PROGRESS: at 7.42% examples, 488960 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:11:04,655 : INFO : EPOCH 1 - PROGRESS: at 11.44% examples, 499060 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:05,673 : INFO : EPOCH 1 - PROGRESS: at 15.26% examples, 499133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:06,684 : INFO : EPOCH 1 - PROGRESS: at 19.11% examples, 503697 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:07,682 : INFO : EPOCH 1 - PROGRESS: at 22.97% examples, 504546 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:08,693 : INFO : EPOCH 1 - PROGRESS: at 26.59% examples, 499654 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:09,703 : INFO : EPOCH 1 - PROGRESS: at 29.97% examples, 491147 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:10,723 : INFO : EPOCH 1 - PROGRESS: at 32.96% examples, 481845 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:11,728 : INFO : EPOCH 1 - PROGRESS: at 36.28% examples, 477380 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:12,736 : INFO : EPOCH 1 - PROGRESS: at 39.89% examples, 476930 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:13,759 : INFO : EPOCH 1 - PROGRESS: at 43.63% examples, 477982 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:14,747 : INFO : EPOCH 1 - PROGRESS: at 46.51% examples, 470747 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 11:11:15,773 : INFO : EPOCH 1 - PROGRESS: at 49.56% examples, 465407 words/s, in_qsize 7, out_qsize 2\n",
      "2018-11-08 11:11:16,812 : INFO : EPOCH 1 - PROGRESS: at 52.49% examples, 459386 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:11:17,831 : INFO : EPOCH 1 - PROGRESS: at 55.43% examples, 455158 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:11:18,832 : INFO : EPOCH 1 - PROGRESS: at 58.71% examples, 454822 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:19,865 : INFO : EPOCH 1 - PROGRESS: at 62.53% examples, 457120 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:20,886 : INFO : EPOCH 1 - PROGRESS: at 65.89% examples, 456991 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 11:11:21,901 : INFO : EPOCH 1 - PROGRESS: at 69.77% examples, 459873 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:22,935 : INFO : EPOCH 1 - PROGRESS: at 73.72% examples, 462615 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:23,949 : INFO : EPOCH 1 - PROGRESS: at 77.66% examples, 465355 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:24,942 : INFO : EPOCH 1 - PROGRESS: at 81.54% examples, 467319 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:25,943 : INFO : EPOCH 1 - PROGRESS: at 85.13% examples, 467844 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:11:26,968 : INFO : EPOCH 1 - PROGRESS: at 88.82% examples, 469275 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:27,994 : INFO : EPOCH 1 - PROGRESS: at 92.52% examples, 469782 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:29,001 : INFO : EPOCH 1 - PROGRESS: at 96.49% examples, 471785 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:29,892 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:11:29,892 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:11:29,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:11:29,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:11:29,908 : INFO : EPOCH - 1 : training on 17797887 raw words (13392421 effective words) took 28.3s, 473455 effective words/s\n",
      "2018-11-08 11:11:29,908 : INFO : training on a 17797887 raw words (13392421 effective words) took 28.3s, 473291 effective words/s\n",
      "2018-11-08 11:11:29,908 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:11:30,923 : INFO : EPOCH 1 - PROGRESS: at 10.90% examples, 1447024 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:31,939 : INFO : EPOCH 1 - PROGRESS: at 21.66% examples, 1429759 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:11:32,942 : INFO : EPOCH 1 - PROGRESS: at 32.79% examples, 1446786 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:33,943 : INFO : EPOCH 1 - PROGRESS: at 43.86% examples, 1452094 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:34,943 : INFO : EPOCH 1 - PROGRESS: at 54.92% examples, 1453653 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:35,960 : INFO : EPOCH 1 - PROGRESS: at 65.84% examples, 1457362 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:11:36,947 : INFO : EPOCH 1 - PROGRESS: at 76.71% examples, 1457796 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:37,948 : INFO : EPOCH 1 - PROGRESS: at 87.31% examples, 1453733 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:38,966 : INFO : EPOCH 1 - PROGRESS: at 97.95% examples, 1451228 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:39,140 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:11:39,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:11:39,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:11:39,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:11:39,156 : INFO : EPOCH - 1 : training on 17797887 raw words (13393510 effective words) took 9.2s, 1450944 effective words/s\n",
      "2018-11-08 11:11:39,156 : INFO : training on a 17797887 raw words (13393510 effective words) took 9.2s, 1450043 effective words/s\n",
      "2018-11-08 11:11:39,156 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:11:40,173 : INFO : EPOCH 1 - PROGRESS: at 8.06% examples, 1057571 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:41,149 : INFO : EPOCH 1 - PROGRESS: at 15.44% examples, 1020136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:42,173 : INFO : EPOCH 1 - PROGRESS: at 22.68% examples, 1000877 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:43,183 : INFO : EPOCH 1 - PROGRESS: at 30.46% examples, 1005535 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:44,194 : INFO : EPOCH 1 - PROGRESS: at 38.61% examples, 1019983 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:45,197 : INFO : EPOCH 1 - PROGRESS: at 46.39% examples, 1022747 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:46,204 : INFO : EPOCH 1 - PROGRESS: at 54.50% examples, 1029764 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:47,206 : INFO : EPOCH 1 - PROGRESS: at 62.25% examples, 1031477 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:48,216 : INFO : EPOCH 1 - PROGRESS: at 70.27% examples, 1037802 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:49,206 : INFO : EPOCH 1 - PROGRESS: at 78.29% examples, 1041816 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:50,222 : INFO : EPOCH 1 - PROGRESS: at 86.42% examples, 1046091 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:51,222 : INFO : EPOCH 1 - PROGRESS: at 94.45% examples, 1049333 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:51,879 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:11:51,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:11:51,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:11:51,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:11:51,895 : INFO : EPOCH - 1 : training on 17797887 raw words (13394951 effective words) took 12.7s, 1051132 effective words/s\n",
      "2018-11-08 11:11:51,895 : INFO : training on a 17797887 raw words (13394951 effective words) took 12.7s, 1050728 effective words/s\n",
      "2018-11-08 11:11:51,957 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:11:52,950 : INFO : EPOCH 1 - PROGRESS: at 3.61% examples, 476947 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:53,972 : INFO : EPOCH 1 - PROGRESS: at 7.36% examples, 499583 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:54,981 : INFO : EPOCH 1 - PROGRESS: at 11.32% examples, 506624 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:11:55,969 : INFO : EPOCH 1 - PROGRESS: at 15.34% examples, 511877 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:11:57,003 : INFO : EPOCH 1 - PROGRESS: at 18.78% examples, 498558 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:11:58,036 : INFO : EPOCH 1 - PROGRESS: at 22.16% examples, 489540 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 11:11:59,043 : INFO : EPOCH 1 - PROGRESS: at 25.74% examples, 487885 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:12:00,042 : INFO : EPOCH 1 - PROGRESS: at 29.21% examples, 485646 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:01,071 : INFO : EPOCH 1 - PROGRESS: at 32.60% examples, 479704 words/s, in_qsize 8, out_qsize 3\n",
      "2018-11-08 11:12:02,095 : INFO : EPOCH 1 - PROGRESS: at 36.38% examples, 480330 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:03,122 : INFO : EPOCH 1 - PROGRESS: at 40.08% examples, 480308 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:04,126 : INFO : EPOCH 1 - PROGRESS: at 44.11% examples, 484055 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:05,157 : INFO : EPOCH 1 - PROGRESS: at 48.13% examples, 486858 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:12:06,166 : INFO : EPOCH 1 - PROGRESS: at 52.10% examples, 489808 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:07,167 : INFO : EPOCH 1 - PROGRESS: at 55.95% examples, 491842 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:08,161 : INFO : EPOCH 1 - PROGRESS: at 59.63% examples, 491769 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:09,198 : INFO : EPOCH 1 - PROGRESS: at 63.59% examples, 493419 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:10,170 : INFO : EPOCH 1 - PROGRESS: at 67.39% examples, 494040 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:11,198 : INFO : EPOCH 1 - PROGRESS: at 71.24% examples, 495122 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:12,205 : INFO : EPOCH 1 - PROGRESS: at 75.23% examples, 496662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:13,199 : INFO : EPOCH 1 - PROGRESS: at 78.78% examples, 495535 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:14,204 : INFO : EPOCH 1 - PROGRESS: at 82.33% examples, 494833 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:15,220 : INFO : EPOCH 1 - PROGRESS: at 86.15% examples, 495446 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:12:16,244 : INFO : EPOCH 1 - PROGRESS: at 90.06% examples, 496834 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:17,262 : INFO : EPOCH 1 - PROGRESS: at 94.05% examples, 497958 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:18,267 : INFO : EPOCH 1 - PROGRESS: at 97.75% examples, 497523 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:18,810 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:12:18,825 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:12:18,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:12:18,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:12:18,841 : INFO : EPOCH - 1 : training on 17797887 raw words (13394327 effective words) took 26.9s, 498331 effective words/s\n",
      "2018-11-08 11:12:18,841 : INFO : training on a 17797887 raw words (13394327 effective words) took 26.9s, 498256 effective words/s\n",
      "2018-11-08 11:12:18,841 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:12:19,830 : INFO : EPOCH 1 - PROGRESS: at 10.53% examples, 1427266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:20,835 : INFO : EPOCH 1 - PROGRESS: at 21.19% examples, 1416201 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:21,836 : INFO : EPOCH 1 - PROGRESS: at 28.77% examples, 1285647 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 11:12:22,844 : INFO : EPOCH 1 - PROGRESS: at 39.03% examples, 1299826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:23,843 : INFO : EPOCH 1 - PROGRESS: at 49.51% examples, 1316408 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:24,846 : INFO : EPOCH 1 - PROGRESS: at 56.81% examples, 1261374 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:25,861 : INFO : EPOCH 1 - PROGRESS: at 64.54% examples, 1226733 words/s, in_qsize 3, out_qsize 1\n",
      "2018-11-08 11:12:26,865 : INFO : EPOCH 1 - PROGRESS: at 73.47% examples, 1221662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:27,866 : INFO : EPOCH 1 - PROGRESS: at 83.29% examples, 1233762 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:28,878 : INFO : EPOCH 1 - PROGRESS: at 93.93% examples, 1252617 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:29,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:12:29,719 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:12:29,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:12:29,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:12:29,729 : INFO : EPOCH - 1 : training on 17797887 raw words (13391818 effective words) took 10.9s, 1228558 effective words/s\n",
      "2018-11-08 11:12:29,732 : INFO : training on a 17797887 raw words (13391818 effective words) took 10.9s, 1227547 effective words/s\n",
      "2018-11-08 11:12:29,734 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:12:30,748 : INFO : EPOCH 1 - PROGRESS: at 7.71% examples, 1040961 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:31,770 : INFO : EPOCH 1 - PROGRESS: at 15.32% examples, 1015330 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:32,771 : INFO : EPOCH 1 - PROGRESS: at 20.87% examples, 923342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:33,775 : INFO : EPOCH 1 - PROGRESS: at 26.34% examples, 876230 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:34,797 : INFO : EPOCH 1 - PROGRESS: at 33.99% examples, 900718 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 11:12:35,798 : INFO : EPOCH 1 - PROGRESS: at 41.82% examples, 922440 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:36,825 : INFO : EPOCH 1 - PROGRESS: at 49.73% examples, 939554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:37,815 : INFO : EPOCH 1 - PROGRESS: at 57.75% examples, 958317 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:38,823 : INFO : EPOCH 1 - PROGRESS: at 65.91% examples, 971289 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:39,826 : INFO : EPOCH 1 - PROGRESS: at 73.96% examples, 981408 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:40,840 : INFO : EPOCH 1 - PROGRESS: at 82.02% examples, 990477 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:41,842 : INFO : EPOCH 1 - PROGRESS: at 88.98% examples, 986410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:42,824 : INFO : EPOCH 1 - PROGRESS: at 97.01% examples, 992529 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:43,199 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:12:43,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:12:43,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:12:43,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:12:43,230 : INFO : EPOCH - 1 : training on 17797887 raw words (13393334 effective words) took 13.5s, 994645 effective words/s\n",
      "2018-11-08 11:12:43,230 : INFO : training on a 17797887 raw words (13393334 effective words) took 13.5s, 994265 effective words/s\n",
      "2018-11-08 11:12:43,277 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:12:44,299 : INFO : EPOCH 1 - PROGRESS: at 3.84% examples, 502120 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:45,316 : INFO : EPOCH 1 - PROGRESS: at 7.81% examples, 511470 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:12:46,347 : INFO : EPOCH 1 - PROGRESS: at 11.81% examples, 517034 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:12:47,351 : INFO : EPOCH 1 - PROGRESS: at 15.88% examples, 521959 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:48,354 : INFO : EPOCH 1 - PROGRESS: at 19.85% examples, 523542 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:49,347 : INFO : EPOCH 1 - PROGRESS: at 23.82% examples, 525287 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:50,361 : INFO : EPOCH 1 - PROGRESS: at 27.81% examples, 525494 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:51,365 : INFO : EPOCH 1 - PROGRESS: at 31.50% examples, 522288 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:52,370 : INFO : EPOCH 1 - PROGRESS: at 35.51% examples, 522818 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:12:53,386 : INFO : EPOCH 1 - PROGRESS: at 39.54% examples, 523477 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:54,406 : INFO : EPOCH 1 - PROGRESS: at 43.47% examples, 523444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:55,412 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 523877 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:56,434 : INFO : EPOCH 1 - PROGRESS: at 51.48% examples, 524074 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:57,440 : INFO : EPOCH 1 - PROGRESS: at 55.46% examples, 524442 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:12:58,456 : INFO : EPOCH 1 - PROGRESS: at 59.16% examples, 522186 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:12:59,457 : INFO : EPOCH 1 - PROGRESS: at 63.16% examples, 522882 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:00,458 : INFO : EPOCH 1 - PROGRESS: at 67.09% examples, 523262 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:01,472 : INFO : EPOCH 1 - PROGRESS: at 71.05% examples, 523802 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:02,492 : INFO : EPOCH 1 - PROGRESS: at 74.88% examples, 523586 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:03,492 : INFO : EPOCH 1 - PROGRESS: at 78.89% examples, 524338 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:04,499 : INFO : EPOCH 1 - PROGRESS: at 82.85% examples, 524220 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:05,505 : INFO : EPOCH 1 - PROGRESS: at 86.68% examples, 523799 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:06,504 : INFO : EPOCH 1 - PROGRESS: at 90.79% examples, 524043 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:07,550 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 524084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:08,552 : INFO : EPOCH 1 - PROGRESS: at 98.98% examples, 524661 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:08,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:13:08,774 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:13:08,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:13:08,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:13:08,805 : INFO : EPOCH - 1 : training on 17797887 raw words (13391695 effective words) took 25.5s, 524880 effective words/s\n",
      "2018-11-08 11:13:08,805 : INFO : training on a 17797887 raw words (13391695 effective words) took 25.5s, 524780 effective words/s\n",
      "2018-11-08 11:13:08,805 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:13:09,809 : INFO : EPOCH 1 - PROGRESS: at 10.94% examples, 1461685 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:10,809 : INFO : EPOCH 1 - PROGRESS: at 21.86% examples, 1462348 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:11,824 : INFO : EPOCH 1 - PROGRESS: at 32.07% examples, 1427319 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:12,820 : INFO : EPOCH 1 - PROGRESS: at 42.55% examples, 1418552 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:13,836 : INFO : EPOCH 1 - PROGRESS: at 53.51% examples, 1429403 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:14,835 : INFO : EPOCH 1 - PROGRESS: at 64.45% examples, 1433570 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:15,836 : INFO : EPOCH 1 - PROGRESS: at 75.30% examples, 1439439 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:13:16,835 : INFO : EPOCH 1 - PROGRESS: at 86.32% examples, 1442879 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:17,838 : INFO : EPOCH 1 - PROGRESS: at 97.26% examples, 1441159 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:18,118 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:13:18,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:13:18,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:13:18,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:13:18,150 : INFO : EPOCH - 1 : training on 17797887 raw words (13391565 effective words) took 9.3s, 1434441 effective words/s\n",
      "2018-11-08 11:13:18,150 : INFO : training on a 17797887 raw words (13391565 effective words) took 9.3s, 1433550 effective words/s\n",
      "2018-11-08 11:13:18,150 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:13:19,165 : INFO : EPOCH 1 - PROGRESS: at 7.37% examples, 979529 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:20,165 : INFO : EPOCH 1 - PROGRESS: at 15.39% examples, 1024468 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:21,165 : INFO : EPOCH 1 - PROGRESS: at 23.43% examples, 1040992 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:22,180 : INFO : EPOCH 1 - PROGRESS: at 31.50% examples, 1049993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:23,167 : INFO : EPOCH 1 - PROGRESS: at 39.64% examples, 1056720 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:24,178 : INFO : EPOCH 1 - PROGRESS: at 47.76% examples, 1060341 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:25,194 : INFO : EPOCH 1 - PROGRESS: at 55.85% examples, 1063516 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:26,197 : INFO : EPOCH 1 - PROGRESS: at 63.93% examples, 1065289 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:27,201 : INFO : EPOCH 1 - PROGRESS: at 71.78% examples, 1064735 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:28,192 : INFO : EPOCH 1 - PROGRESS: at 79.77% examples, 1066863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:29,201 : INFO : EPOCH 1 - PROGRESS: at 87.93% examples, 1067176 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:30,205 : INFO : EPOCH 1 - PROGRESS: at 96.16% examples, 1067755 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:30,675 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:13:30,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:13:30,690 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:13:30,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:13:30,690 : INFO : EPOCH - 1 : training on 17797887 raw words (13392820 effective words) took 12.5s, 1068349 effective words/s\n",
      "2018-11-08 11:13:30,690 : INFO : training on a 17797887 raw words (13392820 effective words) took 12.5s, 1067894 effective words/s\n",
      "2018-11-08 11:13:30,753 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:13:31,760 : INFO : EPOCH 1 - PROGRESS: at 3.95% examples, 530279 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:32,776 : INFO : EPOCH 1 - PROGRESS: at 7.96% examples, 530092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:33,799 : INFO : EPOCH 1 - PROGRESS: at 11.94% examples, 530251 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:13:34,801 : INFO : EPOCH 1 - PROGRESS: at 15.95% examples, 531926 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:35,790 : INFO : EPOCH 1 - PROGRESS: at 19.93% examples, 530846 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:13:36,790 : INFO : EPOCH 1 - PROGRESS: at 23.28% examples, 517276 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:37,816 : INFO : EPOCH 1 - PROGRESS: at 27.06% examples, 515611 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:38,845 : INFO : EPOCH 1 - PROGRESS: at 31.10% examples, 516591 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:39,846 : INFO : EPOCH 1 - PROGRESS: at 35.15% examples, 519061 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:40,879 : INFO : EPOCH 1 - PROGRESS: at 39.35% examples, 520372 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:13:41,917 : INFO : EPOCH 1 - PROGRESS: at 43.28% examples, 520255 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:42,939 : INFO : EPOCH 1 - PROGRESS: at 46.73% examples, 515248 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:43,956 : INFO : EPOCH 1 - PROGRESS: at 50.88% examples, 517163 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:44,958 : INFO : EPOCH 1 - PROGRESS: at 55.00% examples, 518794 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:45,961 : INFO : EPOCH 1 - PROGRESS: at 58.98% examples, 519628 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:46,976 : INFO : EPOCH 1 - PROGRESS: at 62.98% examples, 520140 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:47,987 : INFO : EPOCH 1 - PROGRESS: at 67.14% examples, 521532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:48,985 : INFO : EPOCH 1 - PROGRESS: at 71.11% examples, 522018 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:13:49,994 : INFO : EPOCH 1 - PROGRESS: at 75.21% examples, 522956 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:50,998 : INFO : EPOCH 1 - PROGRESS: at 79.21% examples, 523430 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:52,043 : INFO : EPOCH 1 - PROGRESS: at 83.37% examples, 523956 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:53,043 : INFO : EPOCH 1 - PROGRESS: at 87.44% examples, 524974 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:13:54,063 : INFO : EPOCH 1 - PROGRESS: at 91.40% examples, 525116 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:55,079 : INFO : EPOCH 1 - PROGRESS: at 95.51% examples, 525787 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:56,087 : INFO : EPOCH 1 - PROGRESS: at 99.21% examples, 523943 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:56,286 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:13:56,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:13:56,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:13:56,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:13:56,302 : INFO : EPOCH - 1 : training on 17797887 raw words (13390763 effective words) took 25.5s, 524179 effective words/s\n",
      "2018-11-08 11:13:56,302 : INFO : training on a 17797887 raw words (13390763 effective words) took 25.6s, 524011 effective words/s\n",
      "2018-11-08 11:13:56,302 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:13:57,305 : INFO : EPOCH 1 - PROGRESS: at 10.20% examples, 1373962 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:58,317 : INFO : EPOCH 1 - PROGRESS: at 20.48% examples, 1375390 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:13:59,322 : INFO : EPOCH 1 - PROGRESS: at 31.48% examples, 1404353 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:00,326 : INFO : EPOCH 1 - PROGRESS: at 42.51% examples, 1421239 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:01,322 : INFO : EPOCH 1 - PROGRESS: at 53.33% examples, 1425329 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:02,308 : INFO : EPOCH 1 - PROGRESS: at 62.30% examples, 1385705 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:03,324 : INFO : EPOCH 1 - PROGRESS: at 70.77% examples, 1349740 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:04,331 : INFO : EPOCH 1 - PROGRESS: at 81.47% examples, 1358871 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:05,326 : INFO : EPOCH 1 - PROGRESS: at 92.37% examples, 1370197 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:06,030 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:14:06,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:14:06,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:14:06,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:14:06,046 : INFO : EPOCH - 1 : training on 17797887 raw words (13393950 effective words) took 9.7s, 1376180 effective words/s\n",
      "2018-11-08 11:14:06,046 : INFO : training on a 17797887 raw words (13393950 effective words) took 9.7s, 1375492 effective words/s\n",
      "2018-11-08 11:14:06,046 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:14:07,032 : INFO : EPOCH 1 - PROGRESS: at 7.91% examples, 1061278 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:08,077 : INFO : EPOCH 1 - PROGRESS: at 15.10% examples, 1008749 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:09,077 : INFO : EPOCH 1 - PROGRESS: at 23.12% examples, 1027356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:10,061 : INFO : EPOCH 1 - PROGRESS: at 31.05% examples, 1033697 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:11,073 : INFO : EPOCH 1 - PROGRESS: at 38.05% examples, 1010939 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:12,091 : INFO : EPOCH 1 - PROGRESS: at 45.65% examples, 1014170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:13,081 : INFO : EPOCH 1 - PROGRESS: at 53.67% examples, 1020230 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:14,115 : INFO : EPOCH 1 - PROGRESS: at 61.70% examples, 1023467 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:15,126 : INFO : EPOCH 1 - PROGRESS: at 69.64% examples, 1027382 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:16,103 : INFO : EPOCH 1 - PROGRESS: at 76.33% examples, 1014492 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:17,104 : INFO : EPOCH 1 - PROGRESS: at 83.29% examples, 1006292 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:18,107 : INFO : EPOCH 1 - PROGRESS: at 89.70% examples, 993593 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:19,107 : INFO : EPOCH 1 - PROGRESS: at 95.93% examples, 981839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:19,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 11:14:19,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:14:19,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:14:19,840 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:14:19,841 : INFO : EPOCH - 1 : training on 17797887 raw words (13392403 effective words) took 13.8s, 969536 effective words/s\n",
      "2018-11-08 11:14:19,843 : INFO : training on a 17797887 raw words (13392403 effective words) took 13.8s, 969110 effective words/s\n",
      "2018-11-08 11:14:19,906 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:14:20,913 : INFO : EPOCH 1 - PROGRESS: at 2.97% examples, 392058 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 11:14:21,921 : INFO : EPOCH 1 - PROGRESS: at 5.87% examples, 389912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:22,922 : INFO : EPOCH 1 - PROGRESS: at 9.05% examples, 402358 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-08 11:14:23,924 : INFO : EPOCH 1 - PROGRESS: at 12.34% examples, 410301 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:24,935 : INFO : EPOCH 1 - PROGRESS: at 15.77% examples, 417568 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-08 11:14:25,989 : INFO : EPOCH 1 - PROGRESS: at 19.18% examples, 421735 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:14:26,994 : INFO : EPOCH 1 - PROGRESS: at 22.50% examples, 424327 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:27,999 : INFO : EPOCH 1 - PROGRESS: at 25.79% examples, 425538 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:29,016 : INFO : EPOCH 1 - PROGRESS: at 29.30% examples, 427508 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:30,027 : INFO : EPOCH 1 - PROGRESS: at 32.83% examples, 430825 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:31,028 : INFO : EPOCH 1 - PROGRESS: at 36.26% examples, 433799 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:32,030 : INFO : EPOCH 1 - PROGRESS: at 39.84% examples, 437561 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:33,036 : INFO : EPOCH 1 - PROGRESS: at 43.40% examples, 440519 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:34,040 : INFO : EPOCH 1 - PROGRESS: at 47.36% examples, 446323 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:35,050 : INFO : EPOCH 1 - PROGRESS: at 51.23% examples, 451478 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:36,052 : INFO : EPOCH 1 - PROGRESS: at 55.18% examples, 456359 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:37,055 : INFO : EPOCH 1 - PROGRESS: at 58.83% examples, 457699 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-08 11:14:38,067 : INFO : EPOCH 1 - PROGRESS: at 62.06% examples, 456570 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:39,069 : INFO : EPOCH 1 - PROGRESS: at 65.86% examples, 459710 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:40,098 : INFO : EPOCH 1 - PROGRESS: at 69.05% examples, 457894 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:41,102 : INFO : EPOCH 1 - PROGRESS: at 73.02% examples, 460581 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:42,106 : INFO : EPOCH 1 - PROGRESS: at 76.95% examples, 463636 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:43,141 : INFO : EPOCH 1 - PROGRESS: at 80.34% examples, 462415 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-08 11:14:44,150 : INFO : EPOCH 1 - PROGRESS: at 84.01% examples, 463905 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:45,158 : INFO : EPOCH 1 - PROGRESS: at 87.96% examples, 466443 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:46,172 : INFO : EPOCH 1 - PROGRESS: at 91.98% examples, 468908 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:47,179 : INFO : EPOCH 1 - PROGRESS: at 95.56% examples, 469158 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:48,208 : INFO : EPOCH 1 - PROGRESS: at 99.20% examples, 469662 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:48,351 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:14:48,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:14:48,378 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:14:48,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:14:48,389 : INFO : EPOCH - 1 : training on 17797887 raw words (13393631 effective words) took 28.5s, 470324 effective words/s\n",
      "2018-11-08 11:14:48,390 : INFO : training on a 17797887 raw words (13393631 effective words) took 28.5s, 470253 effective words/s\n",
      "2018-11-08 11:14:48,392 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:14:49,404 : INFO : EPOCH 1 - PROGRESS: at 9.52% examples, 1261075 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:50,407 : INFO : EPOCH 1 - PROGRESS: at 20.09% examples, 1337377 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:51,407 : INFO : EPOCH 1 - PROGRESS: at 30.87% examples, 1364232 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:52,413 : INFO : EPOCH 1 - PROGRESS: at 40.61% examples, 1346090 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:53,414 : INFO : EPOCH 1 - PROGRESS: at 50.46% examples, 1341730 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:54,416 : INFO : EPOCH 1 - PROGRESS: at 60.18% examples, 1334323 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:55,419 : INFO : EPOCH 1 - PROGRESS: at 69.16% examples, 1318456 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:14:56,421 : INFO : EPOCH 1 - PROGRESS: at 78.99% examples, 1316621 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:57,431 : INFO : EPOCH 1 - PROGRESS: at 88.73% examples, 1314959 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:58,435 : INFO : EPOCH 1 - PROGRESS: at 98.72% examples, 1317203 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:14:58,546 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:14:58,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:14:58,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:14:58,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:14:58,556 : INFO : EPOCH - 1 : training on 17797887 raw words (13393093 effective words) took 10.2s, 1318402 effective words/s\n",
      "2018-11-08 11:14:58,558 : INFO : training on a 17797887 raw words (13393093 effective words) took 10.2s, 1317683 effective words/s\n",
      "2018-11-08 11:14:58,559 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:14:59,568 : INFO : EPOCH 1 - PROGRESS: at 7.06% examples, 941170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:00,572 : INFO : EPOCH 1 - PROGRESS: at 14.37% examples, 952443 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:01,576 : INFO : EPOCH 1 - PROGRESS: at 22.10% examples, 980588 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:02,585 : INFO : EPOCH 1 - PROGRESS: at 30.19% examples, 997101 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:03,588 : INFO : EPOCH 1 - PROGRESS: at 38.08% examples, 1008092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:04,594 : INFO : EPOCH 1 - PROGRESS: at 45.93% examples, 1013651 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:05,600 : INFO : EPOCH 1 - PROGRESS: at 53.69% examples, 1018442 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:06,610 : INFO : EPOCH 1 - PROGRESS: at 61.54% examples, 1020995 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:07,611 : INFO : EPOCH 1 - PROGRESS: at 69.28% examples, 1024846 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:08,620 : INFO : EPOCH 1 - PROGRESS: at 77.23% examples, 1026797 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:09,620 : INFO : EPOCH 1 - PROGRESS: at 85.05% examples, 1029497 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:10,622 : INFO : EPOCH 1 - PROGRESS: at 92.84% examples, 1030793 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:11,521 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:15:11,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:15:11,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:15:11,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:15:11,543 : INFO : EPOCH - 1 : training on 17797887 raw words (13390584 effective words) took 13.0s, 1031732 effective words/s\n",
      "2018-11-08 11:15:11,545 : INFO : training on a 17797887 raw words (13390584 effective words) took 13.0s, 1031341 effective words/s\n",
      "2018-11-08 11:15:11,602 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:15:12,613 : INFO : EPOCH 1 - PROGRESS: at 3.57% examples, 471678 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:13,638 : INFO : EPOCH 1 - PROGRESS: at 7.24% examples, 477369 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:14,663 : INFO : EPOCH 1 - PROGRESS: at 11.35% examples, 495853 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:15,668 : INFO : EPOCH 1 - PROGRESS: at 15.34% examples, 504069 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:16,674 : INFO : EPOCH 1 - PROGRESS: at 19.29% examples, 509093 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:17,683 : INFO : EPOCH 1 - PROGRESS: at 23.26% examples, 512001 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:15:18,690 : INFO : EPOCH 1 - PROGRESS: at 26.77% examples, 507428 words/s, in_qsize 8, out_qsize 2\n",
      "2018-11-08 11:15:19,708 : INFO : EPOCH 1 - PROGRESS: at 30.88% examples, 511252 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:20,738 : INFO : EPOCH 1 - PROGRESS: at 34.85% examples, 512748 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:21,749 : INFO : EPOCH 1 - PROGRESS: at 38.76% examples, 514758 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:15:22,765 : INFO : EPOCH 1 - PROGRESS: at 42.84% examples, 516760 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:23,773 : INFO : EPOCH 1 - PROGRESS: at 46.92% examples, 517744 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:24,778 : INFO : EPOCH 1 - PROGRESS: at 50.90% examples, 518586 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:25,785 : INFO : EPOCH 1 - PROGRESS: at 54.88% examples, 519783 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:15:26,802 : INFO : EPOCH 1 - PROGRESS: at 58.98% examples, 520877 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:27,810 : INFO : EPOCH 1 - PROGRESS: at 63.05% examples, 521245 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:28,826 : INFO : EPOCH 1 - PROGRESS: at 67.05% examples, 521821 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:29,826 : INFO : EPOCH 1 - PROGRESS: at 71.01% examples, 522382 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:30,837 : INFO : EPOCH 1 - PROGRESS: at 75.02% examples, 522949 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:31,837 : INFO : EPOCH 1 - PROGRESS: at 78.97% examples, 523298 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:32,853 : INFO : EPOCH 1 - PROGRESS: at 83.01% examples, 523697 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:33,854 : INFO : EPOCH 1 - PROGRESS: at 87.01% examples, 523776 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:15:34,869 : INFO : EPOCH 1 - PROGRESS: at 91.10% examples, 524366 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:35,886 : INFO : EPOCH 1 - PROGRESS: at 95.07% examples, 524581 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:36,895 : INFO : EPOCH 1 - PROGRESS: at 99.16% examples, 525177 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:37,079 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:15:37,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:15:37,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:15:37,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:15:37,108 : INFO : EPOCH - 1 : training on 17797887 raw words (13391983 effective words) took 25.5s, 525203 effective words/s\n",
      "2018-11-08 11:15:37,109 : INFO : training on a 17797887 raw words (13391983 effective words) took 25.5s, 525063 effective words/s\n",
      "2018-11-08 11:15:37,110 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:15:38,119 : INFO : EPOCH 1 - PROGRESS: at 10.55% examples, 1404104 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:39,121 : INFO : EPOCH 1 - PROGRESS: at 21.13% examples, 1407149 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:40,123 : INFO : EPOCH 1 - PROGRESS: at 31.69% examples, 1410642 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:41,124 : INFO : EPOCH 1 - PROGRESS: at 42.01% examples, 1410286 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:42,124 : INFO : EPOCH 1 - PROGRESS: at 52.67% examples, 1410770 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:43,131 : INFO : EPOCH 1 - PROGRESS: at 63.41% examples, 1412411 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:44,133 : INFO : EPOCH 1 - PROGRESS: at 72.63% examples, 1387444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:45,140 : INFO : EPOCH 1 - PROGRESS: at 83.24% examples, 1389901 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:46,144 : INFO : EPOCH 1 - PROGRESS: at 93.44% examples, 1385088 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:46,764 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:15:46,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:15:46,771 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:15:46,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:15:46,776 : INFO : EPOCH - 1 : training on 17797887 raw words (13390895 effective words) took 9.7s, 1386055 effective words/s\n",
      "2018-11-08 11:15:46,777 : INFO : training on a 17797887 raw words (13390895 effective words) took 9.7s, 1385399 effective words/s\n",
      "2018-11-08 11:15:46,778 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:15:47,785 : INFO : EPOCH 1 - PROGRESS: at 7.24% examples, 965415 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:15:48,825 : INFO : EPOCH 1 - PROGRESS: at 15.15% examples, 1003988 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:15:49,818 : INFO : EPOCH 1 - PROGRESS: at 23.26% examples, 1030306 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:50,819 : INFO : EPOCH 1 - PROGRESS: at 31.32% examples, 1044761 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:51,816 : INFO : EPOCH 1 - PROGRESS: at 38.76% examples, 1037077 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:52,818 : INFO : EPOCH 1 - PROGRESS: at 46.64% examples, 1037436 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:53,857 : INFO : EPOCH 1 - PROGRESS: at 54.62% examples, 1040607 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:15:54,858 : INFO : EPOCH 1 - PROGRESS: at 62.78% examples, 1045002 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:55,866 : INFO : EPOCH 1 - PROGRESS: at 70.15% examples, 1038676 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:56,863 : INFO : EPOCH 1 - PROGRESS: at 78.09% examples, 1040607 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:57,859 : INFO : EPOCH 1 - PROGRESS: at 86.13% examples, 1042636 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:58,862 : INFO : EPOCH 1 - PROGRESS: at 93.33% examples, 1035686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:15:59,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:15:59,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:15:59,707 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:15:59,707 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:15:59,707 : INFO : EPOCH - 1 : training on 17797887 raw words (13392149 effective words) took 12.9s, 1038088 effective words/s\n",
      "2018-11-08 11:15:59,707 : INFO : training on a 17797887 raw words (13392149 effective words) took 12.9s, 1037673 effective words/s\n",
      "2018-11-08 11:15:59,770 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 11:16:00,771 : INFO : EPOCH 1 - PROGRESS: at 3.88% examples, 525990 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:01,802 : INFO : EPOCH 1 - PROGRESS: at 7.75% examples, 517276 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:02,850 : INFO : EPOCH 1 - PROGRESS: at 11.73% examples, 522498 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:16:03,859 : INFO : EPOCH 1 - PROGRESS: at 15.74% examples, 523377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:04,869 : INFO : EPOCH 1 - PROGRESS: at 19.87% examples, 526796 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:05,886 : INFO : EPOCH 1 - PROGRESS: at 23.81% examples, 525285 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:06,885 : INFO : EPOCH 1 - PROGRESS: at 27.85% examples, 526168 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:07,890 : INFO : EPOCH 1 - PROGRESS: at 32.07% examples, 529640 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:08,907 : INFO : EPOCH 1 - PROGRESS: at 36.03% examples, 528862 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:09,944 : INFO : EPOCH 1 - PROGRESS: at 40.27% examples, 530292 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:10,944 : INFO : EPOCH 1 - PROGRESS: at 44.24% examples, 530878 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:11,945 : INFO : EPOCH 1 - PROGRESS: at 48.27% examples, 531994 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:12,963 : INFO : EPOCH 1 - PROGRESS: at 52.46% examples, 533210 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:16:13,963 : INFO : EPOCH 1 - PROGRESS: at 56.28% examples, 531919 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:14,966 : INFO : EPOCH 1 - PROGRESS: at 60.19% examples, 531445 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:15,964 : INFO : EPOCH 1 - PROGRESS: at 64.19% examples, 531691 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:16,981 : INFO : EPOCH 1 - PROGRESS: at 68.33% examples, 532337 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:18,011 : INFO : EPOCH 1 - PROGRESS: at 72.13% examples, 530028 words/s, in_qsize 8, out_qsize 4\n",
      "2018-11-08 11:16:19,012 : INFO : EPOCH 1 - PROGRESS: at 76.07% examples, 530306 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:20,059 : INFO : EPOCH 1 - PROGRESS: at 80.24% examples, 530632 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:21,062 : INFO : EPOCH 1 - PROGRESS: at 84.37% examples, 530602 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:22,079 : INFO : EPOCH 1 - PROGRESS: at 88.15% examples, 529199 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:23,081 : INFO : EPOCH 1 - PROGRESS: at 92.22% examples, 529553 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:24,087 : INFO : EPOCH 1 - PROGRESS: at 96.32% examples, 530137 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:24,960 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:16:24,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:16:24,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:16:24,992 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:16:24,992 : INFO : EPOCH - 1 : training on 17797887 raw words (13392043 effective words) took 25.2s, 530823 effective words/s\n",
      "2018-11-08 11:16:24,992 : INFO : training on a 17797887 raw words (13392043 effective words) took 25.2s, 530718 effective words/s\n",
      "2018-11-08 11:16:24,992 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:16:26,009 : INFO : EPOCH 1 - PROGRESS: at 10.62% examples, 1452409 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:27,011 : INFO : EPOCH 1 - PROGRESS: at 21.63% examples, 1456893 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:27,991 : INFO : EPOCH 1 - PROGRESS: at 32.44% examples, 1451503 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:29,009 : INFO : EPOCH 1 - PROGRESS: at 43.53% examples, 1457073 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:30,010 : INFO : EPOCH 1 - PROGRESS: at 54.18% examples, 1451386 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:16:31,032 : INFO : EPOCH 1 - PROGRESS: at 64.56% examples, 1438934 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:32,028 : INFO : EPOCH 1 - PROGRESS: at 75.21% examples, 1436356 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:16:33,047 : INFO : EPOCH 1 - PROGRESS: at 86.17% examples, 1435656 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:34,042 : INFO : EPOCH 1 - PROGRESS: at 96.82% examples, 1433834 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:34,346 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:16:34,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:16:34,362 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:16:34,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:16:34,362 : INFO : EPOCH - 1 : training on 17797887 raw words (13392884 effective words) took 9.4s, 1430644 effective words/s\n",
      "2018-11-08 11:16:34,362 : INFO : training on a 17797887 raw words (13392884 effective words) took 9.4s, 1429733 effective words/s\n",
      "2018-11-08 11:16:34,362 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:16:35,396 : INFO : EPOCH 1 - PROGRESS: at 7.85% examples, 1054694 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:36,369 : INFO : EPOCH 1 - PROGRESS: at 15.69% examples, 1059078 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:37,388 : INFO : EPOCH 1 - PROGRESS: at 23.75% examples, 1062176 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:38,403 : INFO : EPOCH 1 - PROGRESS: at 31.84% examples, 1062808 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:16:39,407 : INFO : EPOCH 1 - PROGRESS: at 39.98% examples, 1065069 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:40,410 : INFO : EPOCH 1 - PROGRESS: at 47.99% examples, 1067014 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:41,429 : INFO : EPOCH 1 - PROGRESS: at 56.12% examples, 1067115 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:42,449 : INFO : EPOCH 1 - PROGRESS: at 64.19% examples, 1067453 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:43,451 : INFO : EPOCH 1 - PROGRESS: at 72.29% examples, 1068179 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:44,455 : INFO : EPOCH 1 - PROGRESS: at 79.38% examples, 1056471 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:45,458 : INFO : EPOCH 1 - PROGRESS: at 87.51% examples, 1057245 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:16:46,461 : INFO : EPOCH 1 - PROGRESS: at 95.61% examples, 1058651 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:46,993 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:16:47,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:16:47,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:16:47,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:16:47,009 : INFO : EPOCH - 1 : training on 17797887 raw words (13393159 effective words) took 12.6s, 1059654 effective words/s\n",
      "2018-11-08 11:16:47,024 : INFO : training on a 17797887 raw words (13393159 effective words) took 12.6s, 1059139 effective words/s\n",
      "2018-11-08 11:16:47,071 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:16:48,087 : INFO : EPOCH 1 - PROGRESS: at 4.04% examples, 531644 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:49,090 : INFO : EPOCH 1 - PROGRESS: at 8.27% examples, 539771 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:50,093 : INFO : EPOCH 1 - PROGRESS: at 12.44% examples, 543976 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:51,109 : INFO : EPOCH 1 - PROGRESS: at 16.42% examples, 539096 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:52,126 : INFO : EPOCH 1 - PROGRESS: at 20.54% examples, 541039 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:53,124 : INFO : EPOCH 1 - PROGRESS: at 24.71% examples, 542711 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:54,135 : INFO : EPOCH 1 - PROGRESS: at 28.90% examples, 543532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:55,154 : INFO : EPOCH 1 - PROGRESS: at 33.13% examples, 546172 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:56,157 : INFO : EPOCH 1 - PROGRESS: at 37.22% examples, 546734 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:57,164 : INFO : EPOCH 1 - PROGRESS: at 41.37% examples, 547145 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:58,190 : INFO : EPOCH 1 - PROGRESS: at 45.57% examples, 547703 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:16:59,206 : INFO : EPOCH 1 - PROGRESS: at 49.45% examples, 544340 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:17:00,210 : INFO : EPOCH 1 - PROGRESS: at 53.64% examples, 545717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:01,232 : INFO : EPOCH 1 - PROGRESS: at 57.83% examples, 546223 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:02,245 : INFO : EPOCH 1 - PROGRESS: at 61.98% examples, 546606 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:03,265 : INFO : EPOCH 1 - PROGRESS: at 66.18% examples, 546740 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:04,282 : INFO : EPOCH 1 - PROGRESS: at 70.30% examples, 547068 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:05,283 : INFO : EPOCH 1 - PROGRESS: at 74.46% examples, 547781 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:06,284 : INFO : EPOCH 1 - PROGRESS: at 78.62% examples, 547912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:07,288 : INFO : EPOCH 1 - PROGRESS: at 82.74% examples, 548105 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:08,309 : INFO : EPOCH 1 - PROGRESS: at 86.86% examples, 548203 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:09,323 : INFO : EPOCH 1 - PROGRESS: at 91.02% examples, 548439 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:10,345 : INFO : EPOCH 1 - PROGRESS: at 95.36% examples, 548855 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:11,339 : INFO : EPOCH 1 - PROGRESS: at 99.53% examples, 548967 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:11,436 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:17:11,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:17:11,440 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:17:11,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:17:11,445 : INFO : EPOCH - 1 : training on 17797887 raw words (13393354 effective words) took 24.4s, 549268 effective words/s\n",
      "2018-11-08 11:17:11,446 : INFO : training on a 17797887 raw words (13393354 effective words) took 24.4s, 549125 effective words/s\n",
      "2018-11-08 11:17:11,447 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:17:12,487 : INFO : EPOCH 1 - PROGRESS: at 10.06% examples, 1322013 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:13,459 : INFO : EPOCH 1 - PROGRESS: at 20.37% examples, 1348685 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:14,476 : INFO : EPOCH 1 - PROGRESS: at 31.29% examples, 1382709 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:15,479 : INFO : EPOCH 1 - PROGRESS: at 42.10% examples, 1400282 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:16,497 : INFO : EPOCH 1 - PROGRESS: at 53.12% examples, 1411445 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:17,497 : INFO : EPOCH 1 - PROGRESS: at 64.04% examples, 1421654 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:18,500 : INFO : EPOCH 1 - PROGRESS: at 74.14% examples, 1411816 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:19,504 : INFO : EPOCH 1 - PROGRESS: at 85.03% examples, 1417567 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:20,506 : INFO : EPOCH 1 - PROGRESS: at 95.93% examples, 1421898 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:20,878 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:17:20,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:17:20,878 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:17:20,878 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:17:20,878 : INFO : EPOCH - 1 : training on 17797887 raw words (13392247 effective words) took 9.4s, 1423078 effective words/s\n",
      "2018-11-08 11:17:20,893 : INFO : training on a 17797887 raw words (13392247 effective words) took 9.4s, 1422137 effective words/s\n",
      "2018-11-08 11:17:20,893 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:17:21,891 : INFO : EPOCH 1 - PROGRESS: at 8.01% examples, 1055785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:22,899 : INFO : EPOCH 1 - PROGRESS: at 16.09% examples, 1062860 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:23,900 : INFO : EPOCH 1 - PROGRESS: at 24.01% examples, 1060716 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:24,906 : INFO : EPOCH 1 - PROGRESS: at 32.01% examples, 1062450 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:25,885 : INFO : EPOCH 1 - PROGRESS: at 39.91% examples, 1060957 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:26,916 : INFO : EPOCH 1 - PROGRESS: at 48.04% examples, 1066082 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:27,924 : INFO : EPOCH 1 - PROGRESS: at 55.98% examples, 1063943 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:28,928 : INFO : EPOCH 1 - PROGRESS: at 63.99% examples, 1065678 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:29,933 : INFO : EPOCH 1 - PROGRESS: at 71.99% examples, 1065841 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:30,941 : INFO : EPOCH 1 - PROGRESS: at 80.11% examples, 1066942 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:31,949 : INFO : EPOCH 1 - PROGRESS: at 88.08% examples, 1067302 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:32,946 : INFO : EPOCH 1 - PROGRESS: at 96.15% examples, 1067755 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:33,413 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:17:33,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:17:33,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:17:33,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:17:33,429 : INFO : EPOCH - 1 : training on 17797887 raw words (13393572 effective words) took 12.5s, 1068128 effective words/s\n",
      "2018-11-08 11:17:33,429 : INFO : training on a 17797887 raw words (13393572 effective words) took 12.5s, 1067619 effective words/s\n",
      "2018-11-08 11:17:33,491 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:17:34,492 : INFO : EPOCH 1 - PROGRESS: at 4.07% examples, 544426 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:35,494 : INFO : EPOCH 1 - PROGRESS: at 8.02% examples, 549667 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:36,513 : INFO : EPOCH 1 - PROGRESS: at 12.26% examples, 550301 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:37,517 : INFO : EPOCH 1 - PROGRESS: at 16.55% examples, 553953 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:38,552 : INFO : EPOCH 1 - PROGRESS: at 20.73% examples, 553817 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:39,573 : INFO : EPOCH 1 - PROGRESS: at 24.91% examples, 553919 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:40,585 : INFO : EPOCH 1 - PROGRESS: at 29.17% examples, 554193 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:41,586 : INFO : EPOCH 1 - PROGRESS: at 33.37% examples, 554760 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:42,579 : INFO : EPOCH 1 - PROGRESS: at 37.55% examples, 554994 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:43,610 : INFO : EPOCH 1 - PROGRESS: at 41.80% examples, 556123 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:44,608 : INFO : EPOCH 1 - PROGRESS: at 45.42% examples, 549795 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:45,609 : INFO : EPOCH 1 - PROGRESS: at 49.38% examples, 548169 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 11:17:46,626 : INFO : EPOCH 1 - PROGRESS: at 53.68% examples, 548757 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:47,646 : INFO : EPOCH 1 - PROGRESS: at 57.92% examples, 549038 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:48,683 : INFO : EPOCH 1 - PROGRESS: at 62.16% examples, 549325 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:49,690 : INFO : EPOCH 1 - PROGRESS: at 66.40% examples, 550099 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:50,704 : INFO : EPOCH 1 - PROGRESS: at 70.57% examples, 550416 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:17:51,705 : INFO : EPOCH 1 - PROGRESS: at 74.55% examples, 549308 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:52,711 : INFO : EPOCH 1 - PROGRESS: at 78.74% examples, 549907 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:53,730 : INFO : EPOCH 1 - PROGRESS: at 82.99% examples, 550292 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:54,715 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 550721 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:17:55,732 : INFO : EPOCH 1 - PROGRESS: at 91.28% examples, 550831 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:17:56,751 : INFO : EPOCH 1 - PROGRESS: at 95.63% examples, 551286 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:57,752 : INFO : EPOCH 1 - PROGRESS: at 99.76% examples, 550546 words/s, in_qsize 3, out_qsize 3\n",
      "2018-11-08 11:17:57,768 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:17:57,799 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:17:57,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:17:57,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:17:57,799 : INFO : EPOCH - 1 : training on 17797887 raw words (13392877 effective words) took 24.3s, 550988 effective words/s\n",
      "2018-11-08 11:17:57,799 : INFO : training on a 17797887 raw words (13392877 effective words) took 24.3s, 550858 effective words/s\n",
      "2018-11-08 11:17:57,799 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:17:58,816 : INFO : EPOCH 1 - PROGRESS: at 10.07% examples, 1366555 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:17:59,821 : INFO : EPOCH 1 - PROGRESS: at 20.73% examples, 1397842 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:00,815 : INFO : EPOCH 1 - PROGRESS: at 30.88% examples, 1384132 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:01,819 : INFO : EPOCH 1 - PROGRESS: at 41.69% examples, 1399694 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:02,826 : INFO : EPOCH 1 - PROGRESS: at 52.71% examples, 1412250 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:03,826 : INFO : EPOCH 1 - PROGRESS: at 63.39% examples, 1413452 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:04,827 : INFO : EPOCH 1 - PROGRESS: at 74.32% examples, 1420872 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:05,827 : INFO : EPOCH 1 - PROGRESS: at 85.24% examples, 1425626 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:06,831 : INFO : EPOCH 1 - PROGRESS: at 96.17% examples, 1427160 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:07,167 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:18:07,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:18:07,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:18:07,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:18:07,183 : INFO : EPOCH - 1 : training on 17797887 raw words (13391803 effective words) took 9.4s, 1427860 effective words/s\n",
      "2018-11-08 11:18:07,183 : INFO : training on a 17797887 raw words (13391803 effective words) took 9.4s, 1427158 effective words/s\n",
      "2018-11-08 11:18:07,184 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:18:08,200 : INFO : EPOCH 1 - PROGRESS: at 7.84% examples, 1067611 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:09,194 : INFO : EPOCH 1 - PROGRESS: at 16.00% examples, 1073165 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:10,196 : INFO : EPOCH 1 - PROGRESS: at 24.11% examples, 1076475 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:11,210 : INFO : EPOCH 1 - PROGRESS: at 32.20% examples, 1077619 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:12,229 : INFO : EPOCH 1 - PROGRESS: at 40.20% examples, 1074742 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:13,248 : INFO : EPOCH 1 - PROGRESS: at 48.27% examples, 1075483 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:14,245 : INFO : EPOCH 1 - PROGRESS: at 56.31% examples, 1072391 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:15,260 : INFO : EPOCH 1 - PROGRESS: at 63.94% examples, 1064714 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:16,259 : INFO : EPOCH 1 - PROGRESS: at 71.97% examples, 1065647 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:17,262 : INFO : EPOCH 1 - PROGRESS: at 79.89% examples, 1065084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:18,279 : INFO : EPOCH 1 - PROGRESS: at 87.48% examples, 1059920 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:19,267 : INFO : EPOCH 1 - PROGRESS: at 95.29% examples, 1057795 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:19,833 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:18:19,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:18:19,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:18:19,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:18:19,849 : INFO : EPOCH - 1 : training on 17797887 raw words (13391768 effective words) took 12.7s, 1057969 effective words/s\n",
      "2018-11-08 11:18:19,849 : INFO : training on a 17797887 raw words (13391768 effective words) took 12.7s, 1057340 effective words/s\n",
      "2018-11-08 11:18:19,916 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:18:20,933 : INFO : EPOCH 1 - PROGRESS: at 4.00% examples, 543957 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:18:21,937 : INFO : EPOCH 1 - PROGRESS: at 8.23% examples, 555320 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:22,938 : INFO : EPOCH 1 - PROGRESS: at 12.41% examples, 557029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:23,938 : INFO : EPOCH 1 - PROGRESS: at 16.55% examples, 555833 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:24,923 : INFO : EPOCH 1 - PROGRESS: at 20.77% examples, 556822 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:25,963 : INFO : EPOCH 1 - PROGRESS: at 24.77% examples, 551502 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:26,950 : INFO : EPOCH 1 - PROGRESS: at 29.02% examples, 553135 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:27,974 : INFO : EPOCH 1 - PROGRESS: at 33.26% examples, 553985 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:28,979 : INFO : EPOCH 1 - PROGRESS: at 37.51% examples, 553170 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:18:29,988 : INFO : EPOCH 1 - PROGRESS: at 41.84% examples, 554254 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:31,014 : INFO : EPOCH 1 - PROGRESS: at 45.91% examples, 554781 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:32,009 : INFO : EPOCH 1 - PROGRESS: at 50.15% examples, 555145 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:33,033 : INFO : EPOCH 1 - PROGRESS: at 54.26% examples, 555620 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:34,030 : INFO : EPOCH 1 - PROGRESS: at 58.39% examples, 555866 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:35,048 : INFO : EPOCH 1 - PROGRESS: at 62.65% examples, 556279 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:36,054 : INFO : EPOCH 1 - PROGRESS: at 66.87% examples, 556851 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:37,047 : INFO : EPOCH 1 - PROGRESS: at 71.10% examples, 556986 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:38,058 : INFO : EPOCH 1 - PROGRESS: at 75.36% examples, 557108 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:39,059 : INFO : EPOCH 1 - PROGRESS: at 79.51% examples, 557192 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:40,060 : INFO : EPOCH 1 - PROGRESS: at 83.76% examples, 557330 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:41,079 : INFO : EPOCH 1 - PROGRESS: at 87.91% examples, 557326 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:18:42,100 : INFO : EPOCH 1 - PROGRESS: at 92.23% examples, 557510 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-08 11:18:43,106 : INFO : EPOCH 1 - PROGRESS: at 96.54% examples, 558159 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:43,888 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:18:43,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:18:43,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:18:43,919 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:18:43,919 : INFO : EPOCH - 1 : training on 17797887 raw words (13392384 effective words) took 24.0s, 558268 effective words/s\n",
      "2018-11-08 11:18:43,919 : INFO : training on a 17797887 raw words (13392384 effective words) took 24.0s, 557989 effective words/s\n",
      "2018-11-08 11:18:43,919 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:18:44,920 : INFO : EPOCH 1 - PROGRESS: at 10.25% examples, 1388079 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:45,929 : INFO : EPOCH 1 - PROGRESS: at 20.26% examples, 1363453 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:46,927 : INFO : EPOCH 1 - PROGRESS: at 31.20% examples, 1394783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:47,935 : INFO : EPOCH 1 - PROGRESS: at 42.23% examples, 1407647 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:48,937 : INFO : EPOCH 1 - PROGRESS: at 53.00% examples, 1416760 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:49,951 : INFO : EPOCH 1 - PROGRESS: at 63.88% examples, 1424296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:50,944 : INFO : EPOCH 1 - PROGRESS: at 74.71% examples, 1426947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:51,946 : INFO : EPOCH 1 - PROGRESS: at 85.12% examples, 1421486 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:52,956 : INFO : EPOCH 1 - PROGRESS: at 96.02% examples, 1425440 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:18:53,300 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:18:53,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:18:53,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:18:53,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:18:53,301 : INFO : EPOCH - 1 : training on 17797887 raw words (13393192 effective words) took 9.4s, 1426459 effective words/s\n",
      "2018-11-08 11:18:53,301 : INFO : training on a 17797887 raw words (13393192 effective words) took 9.4s, 1425511 effective words/s\n",
      "2018-11-08 11:18:53,301 : INFO : training model with 4 workers on 74453 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-08 11:18:54,307 : INFO : EPOCH 1 - PROGRESS: at 7.83% examples, 1059330 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:55,333 : INFO : EPOCH 1 - PROGRESS: at 15.81% examples, 1061103 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:56,336 : INFO : EPOCH 1 - PROGRESS: at 23.95% examples, 1064369 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:57,338 : INFO : EPOCH 1 - PROGRESS: at 31.93% examples, 1067460 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:58,341 : INFO : EPOCH 1 - PROGRESS: at 40.05% examples, 1066128 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:18:59,342 : INFO : EPOCH 1 - PROGRESS: at 47.39% examples, 1054208 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:00,345 : INFO : EPOCH 1 - PROGRESS: at 55.34% examples, 1056900 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:01,362 : INFO : EPOCH 1 - PROGRESS: at 63.31% examples, 1057339 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:02,366 : INFO : EPOCH 1 - PROGRESS: at 71.33% examples, 1058039 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:03,384 : INFO : EPOCH 1 - PROGRESS: at 79.45% examples, 1059835 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-08 11:19:04,371 : INFO : EPOCH 1 - PROGRESS: at 87.50% examples, 1061340 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:05,378 : INFO : EPOCH 1 - PROGRESS: at 95.04% examples, 1056379 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:05,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-08 11:19:05,974 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-08 11:19:05,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-08 11:19:05,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-08 11:19:05,990 : INFO : EPOCH - 1 : training on 17797887 raw words (13393722 effective words) took 12.7s, 1057065 effective words/s\n",
      "2018-11-08 11:19:05,990 : INFO : training on a 17797887 raw words (13393722 effective words) took 12.7s, 1056588 effective words/s\n",
      "2018-11-08 11:19:06,046 : INFO : training model with 4 workers on 74453 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-08 11:19:07,067 : INFO : EPOCH 1 - PROGRESS: at 4.17% examples, 556565 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:08,066 : INFO : EPOCH 1 - PROGRESS: at 8.17% examples, 537960 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-08 11:19:09,083 : INFO : EPOCH 1 - PROGRESS: at 12.11% examples, 538611 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-08 11:19:10,104 : INFO : EPOCH 1 - PROGRESS: at 16.15% examples, 537351 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-08 11:19:11,096 : INFO : EPOCH 1 - PROGRESS: at 20.39% examples, 543566 words/s, in_qsize 8, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m2 = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores)\n",
    "m3 = Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab with first model using all documents\n",
    "m1.build_vocab(allDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "m3.reset_from(m1)\n",
    "\n",
    "# Set training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "# Train the models\n",
    "for epoch in range(passes):  \n",
    "    # Shuffle the documents; literature reports this provides the best results\n",
    "    shuffle(allDocs)\n",
    "    \n",
    "    # Train the models\n",
    "    m1.alpha, m1.min_alpha = alpha, alpha\n",
    "    m1.train(allDocs, total_examples = m1.corpus_count, epochs = 1)\n",
    "    \n",
    "    m2.alpha, m2.min_alpha = alpha, alpha\n",
    "    m2.train(allDocs, total_examples = m2.corpus_count, epochs = 1)\n",
    "    \n",
    "    m3.alpha, m3.min_alpha = alpha, alpha\n",
    "    m3.train(allDocs, total_examples = m3.corpus_count, epochs = 1)\n",
    "   \n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination one:  Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m2 and m3)\n",
    "xTrain = []\n",
    "\n",
    "infer_steps = 5\n",
    "infer_alpha = 0.01\n",
    "\n",
    "for i in tqdm(range(0, len(taggedDocs))):\n",
    "    xTrain.append(np.hstack((\n",
    "        m1.infer_vector(taggedDocs[i].words, steps=infer_steps, alpha=infer_alpha),\n",
    "        m2.infer_vector(taggedDocs[i].words, steps=infer_steps, alpha=infer_alpha)\n",
    "    )))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.052Z"
    }
   },
   "outputs": [],
   "source": [
    "#results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination two:  Train and assess classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the feature set by combining vectors from multiple models (m2 and m3)\n",
    "xTrain = []\n",
    "\n",
    "infer_steps = 7\n",
    "infer_alpha = 0.01\n",
    "\n",
    "for i in tqdm(range(0, len(taggedDocs))):\n",
    "    xTrain.append(np.hstack((\n",
    "        m1.infer_vector(taggedDocs[i].words, steps=infer_steps, alpha=infer_alpha),\n",
    "        m2.infer_vector(taggedDocs[i].words, steps=infer_steps, alpha=infer_alpha),\n",
    "        m3.infer_vector(taggedDocs[i].words, steps=infer_steps, alpha=infer_alpha)\n",
    "    )))\n",
    "    \n",
    "print(\"len(xTrain)\", len(xTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.060Z"
    }
   },
   "outputs": [],
   "source": [
    "results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['SVM', 'LDA', 'LR'])\n",
    "#results, _df = trainModels(xTrain, df.iloc[:, 1], modelsToRun = ['LDA', 'LR'])\n",
    "print(_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True]))\n",
    "makeWhisker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "So far Doc2Vec with combined models and manual training has given us the best results with a 89.53% on the training data.  This is 3 percentage points over the baseline and the Doc2Vec centroid models, and 5 percentage points better than the initial, untuned Doc2Ved model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-08T16:48:34.065Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this write-up we accomplished the following:\n",
    "\n",
    "1. Created a set of document vectors from the IMDb movie review text utilizing [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "2. Tuned and trained a number of Doc2Vec models on the movie review corpus \n",
    "2. Ran the models from the [first write-up](./Model-06.ipynb) against the Doc2Vec feature set outputs\n",
    "3. Evaluated if utilizing Doc2Vec improved our ability to correctly classify movie review sentiment\n",
    "\n",
    "\n",
    "Performance metrics so far:\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|--------------------------|--------|-----------------------------------|\n",
    "|LR (baseline)             |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid              |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec               |84.48%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec Init tuning   |88.45%  |dm0, vs100, ng5, hs0, mc2, sm0, e20|\n",
    "|LR manual/combined        |89.53%  |model1, model2, model3             |\n",
    "<div style=\"clear:both\"></div>\n",
    "\n",
    "\n",
    "Utilizing Doc2Vec with manual training and combining model outputs has given us the best classification results to date.  We were able to gain over 3 percentage points in performance from the LR baseline model.\n",
    "\n",
    "If we were to continue this write-up it would be interesting to explore adding many models together and seeing how that affected the output  similar to bagging.  We could also likely spend a lot of time with further tuning, because both the Doc2Vec and Scikit-learn models have a large number of tunable parameters we could leverage.  The best strategy would likely be to start with a randomized grid search due to the large number of parameters, and then focus in on a more narrow set once the more performant combinations started to emerge.\n",
    "\n",
    "And lastly, I'd also like to try taking the combined model feature set and feeding it to a neural network or LSTM for final classification.  It would be interesting to see how one of these more complex algorithms compared against the Scikit-learn linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
