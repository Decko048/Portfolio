{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#IMDB-Movie-Review-Sentiment-Classification\" data-toc-modified-id=\"IMDB-Movie-Review-Sentiment-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IMDB Movie Review Sentiment Classification</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Methodology\" data-toc-modified-id=\"Methodology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Methodology</a></span></li><li><span><a href=\"#Configure-notebook,-import-libraries,-and-import-dataset\" data-toc-modified-id=\"Configure-notebook,-import-libraries,-and-import-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configure notebook, import libraries, and import dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Define-global-variables\" data-toc-modified-id=\"Define-global-variables-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Define global variables</a></span></li><li><span><a href=\"#Load-in-data-sets\" data-toc-modified-id=\"Load-in-data-sets-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Load in data sets</a></span></li></ul></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#Examine-the-data\" data-toc-modified-id=\"Examine-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Examine the data</a></span></li><li><span><a href=\"#Cleaning-and-preprocessing\" data-toc-modified-id=\"Cleaning-and-preprocessing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cleaning and preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Write-helper-functions\" data-toc-modified-id=\"Write-helper-functions-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Write helper functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-cleaner\" data-toc-modified-id=\"Sentence-cleaner-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Sentence cleaner</a></span></li></ul></li><li><span><a href=\"#Create-list-of-cleaned-and-processed-Doc2Vec-TaggedDocument-objects\" data-toc-modified-id=\"Create-list-of-cleaned-and-processed-Doc2Vec-TaggedDocument-objects-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Create list of cleaned and processed Doc2Vec TaggedDocument objects</a></span></li></ul></li><li><span><a href=\"#Doc2Vec-model-tuning\" data-toc-modified-id=\"Doc2Vec-model-tuning-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Doc2Vec model tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-process-sanity-check\" data-toc-modified-id=\"Ensemble-process-sanity-check-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Ensemble process sanity check</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sanity-check---Create-Doc2Vec-model,-build-vocab,-and-train\" data-toc-modified-id=\"Sanity-check---Create-Doc2Vec-model,-build-vocab,-and-train-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Sanity check - Create Doc2Vec model, build vocab, and train</a></span></li><li><span><a href=\"#Sanity-check---Split-Doc2Vec-vectors-into-train,-validation,-and-test-sets\" data-toc-modified-id=\"Sanity-check---Split-Doc2Vec-vectors-into-train,-validation,-and-test-sets-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Sanity check - Split Doc2Vec vectors into train, validation, and test sets</a></span></li><li><span><a href=\"#Sanity-check---Train-and-assess-classifier\" data-toc-modified-id=\"Sanity-check---Train-and-assess-classifier-8.1.3\"><span class=\"toc-item-num\">8.1.3&nbsp;&nbsp;</span>Sanity check - Train and assess classifier</a></span></li><li><span><a href=\"#Sanity-check---Comments\" data-toc-modified-id=\"Sanity-check---Comments-8.1.4\"><span class=\"toc-item-num\">8.1.4&nbsp;&nbsp;</span>Sanity check - Comments</a></span></li></ul></li></ul></li><li><span><a href=\"#Combining-Doc2Vec-models\" data-toc-modified-id=\"Combining-Doc2Vec-models-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Combining Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-baseline-Doc2Vec-models,-train,-and-evaluate\" data-toc-modified-id=\"Create-baseline-Doc2Vec-models,-train,-and-evaluate-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Create baseline Doc2Vec models, train, and evaluate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Doc2Vec-models\" data-toc-modified-id=\"Create-Doc2Vec-models-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>Create Doc2Vec models</a></span></li><li><span><a href=\"#Assess-combined-model-outputs-on-XGBoost-classifier\" data-toc-modified-id=\"Assess-combined-model-outputs-on-XGBoost-classifier-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>Assess combined model outputs on XGBoost classifier</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-9.1.3\"><span class=\"toc-item-num\">9.1.3&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Doc2Vec-tuning\" data-toc-modified-id=\"Doc2Vec-tuning-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Doc2Vec tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Develop-helper-functions\" data-toc-modified-id=\"Develop-helper-functions-9.2.1\"><span class=\"toc-item-num\">9.2.1&nbsp;&nbsp;</span>Develop helper functions</a></span></li><li><span><a href=\"#PV-DM-(dm-=-1)-model-tuning\" data-toc-modified-id=\"PV-DM-(dm-=-1)-model-tuning-9.2.2\"><span class=\"toc-item-num\">9.2.2&nbsp;&nbsp;</span>PV-DM (dm = 1) model tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#PV-DM-(dm-=-1)-model-tuning-comments\" data-toc-modified-id=\"PV-DM-(dm-=-1)-model-tuning-comments-9.2.2.1\"><span class=\"toc-item-num\">9.2.2.1&nbsp;&nbsp;</span>PV-DM (dm = 1) model tuning comments</a></span></li></ul></li><li><span><a href=\"#Tune-PV-DBOW-(dm-=-0)-model-tuning\" data-toc-modified-id=\"Tune-PV-DBOW-(dm-=-0)-model-tuning-9.2.3\"><span class=\"toc-item-num\">9.2.3&nbsp;&nbsp;</span>Tune PV-DBOW (dm = 0) model tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#PV-DBOW-(dm-=-0)-model-tuning-comments\" data-toc-modified-id=\"PV-DBOW-(dm-=-0)-model-tuning-comments-9.2.3.1\"><span class=\"toc-item-num\">9.2.3.1&nbsp;&nbsp;</span>PV-DBOW (dm = 0) model tuning comments</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Create-instances-of-tuned-Doc2Vec-models-and-create-feature-set\" data-toc-modified-id=\"Create-instances-of-tuned-Doc2Vec-models-and-create-feature-set-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Create instances of tuned Doc2Vec models and create feature set</a></span></li><li><span><a href=\"#Tune-XGBoost-using-best-Doc2Vec-models\" data-toc-modified-id=\"Tune-XGBoost-using-best-Doc2Vec-models-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Tune XGBoost using best Doc2Vec models</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Pick-sane-model-param-defaults\" data-toc-modified-id=\"Pick-sane-model-param-defaults-11.0.1\"><span class=\"toc-item-num\">11.0.1&nbsp;&nbsp;</span>Pick sane model param defaults</a></span></li><li><span><a href=\"#Calculate-best-initial-n_estimators-value-(i.e.-number-of-trees)\" data-toc-modified-id=\"Calculate-best-initial-n_estimators-value-(i.e.-number-of-trees)-11.0.2\"><span class=\"toc-item-num\">11.0.2&nbsp;&nbsp;</span>Calculate best initial n_estimators value (i.e. number of trees)</a></span></li><li><span><a href=\"#Tune-max_depth-and-min_child_weight\" data-toc-modified-id=\"Tune-max_depth-and-min_child_weight-11.0.3\"><span class=\"toc-item-num\">11.0.3&nbsp;&nbsp;</span>Tune max_depth and min_child_weight</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fine-tune\" data-toc-modified-id=\"Fine-tune-11.0.3.1\"><span class=\"toc-item-num\">11.0.3.1&nbsp;&nbsp;</span>Fine tune</a></span></li></ul></li></ul></li><li><span><a href=\"#Tune-gamma,-subsample-and-colsample_bytree\" data-toc-modified-id=\"Tune-gamma,-subsample-and-colsample_bytree-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Tune gamma, subsample and colsample_bytree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gamma-tuning\" data-toc-modified-id=\"Gamma-tuning-11.1.1\"><span class=\"toc-item-num\">11.1.1&nbsp;&nbsp;</span>Gamma tuning</a></span></li><li><span><a href=\"#Calculate-optimal-n_estimators-value\" data-toc-modified-id=\"Calculate-optimal-n_estimators-value-11.1.2\"><span class=\"toc-item-num\">11.1.2&nbsp;&nbsp;</span>Calculate optimal n_estimators value</a></span></li><li><span><a href=\"#subsample-and-colsample_bytree-tuning\" data-toc-modified-id=\"subsample-and-colsample_bytree-tuning-11.1.3\"><span class=\"toc-item-num\">11.1.3&nbsp;&nbsp;</span>subsample and colsample_bytree tuning</a></span></li></ul></li><li><span><a href=\"#Tune-regularization-params,-reg_alpha-and-reg_lambda\" data-toc-modified-id=\"Tune-regularization-params,-reg_alpha-and-reg_lambda-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Tune regularization params, reg_alpha and reg_lambda</a></span></li><li><span><a href=\"#Obtain-new-n_estimators-value\" data-toc-modified-id=\"Obtain-new-n_estimators-value-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Obtain new n_estimators value</a></span></li><li><span><a href=\"#Tune-the-learning-rate-and-re-eval-n_estimators\" data-toc-modified-id=\"Tune-the-learning-rate-and-re-eval-n_estimators-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Tune the learning rate and re-eval n_estimators</a></span></li></ul></li><li><span><a href=\"#Test-set-predictions-and-Kaggle-score\" data-toc-modified-id=\"Test-set-predictions-and-Kaggle-score-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Test set predictions and Kaggle score</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-and-validation-on-the-entire-dataset\" data-toc-modified-id=\"Training-and-validation-on-the-entire-dataset-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Training and validation on the entire dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-best-Doc2Vec-models\" data-toc-modified-id=\"Train-best-Doc2Vec-models-12.1.1\"><span class=\"toc-item-num\">12.1.1&nbsp;&nbsp;</span>Train best Doc2Vec models</a></span></li><li><span><a href=\"#Train-best-XGBoost-model\" data-toc-modified-id=\"Train-best-XGBoost-model-12.1.2\"><span class=\"toc-item-num\">12.1.2&nbsp;&nbsp;</span>Train best XGBoost model</a></span></li><li><span><a href=\"#Examine-predictions\" data-toc-modified-id=\"Examine-predictions-12.1.3\"><span class=\"toc-item-num\">12.1.3&nbsp;&nbsp;</span>Examine predictions</a></span></li></ul></li><li><span><a href=\"#Training-and-validation-on-the-entire-dataset-with-stemming-and-contractions\" data-toc-modified-id=\"Training-and-validation-on-the-entire-dataset-with-stemming-and-contractions-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Training and validation on the entire dataset with stemming and contractions</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Movie Review Sentiment Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 30%; height: 30%;\" src=\"images/imdb.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to:\n",
    "\n",
    "1. Clean and process the IMDb source data\n",
    "1. Develop an ensemble:\n",
    "   1. Create and optimize two Doc2Vec models: Distributed bag of words (PV-DBOW) and Distributed memory (PV-DM)\n",
    "   1. Combine the outputs of these two models\n",
    "   1. Feed the combined output to a XGBoost classification model\n",
    "   1. Perform tuning on the XGBoost classification model\n",
    "1. Examine accuracy scores against the evaluation data set\n",
    "1. Submit results to Kaggle if improvements occur against our current best score of 0.88840 achieved via a CNN\n",
    "\n",
    "References:\n",
    "* [Gensim Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "* [Original paper](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "* [XGBoost API](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "\n",
    "Dataset source:  [IMDB Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "First, I normally develop the code and go through the process before finishing the narrative.  As such we'll cut some portions of the process out for brevity's sake where appropriate.  I will make note when this occurs.\n",
    "\n",
    "Next, progress and model performance was assessed against 1st) evaluation data set accuracy (which so far has shown positive correlation to Kaggle score), and then 2nd) Kaggle submission score.  \n",
    "\n",
    "(So far the best Kaggle score we've achieved is 0.88840 utilizing a CNN in (this write-up)[].)\n",
    "\n",
    "I also read in papers--and experienced personally via hands-on testing--that hyperparameter tuning only provided small, incremental improvements.  The largest improvements in classification accuracy came from preparation of the source data.  As such I added steps for resolving contractions, added a NLTK Lemmatizer, etc. to the data cleaning/processing steps.\n",
    "\n",
    "And finally the Doc2Vec and XGBoost models were first created and baselined with 'sane' defaults which I aggregated from research and reading followed by rounds of tuning to (hopefully) optimize performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure notebook, import libraries, and import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T15:16:22.416553Z",
     "start_time": "2018-10-16T15:16:22.413553Z"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T20:49:57.327497Z",
     "start_time": "2018-12-10T20:49:56.251062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import os, re, csv, copy, pickle, random\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import xgboost as xg\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# http://www.nltk.org/index.html\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Creating function implementing punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Only need this the first time...\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Opens a GUI that allows us to download the NLTK data\n",
    "# nltk.download()\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer as lemm\n",
    "\n",
    "\n",
    "# conda install -c conda-forge spacy\n",
    "# -OR-\n",
    "# pip install spacy\n",
    "# -then-\n",
    "# python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# https://pypi.org/project/gensim/\n",
    "# pip install gensim\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert(gensim.models.doc2vec.FAST_VERSION > -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:26.172891Z",
     "start_time": "2018-12-05T17:38:23.139805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the seeds\n",
    "seedVal = 10\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(seedVal)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seedVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:26.494750Z",
     "start_time": "2018-12-05T17:38:26.175899Z"
    }
   },
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "contractionsObj = re.compile('(%s)' % '|'.join(contractions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:28.419882Z",
     "start_time": "2018-12-05T17:38:26.496756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labDat.shape : (25000, 3)\n",
      "unlabDat.shape : (50000, 2)\n",
      "testDat.shape : (25000, 2)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n",
      "labDat.info() : None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      "id           50000 non-null object\n",
      "review       50000 non-null object\n",
      "sentiment    0 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n",
      "unlabDat.info() : None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "review       25000 non-null object\n",
      "sentiment    0 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 586.0+ KB\n",
      "testDat.info() : None\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')\n",
    "unlabeledTrainData = os.path.join(dataPath, 'unlabeledTrainData.tsv')\n",
    "testData = os.path.join(dataPath, 'testData.tsv')\n",
    "\n",
    "\n",
    "labDat = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "unlabDat = pd.read_csv(unlabeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "testDat = pd.read_csv(testData, sep = '\\t', header = 0, quoting = 3)\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "print('labDat.shape :', labDat.shape)\n",
    "print('unlabDat.shape :', unlabDat.shape)\n",
    "print('testDat.shape :', testDat.shape)\n",
    "\n",
    "unlabDat['sentiment'] = None\n",
    "testDat['sentiment'] = None\n",
    "\n",
    "print(\"\\n\")\n",
    "print('labDat.info() :', labDat.info())\n",
    "print(\"\\n\")\n",
    "print('unlabDat.info() :', unlabDat.info())\n",
    "print(\"\\n\")\n",
    "print('testDat.info() :', testDat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:28.793876Z",
     "start_time": "2018-12-05T17:38:28.420885Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      "id           100000 non-null object\n",
      "review       100000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combinedDat = pd.concat(objs=[labDat, unlabDat, testDat], axis=0).reset_index(drop=True)\n",
    "print(combinedDat.shape)\n",
    "print(\"\\n\")\n",
    "print(combinedDat.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:29.123756Z",
     "start_time": "2018-12-05T17:38:28.794879Z"
    }
   },
   "outputs": [],
   "source": [
    "def expandContractions(txt, contractions = contractions):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractionsObj.sub(replace, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Examine-the-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write helper functions\n",
    "\n",
    "Doc2Vec expects a list of `TaggedDocument` objects.  The first argument of the `TaggedDocument` constructor is a contiguous list of words (which we'll clean as usual), and the second argument is a unique tag.  For example, here is what a sample `TaggedDocument` object looks like:\n",
    "\n",
    "```\n",
    "TaggedDocument(words=['with', 'all', 'this', 'stuff', 'going', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'started', 'listening', 'to', 'his', ...... <SNIP>], tags=[0])\n",
    "```\n",
    "\n",
    "In order to facilitate this we'll first write the \"cleaner\" function to process the review text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence cleaner\n",
    "\n",
    "Take a given sentence and process/clean it (i.e. remove HTML and other cruft, lower case the text, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:30.802800Z",
     "start_time": "2018-12-05T17:51:30.430807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean IMDB review text\n",
    "def cleanReview(review, removeStopWords = False, applyLemmatizing = False):\n",
    "    # Convert the stop words to a set\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Remove HTML\n",
    "    clean = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Expand contractions (i.e. wasn't => was not)\n",
    "    clean = expandContractions(clean)\n",
    "    \n",
    "    # Remove non-alpha chars\n",
    "    clean = re.sub(\"[^a-zA-Z]\", ' ', clean)\n",
    "    \n",
    "    # Lemmatizer\n",
    "    if applyLemmatizing:\n",
    "        # This also results in the words being lower cased and tokenized\n",
    "        clean = nlp(clean)\n",
    "        clean = [token.lemma_ for token in clean]\n",
    "        # Remove any strings containing only spaces\n",
    "        clean = [x for x in clean if x.strip()]\n",
    "    else:\n",
    "        # Convert to lower case and \"tokenize\"\n",
    "        clean = clean.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    if removeStopWords:\n",
    "        clean = [x for x in clean if not x in stopWords]\n",
    "    \n",
    "    # Return results\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick examination of the raw text and then the processed output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:31.199816Z",
     "start_time": "2018-12-05T17:51:30.871940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Looking for Quo Vadis at my local video store, I found this 1985 version that looked interesting. Wow! It was amazing! Very much a Ken Russell kind of film -quirky, stylized, very artistic, and of course \\\\\"different.\\\\\" Nero was presented not so much as evil incarnate, but as a wacky, unfulfilled emperor who would rather have had a circus career. He probably wondered why on earth he was put in the position of \\\\\"leading\\\\\" an empire -it wasn\\'t much fun, and fun is what he longed for. Klause Maria Bandaur had a tremendous time with this role and played it for all it was worth. Yes, Nero persecuted the Christians with a vengeance; one of many who did so. At one point one of his henchmen murmurs: \\\\\"No one will ever understand we were simply protecting ourselves.\\\\\" He got that right.\"'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine raw\n",
    "combinedDat.iloc[25,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:31.663054Z",
     "start_time": "2018-12-05T17:51:31.202824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look',\n",
       " 'quo',\n",
       " 'vadis',\n",
       " '-PRON-',\n",
       " 'local',\n",
       " 'video',\n",
       " 'store',\n",
       " '-PRON-',\n",
       " 'find',\n",
       " 'version',\n",
       " 'look',\n",
       " 'interesting']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine processed\n",
    "cleanReview(combinedDat.iloc[25,1], True, True)[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of cleaned and processed Doc2Vec TaggedDocument objects\n",
    "\n",
    "Next we need to create a collection of cleaned and processed `TaggedDocument` objects using the helper functions we just wrote.  We'll want one TaggedDocument object for each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:09.776000Z",
     "start_time": "2018-12-05T22:44:09.437096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allows us to write various cleaning/processing methods to different files if required\n",
    "#docsFileName = \"taggedDocs.p\"\n",
    "docsFileName = \"taggedDocsTrainOnly.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:11.735726Z",
     "start_time": "2018-12-05T22:44:10.510459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell if you've already cleaned and proccessed the reviews and want to load the previous results\n",
    "taggedDocs = pickle.load( open(docsFileName, \"rb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T20:31:03.714427Z",
     "start_time": "2018-12-05T20:25:58.000337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5e8fbd5dcf4108a0bf7198b15465fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell if you need to clean and proccesse the reviews\n",
    "writeToDisk = True\n",
    "trainOnly = True\n",
    "taggedDocs = []\n",
    "\n",
    "# Cleaning and processing params - Alter these to configure the cleaning/processing of the review text\n",
    "removeStopWords = True\n",
    "applyLemmatizing = True\n",
    "\n",
    "for i, s in tqdm(enumerate(combinedDat.iloc[:,1])):\n",
    "    # Allows us to only process the training data... useful if we want to explore the\n",
    "    # impact of different cleaning pipelines later on w/ various models\n",
    "    if (trainOnly) and (i == 25000):\n",
    "        break\n",
    "    # Remove stop words and apply Lemmatizing\n",
    "    clean = cleanReview(s, removeStopWords, applyLemmatizing)\n",
    "    taggedDocs.append(TaggedDocument(clean, [i]))\n",
    "    \n",
    "if writeToDisk:\n",
    "    # Write to disk, so we can load if/when we run the notebook again\n",
    "    pickle.dump( taggedDocs, open(docsFileName, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:15.267029Z",
     "start_time": "2018-12-05T22:44:14.941161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check we have the same number of objects as reviews\n",
    "len(taggedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:15.803811Z",
     "start_time": "2018-12-05T22:44:15.485960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['look', 'quo', 'vadis', '-PRON-', 'local', 'video', 'store', '-PRON-', 'find', 'version', 'look', 'interesting', 'wow', '-PRON-', 'amazing', 'much', 'ken', 'russell', 'kind', 'film', 'quirky', 'stylize', 'artistic', 'course', 'different', 'nero', 'present', 'much', 'evil', 'incarnate', 'wacky', 'unfulfilled', 'emperor', 'would', 'rather', 'circus', 'career', '-PRON-', 'probably', 'wonder', 'earth', '-PRON-', 'put', 'position', 'lead', 'empire', '-PRON-', 'much', 'fun', 'fun', '-PRON-', 'long', 'klause', 'maria', 'bandaur', 'tremendous', 'time', 'role', 'play', '-PRON-', '-PRON-', 'worth', 'yes', 'nero', 'persecute', 'christians', 'vengeance', 'one', 'many', 'one', 'point', 'one', '-PRON-', 'henchman', 'murmur', 'one', 'ever', 'understand', '-PRON-', 'simply', 'protect', '-PRON-', '-PRON-', 'get', 'right'], tags=[25])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine an example:\n",
    "taggedDocs[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec model tuning \n",
    "\n",
    "We are now ready to train the Doc2Vec models.  The process will go something like this:\n",
    "1. Define two Doc2Vec model objects:  PV-DBOW and PV-DM\n",
    "2. Build vocabulary from a sequence of sentences (i.e. our cleaned and processed reviews)\n",
    "3. Train the Doc2Vec models (Doc2Vec uses a inner shallow neural network to create the embeddings)\n",
    "4. Create a combined feature set utilizing the trained Doc2Vec models\n",
    "5. Pass the combined feature set to the XGBoost model for evaluation\n",
    "\n",
    "Two very helpful resources for tuning:\n",
    "\n",
    "1. [The original paper itself](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "2. [Gensim's Doc2Vec Tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb)\n",
    "\n",
    "One note however:  During my research I came across some discussion/controversy about the validity of the final accuracy score in the original paper.  This also included skepticism voiced by one of the paper's authors, Mikilov.  As such we won't try to replicate the paper's accuracy metrics exactly, as there is some question as to whether that is possible or not on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble process sanity check\n",
    "\n",
    "Let's begin by ensuring the process we outlined above works.  First we'll create a single Doc2Vec model instance, run the collection of tagged documents through it, and then feed the results to a XGBoost model.  We'll examine the accuracy and confirm the ensemble pipeline we wish to utilize outputs sane results.\n",
    "\n",
    "### Sanity check - Create Doc2Vec model, build vocab, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.186264Z",
     "start_time": "2018-12-05T21:20:21.959552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc2vecModel = Doc2Vec(dm = 0, vector_size = 100, negative = 5, hs = 0, min_count = 2, sample = 0, epochs = 20, workers = cores)\n",
    "doc2vecModel.build_vocab(taggedDocs)\n",
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.540198Z",
     "start_time": "2018-12-05T21:20:55.187266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(doc2vecModel.docvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Split Doc2Vec vectors into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.872077Z",
     "start_time": "2018-12-05T21:20:55.541203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "trainVecs = doc2vecModel.docvecs.doctag_syn0[:25000]\n",
    "\n",
    "if not trainOnly:\n",
    "    valVecs = doc2vecModel.docvecs.doctag_syn0[25000:75000]\n",
    "    testVecs = doc2vecModel.docvecs.doctag_syn0[75000:]\n",
    "\n",
    "trainLabels = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "print(len(trainVecs))\n",
    "print(len(trainLabels))\n",
    "\n",
    "if not trainOnly:\n",
    "    print(len(valVecs))\n",
    "    print(len(testVecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:56.226010Z",
     "start_time": "2018-12-05T21:20:55.876088Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    trainVecs, \n",
    "    trainLabels, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = trainLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Train and assess classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:56.591977Z",
     "start_time": "2018-12-05T21:20:56.227013Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    fig, (ax1) = plt.subplots(nrows = 1, ncols = 1, figsize = (8, 4))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    ax1.plot(history['validation_0']['auc'])\n",
    "    ax1.plot(history['validation_1']['auc'])\n",
    "    ax1.set_title('Model AUC')\n",
    "    ax1.set_ylabel('AUC')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Val'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:21.564900Z",
     "start_time": "2018-12-05T21:20:56.592980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.768587\tvalidation_1-auc:0.757861\n",
      "[50]\tvalidation_0-auc:0.921614\tvalidation_1-auc:0.899597\n",
      "[99]\tvalidation_0-auc:0.946207\tvalidation_1-auc:0.922702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=10, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xg.XGBClassifier(\n",
    "    objective = \"binary:logistic\",\n",
    "    random_state = seedVal\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 5,\n",
    "    callbacks=[\n",
    "        xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:21.921844Z",
     "start_time": "2018-12-05T21:21:21.566904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1052  198]\n",
      " [ 182 1068]]\n",
      "0.848\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_eval)\n",
    "print(confusion_matrix(y_eval, preds))\n",
    "print(accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:22.440210Z",
     "start_time": "2018-12-05T21:21:21.922847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotHistory(model.evals_result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Comments\n",
    "\n",
    "The ensemble process seems to be working well.  We achieved an eval data set accuracy rating of 0.848 right out of the gate which isn't too far off from what we achieved utilizing the best model to date (a CNN model written in a [previous write-up]().\n",
    "\n",
    "We can now continue with tuning the Doc2Vec and XGBoost models in the hopes of increasing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Doc2Vec models\n",
    "\n",
    "Next we'll move on to combining the outputs of two Doc2Vec models into a single output and then evaluating performance.  We'll first explore two models with \"sane\" hyperparameter settings, record the results as a baseline, and then advance into tuning.\n",
    "\n",
    "One model will be a PV-DBOW and the other a PV-DM.\n",
    "\n",
    "(Note that I experimented with a few combinations of model parameters before I came up with good baselines, but I'll omit that testing and utilize only the two best baseline Doc2Vec models below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baseline Doc2Vec models, train, and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Doc2Vec models\n",
    "First, create and train the Doc2Vec models.  We'll also include a mechanism to shuffle the tagged documents each epoch, which the literature reports improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:08:20.684824Z",
     "start_time": "2018-12-05T23:06:50.051995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m2 = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, workers=cores)\n",
    "m3 = Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m2.build_vocab(taggedDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other model(s)\n",
    "m3.reset_from(m2)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "# We don't want to shuffle taggedDocs in place later on, so make a copy\n",
    "mixedUp = taggedDocs.copy()\n",
    "\n",
    "# Train the models.  We need to manually adjust the alpha since we want to \n",
    "# shuffle the tagged docs each epoch\n",
    "for epoch in range(passes):  \n",
    "    # Shuffle the documents; literature reports this provides the best results\n",
    "    random.Random(seedVal).shuffle(mixedUp)\n",
    "    \n",
    "    # Train the models  \n",
    "    m2.alpha, m2.min_alpha = alpha, alpha\n",
    "    m2.train(mixedUp, total_examples = m2.corpus_count, epochs = 1)\n",
    "    \n",
    "    m3.alpha, m3.min_alpha = alpha, alpha\n",
    "    m3.train(mixedUp, total_examples = m3.corpus_count, epochs = 1)\n",
    "   \n",
    "    alpha -= alpha_delta\n",
    "\n",
    "# From the docs:  If you’re finished training a model (=no more updates, only querying, reduce memory usage),\n",
    "# you can do \"model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\"\n",
    "m2.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "m3.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "# Release memory\n",
    "del mixedUp\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess combined model outputs on XGBoost classifier\n",
    "\n",
    "Second, ensemble the Doc2Vec model vectors and feed through a XGBoost classification model, and then evaluate the ensemble's performance against the validation test set and establish a performance baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:25.119988Z",
     "start_time": "2018-12-05T23:44:24.786441Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessXGB(xgModel, d2vM1, d2vM2, y):\n",
    "    # Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "    trainVecs = []\n",
    "\n",
    "    for i in range(0, 25000):\n",
    "        trainVecs.append(np.hstack((d2vM1.docvecs[i], d2vM2.docvecs[i])))\n",
    "\n",
    "    print(\"len(trainVecs)\", len(trainVecs))\n",
    "\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        np.asarray(trainVecs), \n",
    "        y, \n",
    "        test_size = 0.1, \n",
    "        shuffle = True, \n",
    "        random_state = seedVal, \n",
    "        stratify = y\n",
    "    )\n",
    "    \n",
    "    xgModel.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = 10,\n",
    "        callbacks=[\n",
    "            xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_eval)\n",
    "    print(confusion_matrix(y_eval, preds))\n",
    "    print(accuracy_score(y_eval, preds))\n",
    "\n",
    "    plotHistory(model.evals_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:09:09.256975Z",
     "start_time": "2018-12-05T23:08:21.064834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trainVecs) 25000\n",
      "[0]\tvalidation_0-auc:0.765762\tvalidation_1-auc:0.756649\n",
      "[50]\tvalidation_0-auc:0.928115\tvalidation_1-auc:0.91227\n",
      "[99]\tvalidation_0-auc:0.951627\tvalidation_1-auc:0.930465\n",
      "[[1078  172]\n",
      " [ 189 1061]]\n",
      "0.8556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xg.XGBClassifier(\n",
    "    objective = \"binary:logistic\",\n",
    "    random_state = seedVal,\n",
    ")\n",
    "\n",
    "assessXGB(model, m2, m3, list(combinedDat['sentiment'][:25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Combining outputs from the PV-DBOW model and the PV-DM model seems to be heading in the right direction.  Accuracy against the evaluation test set increased from 0.848 to 0.8556.\n",
    "\n",
    "Next we'll start hyperparameter tuning for the Doc2Vec models, and see if we can further increase performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec tuning\n",
    "\n",
    "We have two Doc2Vec models to tune hyperparameters for:  PV-DBOW and PV-DM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop helper functions\n",
    "\n",
    "First we'll need to write a function that will allow us to pass in a set of hyperparameters, create a Doc2Vec model utilizing those hyperparameters, and then train the model on the tagged documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T15:35:16.240643Z",
     "start_time": "2018-12-07T15:35:05.499Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainDoc2Vec(params):\n",
    "    m = Doc2Vec(\n",
    "        dm=params['dm'], \n",
    "        dm_concat=params['dm_concat'], \n",
    "        dm_mean=params['dm_mean'],\n",
    "        size=params['size'], \n",
    "        window=params['window'], \n",
    "        negative=params['negative'], \n",
    "        hs=params['hs'], \n",
    "        min_count=params['min_count'], \n",
    "        workers=cores,\n",
    "        vector_size=['vector_size'],\n",
    "        dbow_words=params['dbow_words'],\n",
    "        seed = seedVal\n",
    "    )\n",
    "    \n",
    "    # Build vocab\n",
    "    m.build_vocab(taggedDocs)\n",
    "\n",
    "    # Calculate alpha delta\n",
    "    alpha = params['alpha']\n",
    "    alpha_delta = (params['alpha'] - params['minAlpha']) / params['passes']\n",
    "    \n",
    "    # We don't want to shuffle taggedDocs in place later on, so make a copy\n",
    "    mixedUp = taggedDocs.copy()\n",
    "\n",
    "    # Train the models\n",
    "    for epoch in range(params['passes']):  \n",
    "        # Shuffle the documents; literature reports this provides the best results\n",
    "        random.Random(seedVal).shuffle(mixedUp)\n",
    "\n",
    "        # Train the models\n",
    "        m.alpha, m.min_alpha = alpha, alpha\n",
    "        m.train(taggedDocs, total_examples = m.corpus_count, epochs = 1)\n",
    "        \n",
    "        alpha -= alpha_delta\n",
    "    \n",
    "    # Release memory\n",
    "    m.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    del mixedUp\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next we need a function that combines the document vectors of the trained Doc2Vec models, splits them into training and evaluation sets, feeds the vectors into a XGBoost model to create predictions, and then assess the accuracy of the predictions against the evaluation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:01:04.613019Z",
     "start_time": "2018-12-06T16:00:35.992Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessXGB(xgModel, d2vM1, d2vM2, y, silent = True):\n",
    "    # Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "    # Or from just a single model if only one Doc2Vec model was passed to the function\n",
    "\n",
    "    # Do we have two Doc2Vec models to combine?\n",
    "    if (d2vM2 is not None):\n",
    "        # Yes, combine\n",
    "        trainVecs = []\n",
    "        for i in range(0, 25000):\n",
    "            trainVecs.append(np.hstack((d2vM1.docvecs[i], d2vM2.docvecs[i])))\n",
    "    else:\n",
    "        # No, just use the values from the single model\n",
    "        trainVecs = d2vM1.docvecs.doctag_syn0[:25000]\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"len(trainVecs)\", len(trainVecs))\n",
    "\n",
    "    # Split the Doc2Vec vectors into training and evaluation data sets\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        np.asarray(trainVecs), \n",
    "        trainLabels, \n",
    "        test_size = 0.1, \n",
    "        shuffle = True, \n",
    "        random_state = seedVal, \n",
    "        stratify = trainLabels\n",
    "    )\n",
    "    \n",
    "    # Train the XGBoost model\n",
    "    xgModel.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = 10,\n",
    "        callbacks=[\n",
    "            #xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #print(X_eval.__class__)\n",
    "    #print(X_eval)\n",
    "    #return 1\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = xgModel.predict(X_eval)\n",
    "    \n",
    "    if not silent:\n",
    "        print(confusion_matrix(y_eval, preds))\n",
    "        print(accuracy_score(y_eval, preds))\n",
    "\n",
    "        plotHistory(xgModel.evals_result())\n",
    "    else:\n",
    "        # Return the accuracy on the evaluation data set labels\n",
    "        return accuracy_score(y_eval, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:54:13.257908Z",
     "start_time": "2018-12-05T23:54:12.916000Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "And finally we need another function that passes various hyperparameter combinations to the Doc2Vec model we are tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:17:04.159010Z",
     "start_time": "2018-12-06T16:17:03.807347Z"
    }
   },
   "outputs": [],
   "source": [
    "def searchDoc2VecParamsBase(params, silent = True):\n",
    "    \n",
    "    resultsDF = pd.DataFrame(columns = ['Model', 'Accuracy', 'Params'])\n",
    "    labels = list(combinedDat['sentiment'][:25000])\n",
    "    \n",
    "    for i, p in enumerate(params):\n",
    "        if not silent:\n",
    "                print(\"  Starting param run\", i, \"out of\", len(params)-1, \"...\")\n",
    "        \n",
    "        start = timer()\n",
    "        doc2vecModel = trainDoc2Vec(p)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    Doc2Vec training finished in\", round((end-start)/60, 2), \" mins\")\n",
    "        \n",
    "        xgModel = xg.XGBClassifier(\n",
    "            objective = \"binary:logistic\",\n",
    "            random_state = seedVal\n",
    "        )\n",
    "        \n",
    "        start = timer()\n",
    "        results = assessXGB(xgModel, doc2vecModel, None, labels, silent = True)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    xgModel training finished in\", round((end-start)/60, 2), \" mins with accuracy\", results)\n",
    "    \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            'Pass ' +  str(len(resultsDF)), \n",
    "            results,\n",
    "            p,\n",
    "        ])\n",
    "    \n",
    "    return resultsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PV-DM (dm = 1) model tuning\n",
    "\n",
    "Now that the helper functions are written we'll start tuning the PV-DM model.\n",
    "\n",
    "(Note that I've already done some tuning not shown here for brevity's sake.)\n",
    "\n",
    "---\n",
    "\n",
    "We'll start with `negative`, `min_count`, and `vector_size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T17:51:56.420360Z",
     "start_time": "2018-12-06T17:51:56.067629Z"
    }
   },
   "outputs": [],
   "source": [
    "def tunePVDM_1(silent = True):\n",
    "    print(\"**Starting run!\")\n",
    "    \n",
    "    params = []\n",
    "    base = {'dm':1, 'dm_concat':0, 'dm_mean': 1, 'size':500, 'window':3, 'negative':5, \n",
    "            'hs':0, 'min_count':2, 'passes':10, 'vector_size':300, 'dbow_words':0,\n",
    "            'alpha':0.025, 'minAlpha':0.001}\n",
    "    \n",
    "    for negative_ in [7, 9, 11]:\n",
    "        for min_count_ in np.linspace(2, 5, 4):\n",
    "            for vector_size_ in [500]:\n",
    "                _ = copy.deepcopy(base)\n",
    "                _['negative'] = negative_\n",
    "                _['min_count'] = min_count_\n",
    "                _['vector_size'] = vector_size_\n",
    "                params.append(_)\n",
    "    \n",
    "    results = searchDoc2VecParamsBase(params, silent)\n",
    "    print(\"**Finished!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:23:05.123150Z",
     "start_time": "2018-12-06T17:51:56.421363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass 4</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9, 'hs': 0, 'min_count': 2.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pass 9</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11, 'hs': 0, 'min_count': 3.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pass 10</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11, 'hs': 0, 'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 5.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  \\\n",
       "2   Pass 2   0.8496     \n",
       "4   Pass 4   0.8492     \n",
       "9   Pass 9   0.8460     \n",
       "10  Pass 10  0.8448     \n",
       "3   Pass 3   0.8420     \n",
       "\n",
       "                                                                                                                                                                                                Params  \n",
       "2   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "4   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9, 'hs': 0, 'min_count': 2.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "9   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11, 'hs': 0, 'min_count': 3.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "10  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11, 'hs': 0, 'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "3   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 5.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = tunePVDM_1()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "And now the `alpha` and `minAlpha` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:44:31.981839Z",
     "start_time": "2018-12-06T18:44:31.641941Z"
    }
   },
   "outputs": [],
   "source": [
    "def tunePVDM_2(silent = True):\n",
    "    print(\"**Starting run!\")\n",
    "    \n",
    "    params = []\n",
    "    base = {'dm':1, 'dm_concat':0, 'dm_mean': 1, 'size':500, 'window':3, 'negative':7, \n",
    "            'hs':0, 'min_count':4, 'passes':10, 'vector_size':500, 'dbow_words':0,\n",
    "            'alpha':0.025, 'minAlpha':0.001}\n",
    "    \n",
    "\n",
    "    for alpha in [0.001, 0.025, 0.075]:\n",
    "        for minAlpha in [0.0001, 0.001, 0.01]:\n",
    "            _ = copy.deepcopy(base)\n",
    "            _['alpha'] = alpha\n",
    "            _['minAlpha'] = minAlpha\n",
    "            params.append(_)\n",
    "    \n",
    "    results = searchDoc2VecParamsBase(params, silent)\n",
    "    print(\"**Finished!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T19:06:05.936845Z",
     "start_time": "2018-12-06T18:44:31.982842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass 4</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pass 7</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.075, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.8376</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pass 5</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pass 6</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.075, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "4  Pass 4  0.8416     \n",
       "7  Pass 7  0.8412     \n",
       "3  Pass 3  0.8376     \n",
       "5  Pass 5  0.8352     \n",
       "6  Pass 6  0.8264     \n",
       "\n",
       "                                                                                                                                                                                             Params  \n",
       "4  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "7  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.075, 'minAlpha': 0.001}   \n",
       "3  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}  \n",
       "5  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.01}    \n",
       "6  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.075, 'minAlpha': 0.0001}  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df2 = tunePVDM_2()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df2.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PV-DM (dm = 1) model tuning comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the best set of hyperparameters (see variance comments below) achieved an accuracy rating of 0.8496 for the PV-DM model.  They are as follows:\n",
    "\n",
    "```python\n",
    "{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, \n",
    "'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}\n",
    "```    \n",
    "\n",
    "__HOWEVER BIG NOTE ON VARIANCE__:  You'll notice if you run the training code you'll get slightly different accuracy rates each run!  This appears to be a non-deterministic function of how Doc2Vec works that I haven't found a solution for as of yet.  So, we'll have to look for more significant movements of the accuracy instead of small changes.  For example, if we went from 75% to 81% we could probably feel comfortable whatever adjustment we just made to the model had an effect and wasn't just statistical noise.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variance illustration\n",
    "\n",
    "--- \n",
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T15:36:50.382979Z",
     "start_time": "2018-12-07T15:36:49.996960Z"
    }
   },
   "outputs": [],
   "source": [
    "def tunePVDM_3(silent = True):\n",
    "    print(\"**Starting run!\")\n",
    "    \n",
    "    params = []\n",
    "    base = {'dm':1, 'dm_concat':0, 'dm_mean': 1, 'size':500, 'window':3, 'negative':7, \n",
    "            'hs':0, 'min_count':4, 'passes':10, 'vector_size':500, 'dbow_words':0,\n",
    "            'alpha':0.025, 'minAlpha':0.001}\n",
    "    \n",
    "\n",
    "    for alpha in [0.001, 0.025]:\n",
    "        for minAlpha in [0.0001, 0.001]:\n",
    "            _ = copy.deepcopy(base)\n",
    "            _['alpha'] = alpha\n",
    "            _['minAlpha'] = minAlpha\n",
    "            params.append(_)\n",
    "    \n",
    "    results = searchDoc2VecParamsBase(params, silent)\n",
    "    print(\"**Finished!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Variance one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T15:46:46.240685Z",
     "start_time": "2018-12-07T15:36:50.730128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "3  Pass 3  0.8352     \n",
       "2  Pass 2  0.8272     \n",
       "1  Pass 1  0.6012     \n",
       "0  Pass 0  0.5764     \n",
       "\n",
       "                                                                                                                                                                                             Params  \n",
       "3  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "2  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}  \n",
       "1  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}   \n",
       "0  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df3 = tunePVDM_3()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df3.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Variance two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T15:56:01.270404Z",
     "start_time": "2018-12-07T15:46:46.244696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.5616</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "2  Pass 2  0.8296     \n",
       "3  Pass 3  0.8296     \n",
       "1  Pass 1  0.5992     \n",
       "0  Pass 0  0.5616     \n",
       "\n",
       "                                                                                                                                                                                             Params  \n",
       "2  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}  \n",
       "3  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "1  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}   \n",
       "0  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df3 = tunePVDM_3()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df3.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Variance three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:05:00.617058Z",
     "start_time": "2018-12-07T15:56:01.271407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "2  Pass 2  0.8468     \n",
       "3  Pass 3  0.8392     \n",
       "1  Pass 1  0.6080     \n",
       "0  Pass 0  0.5572     \n",
       "\n",
       "                                                                                                                                                                                             Params  \n",
       "2  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.0001}  \n",
       "3  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}   \n",
       "1  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.001}   \n",
       "0  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, 'hs': 0, 'min_count': 4, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, 'alpha': 0.001, 'minAlpha': 0.0001}  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df3 = tunePVDM_3()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df3.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune PV-DBOW (dm = 0) model tuning\n",
    "\n",
    "I was curious if there would be much of a difference between tuning all the parameters at once vs. in groups.  I tried both methods and achieved the same results.  I'll include only the former below to save space.\n",
    "\n",
    "---\n",
    "\n",
    "Tuning all hyperparamters at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T21:10:40.882751Z",
     "start_time": "2018-12-06T21:10:40.551873Z"
    }
   },
   "outputs": [],
   "source": [
    "def tunePVDBOW_3(silent = True):\n",
    "    print(\"**Starting run!\")\n",
    "    \n",
    "    params = []\n",
    "    base = {'dm':0, 'dm_concat':1, 'dm_mean': 1, 'size':100, 'window':3, 'negative':5, \n",
    "            'hs':0, 'min_count':2, 'passes':10, 'vector_size':300, 'dbow_words':0,\n",
    "            'alpha':0.025, 'minAlpha':0.001}\n",
    "    \n",
    "\n",
    "    for size_ in np.linspace(100, 500, 3):\n",
    "        for window_ in np.linspace(3, 7, 3):\n",
    "            for vector_size_ in np.linspace(100, 700, 4):\n",
    "                for negative in [2, 5, 8]:\n",
    "                    for min_count in [1, 2, 5, 7]:\n",
    "                        _ = copy.deepcopy(base)\n",
    "                        _['size'] = size_\n",
    "                        _['window'] = window_\n",
    "                        _['vector_size'] = vector_size_\n",
    "                        _['negative'] = negative\n",
    "                        _['min_count'] = min_count\n",
    "                        params.append(_)\n",
    "    \n",
    "    results = searchDoc2VecParamsBase(params, silent)\n",
    "    print(\"**Finished!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T08:42:42.352388Z",
     "start_time": "2018-12-06T21:10:40.883754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Pass 416</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Pass 418</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 5, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Pass 190</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 8, 'hs': 0, 'min_count': 5, 'passes': 10, 'vector_size': 700.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Pass 429</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 2, 'passes': 10, 'vector_size': 700.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Pass 368</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 8, 'hs': 0, 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Accuracy  \\\n",
       "416  Pass 416  0.8656     \n",
       "418  Pass 418  0.8648     \n",
       "190  Pass 190  0.8640     \n",
       "429  Pass 429  0.8632     \n",
       "368  Pass 368  0.8620     \n",
       "\n",
       "                                                                                                                                                                                                    Params  \n",
       "416  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "418  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 5, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "190  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 8, 'hs': 0, 'min_count': 5, 'passes': 10, 'vector_size': 700.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "429  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, 'min_count': 2, 'passes': 10, 'vector_size': 700.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  \n",
       "368  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 8, 'hs': 0, 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df3 = tunePVDBOW_3()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df3.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  PV-DBOW (dm = 0) model tuning comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the best set of hyperparameters (see variance comments below) achieved an accuracy rating of 0.8656 for the PV-DBOW model.  They are as follows:\n",
    "\n",
    "```python\n",
    "{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, 'hs': 0, \n",
    " 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, 'alpha': 0.025, 'minAlpha': 0.001}\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instances of tuned Doc2Vec models and create feature set\n",
    "\n",
    "We'll train and assign the best two Doc2Vec models into variables for further use below, and we'll also combine their document vectors into a single feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:27:55.627067Z",
     "start_time": "2018-12-07T16:26:43.821864Z"
    }
   },
   "outputs": [],
   "source": [
    "m1 = trainDoc2Vec({'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 8, \n",
    "                   'hs': 0, 'min_count': 1, 'passes': 10, 'vector_size': 500.0, 'dbow_words': 0, \n",
    "                   'alpha': 0.025, 'minAlpha': 0.001})\n",
    "\n",
    "m2 = trainDoc2Vec({'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7, \n",
    "                   'hs': 0, 'min_count': 4.0, 'passes': 10, 'vector_size': 500, 'dbow_words': 0, \n",
    "                   'alpha': 0.025, 'minAlpha': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T19:27:43.581445Z",
     "start_time": "2018-12-10T19:27:43.251565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n",
      "(25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(m1.docvecs.doctag_syn0.shape)\n",
    "print(m2.docvecs.doctag_syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:28:07.052766Z",
     "start_time": "2018-12-07T16:28:06.683789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "featureSet = np.hstack((m1.docvecs.doctag_syn0, m2.docvecs.doctag_syn0))\n",
    "print(featureSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:28:10.906470Z",
     "start_time": "2018-12-07T16:28:10.508417Z"
    }
   },
   "outputs": [],
   "source": [
    "y = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    featureSet,  \n",
    "    y, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune XGBoost using best Doc2Vec models\n",
    "\n",
    "Training XGBoost isn't as straightforward as other models.  Our strategy will be as follows:\n",
    "\n",
    "1. Pick some sane model param defaults\n",
    "2. Calculate best initial n_estimators value (i.e. number of trees)\n",
    "3. Tune max_depth and min_child_weight\n",
    "4. Tune gamma, subsample and colsample_bytree\n",
    "5. Tune regularization params, reg_alpha and reg_lambda\n",
    "6. Obtain new n_estimators value\n",
    "7. Tune the learning rate and re-eval n_estimators\n",
    "\n",
    "References:\n",
    "* https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "* https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T17:58:32.035638Z",
     "start_time": "2018-12-03T17:58:31.661972Z"
    }
   },
   "source": [
    "### Pick sane model param defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:28:23.161402Z",
     "start_time": "2018-12-07T16:28:22.748647Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = xg.XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=5000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate best initial n_estimators value (i.e. number of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:37:04.886922Z",
     "start_time": "2018-12-07T16:28:31.435961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=202,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The `cv` function determined that `n_estimators = 202` is optimal.  We'll examine the model's accuracy on the Doc2Vec feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T16:39:00.240431Z",
     "start_time": "2018-12-07T16:37:26.566294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval data:  0.8676\n"
     ]
    }
   ],
   "source": [
    "xgb1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 5,\n",
    ")\n",
    "    \n",
    "preds = xgb1.predict(X_eval)\n",
    "print(\"Accuracy on eval data: \", accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The baseline accuracy in section 9 of this write-up was 0.8556.  We've clearly made improvements with a new best accuracy value of 0.8676 against the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune max_depth and min_child_weight\n",
    "\n",
    "Start by writing two helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T17:56:56.756386Z",
     "start_time": "2018-12-07T17:56:56.401443Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModel():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=202,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T17:57:35.040180Z",
     "start_time": "2018-12-07T17:57:34.704288Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalXGB(model, silent = True, early_stopping_rounds = 25):\n",
    "    start = timer()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = early_stopping_rounds,\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_eval)\n",
    "    acc = accuracy_score(y_eval, preds)\n",
    "    \n",
    "    end = timer()\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"    Model training finished in\", round((end-start)/60, 2), \"mins with accuracy\", acc)\n",
    "            \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Perform the hyperparameter tuning grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T18:46:17.537962Z",
     "start_time": "2018-12-07T17:57:35.042185Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for max_depth in np.linspace(2, 10, 5):\n",
    "    for min_child_weight in np.linspace(2, 8, 4):\n",
    "        xgb1 = getXGBModel()\n",
    "        xgb1.set_params(max_depth = int(max_depth), min_child_weight = int(min_child_weight))\n",
    "        acc = evalXGB(xgb1)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T18:47:04.754573Z",
     "start_time": "2018-12-07T18:47:04.382923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8748</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8732</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 2, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8724</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 4, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8720</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 6, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8720</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 4, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "19  0.8748     \n",
       "12  0.8732     \n",
       "17  0.8724     \n",
       "18  0.8720     \n",
       "9   0.8720     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   Params  \n",
       "19  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "12  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 2, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "17  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 4, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "18  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 6, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "9   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 4, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tune \n",
    "\n",
    "Best parameter value for `max_depth` was 10, and the best parameter value for `min_child_weight` was 8.  The accuracy rate for this combination was 0.8748 against the evaluation data set.  \n",
    "\n",
    "Next we'll fine tune since the initial grid was wide (increased in steps of 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T19:15:40.423183Z",
     "start_time": "2018-12-07T18:47:20.945381Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8748</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8724</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8720</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 7, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 9, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8700</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 9, 'min_child_weight': 9, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "4  0.8748     \n",
       "7  0.8724     \n",
       "6  0.8720     \n",
       "8  0.8712     \n",
       "2  0.8700     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                  Params  \n",
       "4  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "7  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 8, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "6  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 7, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "8  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 9, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 9, 'min_child_weight': 9, 'missing': None, 'n_estimators': 202, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for max_depth in [9, 10, 11]:\n",
    "    for min_child_weight in [7, 8, 9]:\n",
    "        xgb1 = getXGBModel()\n",
    "        xgb1.set_params(max_depth = int(max_depth), min_child_weight = int(min_child_weight))\n",
    "        acc = evalXGB(xgb1)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "There was no change, so we'll keep the original values for `max_depth` and `min_child_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune gamma, subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma tuning\n",
    "\n",
    "From my research there wasn't a clear consensus on a good, initial value for gamma tuning.  As such we'll start with a wide range and then zero in on the best value for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results--not shown here--for the following gamma values had no effect on the model's performance:\n",
    "\n",
    "* [.1, .5, 1, 5]\n",
    "* [10, 15, 20]\n",
    "* [.01, .001, .0001]\n",
    "\n",
    "As such the gamma value of zero will be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T21:35:06.309933Z",
     "start_time": "2018-12-03T21:35:05.989563Z"
    }
   },
   "source": [
    "### Calculate optimal n_estimators value\n",
    "\n",
    "Let's go ahead and update--if required--the optimal n_estimators value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T19:53:14.355176Z",
     "start_time": "2018-12-07T19:22:50.274678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=8, missing=None, n_estimators=630,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = getXGBModelv2()\n",
    "xgb1.set_params(gamma = 0, n_estimators=5000)\n",
    "\n",
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n_estimators value has changed to 630."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  subsample and colsample_bytree tuning\n",
    "\n",
    "* subsample [default=1]\n",
    "  * Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
    "  * Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "  * Typical values: 0.5-1\n",
    "\n",
    "\n",
    "* colsample_bytree [default=1]\n",
    "  * Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
    "  * Typical values: 0.5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T20:53:28.446966Z",
     "start_time": "2018-12-07T20:53:28.050917Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv3():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=8, missing=None, n_estimators=630,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T22:27:23.736732Z",
     "start_time": "2018-12-07T20:54:04.159878Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8784</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8764</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8760</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8760</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8760</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.9}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "1   0.8784     \n",
       "14  0.8764     \n",
       "10  0.8760     \n",
       "7   0.8760     \n",
       "20  0.8760     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   Params  \n",
       "1   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  \n",
       "14  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}  \n",
       "10  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}  \n",
       "7   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.6}  \n",
       "20  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.9}  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for subsample in np.linspace(0.5, 0.9, 5):\n",
    "    for colsample_bytree in np.linspace(0.5, 0.9, 5):\n",
    "        xgb1 = getXGBModelv3()\n",
    "        xgb1.set_params(subsample = subsample, colsample_bytree = colsample_bytree)\n",
    "        acc = evalXGB(xgb1)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Best parameter value for `subsample` was 0.5, and the best parameter value for `colsample_bytree` was 0.6.  The accuracy rate for this combination went up slightly from 0.8748 to 0.8784."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune regularization params, reg_alpha and reg_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reg_lambda [default=1]\n",
    "  * L2 regularization term on weights (analogous to Ridge regression)\n",
    "  * This used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, it should be explored to reduce overfitting.\n",
    "\n",
    "\n",
    "* reg_alpha [default=0]\n",
    "  * L1 regularization term on weight (analogous to Lasso regression)\n",
    "  * Can be used in case of very high dimensionality so that the algorithm runs faster when implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:16:13.639153Z",
     "start_time": "2018-12-07T23:16:13.295239Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv4():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=8, missing=None, n_estimators=630,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:18:40.065915Z",
     "start_time": "2018-12-07T23:16:35.118579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8784</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8784</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8764</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.5, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8756</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8756</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.001, 'reg_lambda': 2, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "10  0.8784     \n",
       "11  0.8784     \n",
       "6   0.8764     \n",
       "1   0.8756     \n",
       "22  0.8756     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                          Params  \n",
       "10  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}         \n",
       "11  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}    \n",
       "6   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.5, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  \n",
       "1   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  \n",
       "22  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 630, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.001, 'reg_lambda': 2, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}     "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for reg_lambda in [0.1, 0.5, 1, 1.5, 2]:\n",
    "    for reg_alpha in [0, 0.0001, 0.001, 0.1, 1]:\n",
    "        xgb1 = getXGBModelv4()\n",
    "        xgb1.set_params(reg_lambda = reg_lambda, reg_alpha = reg_alpha)\n",
    "        acc = evalXGB(xgb1)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "There was no improvement in accuracy against the validation set after tuning the regularization parameters, so we'll keep the existing regularization default parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain new n_estimators value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T15:28:27.491604Z",
     "start_time": "2018-12-10T15:17:32.457153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=8, missing=None, n_estimators=377,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = getXGBModelv4()\n",
    "xgb1.set_params(n_estimators=5000)\n",
    "\n",
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal `n_estimators` value has changed to 377."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the learning rate and re-eval n_estimators\n",
    "\n",
    "Next we'll examine tuning the learning rate.  As in previous cells we'll start with a wide spread of potential best values, and then narrow down if it appears we've found a effective new parameter value that differs from the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T15:49:02.348410Z",
     "start_time": "2018-12-10T15:49:02.013361Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv5():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=8, missing=None, n_estimators=377,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T15:52:11.372559Z",
     "start_time": "2018-12-10T15:49:15.209648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8508</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.5, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8504</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.001, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7920</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 1.5, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7708</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "1  0.8508     \n",
       "0  0.8504     \n",
       "2  0.7920     \n",
       "3  0.7708     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                    Params  \n",
       "1  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.5, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}    \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.001, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 1.5, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}    \n",
       "3  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}      "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for learning_rate in [0.001, .5, 1.5, 3]:\n",
    "    xgb1 = getXGBModelv5()\n",
    "    xgb1.set_params(learning_rate = learning_rate)\n",
    "    acc = evalXGB(xgb1)\n",
    "\n",
    "    resultsDF.loc[len(resultsDF)] = list([\n",
    "        acc,\n",
    "        xgb1.get_params()\n",
    "    ])\n",
    "\n",
    "    counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "No improvement at all.  We'll try one more time with small steps around the default learning rate of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T16:19:11.481209Z",
     "start_time": "2018-12-10T16:09:21.580614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.09, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8672</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.3, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8660</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.2, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8656</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.08, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "1  0.8712     \n",
       "3  0.8672     \n",
       "2  0.8660     \n",
       "0  0.8656     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   Params  \n",
       "1  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.09, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  \n",
       "3  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.3, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}   \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.2, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}   \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.08, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 377, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.5}  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for learning_rate in [.08, .09, .2, .3]:\n",
    "    xgb1 = getXGBModelv5()\n",
    "    xgb1.set_params(learning_rate = learning_rate)\n",
    "    acc = evalXGB(xgb1)\n",
    "\n",
    "    resultsDF.loc[len(resultsDF)] = list([\n",
    "        acc,\n",
    "        xgb1.get_params()\n",
    "    ])\n",
    "\n",
    "    counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Again no improvement, so we'll continue to utilize the default learning rate of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set predictions and Kaggle score\n",
    "\n",
    "Let's go ahead and train the models on the entire training set, make predictions against the test set, and see what our Kaggle score is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T19:08:18.411001Z",
     "start_time": "2018-12-10T19:04:42.414737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=8, missing=None, n_estimators=377,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We've already trained the two Doc2Vec models on the training data\n",
    "# They are assigned to variables m1 and m2\n",
    "\n",
    "# Fit the XGBoost model to the entire training set\n",
    "xgbModel = getXGBModelv5()\n",
    "xgbModel.fit(featureSet, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T19:16:05.679295Z",
     "start_time": "2018-12-10T19:10:59.088058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0f3a79030c40b5a2234fef09870164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "['naturally', 'film', 'main', 'theme', 'mortality', 'nostalgia', 'loss', 'innocence', '-PRON-', 'perhaps', 'surprising', '-PRON-', 'rat', 'highly', 'old', 'viewer', 'young', 'one', 'however', 'craftsmanship', 'completeness', 'film', 'anyone', 'enjoy', 'pace', 'steady', 'constant', 'character', 'full', 'engage', 'relationship', 'interaction', 'natural', 'showing', '-PRON-', 'need', 'flood', 'tear', 'show', 'emotion', 'scream', 'show', 'fear', 'shout', 'show', 'dispute', 'violence', 'show', 'anger', 'naturally', 'joyce', 'short', 'story', 'lend', 'film', 'ready', 'make', 'structure', 'perfect', 'polished', 'diamond', 'small', 'change', 'huston', 'make', 'inclusion', 'poem', 'fit', 'neatly', '-PRON-', 'truly', 'masterpiece', 'tact', 'subtlety', 'overwhelming', 'beauty']\n"
     ]
    }
   ],
   "source": [
    "# Process and clean the test data set\n",
    "cleanTest = []\n",
    "\n",
    "for review in tqdm(combinedDat.iloc[75000:,1]):\n",
    "    cleanTest.append(cleanReview(review, True, True))\n",
    "    \n",
    "print(len(cleanTest))\n",
    "print(cleanTest[0])\n",
    "\n",
    "pickle.dump( \"cleanedDocsTestOnly.p\", open(docsFileName, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T19:30:54.813551Z",
     "start_time": "2018-12-10T19:28:45.045012Z"
    }
   },
   "outputs": [],
   "source": [
    "testVecs = []\n",
    "\n",
    "for i in cleanTest:\n",
    "    inf1 = m1.infer_vector(i)\n",
    "    inf2 = m2.infer_vector(i)\n",
    "    testVecs.append(np.hstack((inf1, inf2)))\n",
    "    \n",
    "pickle.dump( \"inferedVectorsTestOnly.p\", open(docsFileName, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T20:55:28.711757Z",
     "start_time": "2018-12-10T20:55:26.469829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment\n",
      "id                   \n",
      "\"12311_10\"  1        \n",
      "\"8348_2\"    0        \n",
      "\"5828_4\"    0        \n",
      "\"7186_2\"    0        \n",
      "\"12128_7\"   1        \n"
     ]
    }
   ],
   "source": [
    "preds = xgbModel.predict(testVecs)\n",
    "\n",
    "df_results = pd.DataFrame({'id': combinedDat.iloc[75000:, 0], 'sentiment': preds}).set_index('id')\n",
    "print(df_results.head())\n",
    "\n",
    "# create a submission csv file\n",
    "df_results.to_csv('kaggle_submission_xgb.csv', quoting = csv.QUOTE_NONE) \n",
    "# XGBoost v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T20:53:29.392611Z",
     "start_time": "2018-12-10T20:53:29.000573Z"
    }
   },
   "source": [
    "Kaggle score:  0.83628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation on the entire dataset\n",
    "\n",
    "The final question is if utilizing the entire data set (labeled and unlabeled data) for training the Doc2Vec models will help or hinder.  We'll explore that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best Doc2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:44:47.570186Z",
     "start_time": "2018-12-04T23:33:11.401634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n",
      "(100000, 100)\n",
      "(100000, 500)\n",
      "(25000, 600)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=0, dm_concat=1, dm_mean=1, size=100, window=7, negative=5,  hs=0, min_count=2, vector_size=100, workers=cores)\n",
    "m2 = Doc2Vec(dm=1, dm_concat=0, dm_mean=1, size=500, window=3, negative=11, hs=0, min_count=3, vector_size=300, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m1.build_vocab(taggedDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "# Train each model on the labeled training data\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(m1.docvecs.doctag_syn0.shape)\n",
    "print(m2.docvecs.doctag_syn0.shape)\n",
    "\n",
    "featureSet = np.hstack((m1.docvecs.doctag_syn0[:25000], m2.docvecs.doctag_syn0[:25000]))\n",
    "print(featureSet.shape)\n",
    "\n",
    "y = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    featureSet,  \n",
    "    y, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = y \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:47:12.116627Z",
     "start_time": "2018-12-04T23:44:47.571189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = getXGBModelv5()\n",
    "\n",
    "xgb1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:47:12.480596Z",
     "start_time": "2018-12-04T23:47:12.117630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval data:  0.8824\n"
     ]
    }
   ],
   "source": [
    "preds = xgb1.predict(X_eval)\n",
    "print(\"Accuracy on eval data: \", accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that utilizing the whole set of reviews seems to actually drop performance.  Thus our best model to date is an ensemble from the PV-DBOW and PV-DM Dov2Vec models fed into a XGBoost implementation with an evaluation data set accuracy of 0.8948.  The hyper parameters for the entities are as follows:\n",
    "\n",
    "* Distributed bag of words (PV-DBOW) (i.e. dm-0)\n",
    "  * {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100}\n",
    "\n",
    "\n",
    "* Distributed memory (PV-DM) (i.e. dm=1)\n",
    "  * {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3, 'passes': 2, 'vector_size': 300}\n",
    "\n",
    "\n",
    "* XGBoost\n",
    "  * {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation on the entire dataset with stemming and contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T18:51:23.751678Z",
     "start_time": "2018-11-08T18:51:23.283886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this write-up we accomplished the following:\n",
    "\n",
    "1. Created a set of document vectors from the IMDb movie review text utilizing [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "2. Tuned and trained a number of Doc2Vec models on the movie review corpus \n",
    "2. Ran the models from the [first write-up](./Model-06.ipynb) against the Doc2Vec feature set outputs\n",
    "3. Evaluated if utilizing Doc2Vec improved our ability to correctly classify movie review sentiment\n",
    "\n",
    "\n",
    "Performance metrics so far:\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|--------------------------|--------|-----------------------------------|\n",
    "|LR (baseline)             |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid              |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec               |84.48%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec Init tuning   |88.45%  |dm0, vs100, ng5, hs0, mc2, sm0, e20|\n",
    "|LR manual/combined        |89.51%  |model1, model2, model3             |\n",
    "<div style=\"clear:both\"></div>\n",
    "\n",
    "\n",
    "Utilizing Doc2Vec with manual training and combining model outputs has given us the best classification results to date.  We were able to gain over 3 percentage points in performance from the LR baseline model.\n",
    "\n",
    "If we were to continue this write-up it would be interesting to explore adding many models together and seeing how that affected the output  similar to bagging.  We could also likely spend a lot of time with further tuning, because both the Doc2Vec and Scikit-learn models have a large number of tunable parameters we could leverage.  The best strategy would likely be to start with a randomized grid search due to the large number of parameters, and then focus in on a more narrow set once the more performant combinations started to emerge.\n",
    "\n",
    "And lastly, I'd also like to try taking the combined model feature set and feeding it to a neural network or LSTM for final classification.  It would be interesting to see how one of these more complex algorithms compared against the Scikit-learn linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
