{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Boston-Housing-Prices-Regression-Modeling-with-Keras\" data-toc-modified-id=\"Boston-Housing-Prices-Regression-Modeling-with-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Boston Housing Prices Regression Modeling with Keras</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Load-libraries-and-data\" data-toc-modified-id=\"Load-libraries-and-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load libraries and data</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Inspect-and-visualize-the-data\" data-toc-modified-id=\"Inspect-and-visualize-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inspect and visualize the data</a></span></li><li><span><a href=\"#Model-the-data\" data-toc-modified-id=\"Model-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-validation-data-set\" data-toc-modified-id=\"Create-validation-data-set-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Create validation data set</a></span></li><li><span><a href=\"#Build-models\" data-toc-modified-id=\"Build-models-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Build models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-model-function\" data-toc-modified-id=\"Build-model-function-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Build model function</a></span></li><li><span><a href=\"#Initial-pass\" data-toc-modified-id=\"Initial-pass-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Initial pass</a></span></li><li><span><a href=\"#Grid-search-hyperparameter-tuning\" data-toc-modified-id=\"Grid-search-hyperparameter-tuning-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Grid search hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optimizers\" data-toc-modified-id=\"Optimizers-6.2.3.1\"><span class=\"toc-item-num\">6.2.3.1&nbsp;&nbsp;</span>Optimizers</a></span></li><li><span><a href=\"#Epochs-and-Batch-Size\" data-toc-modified-id=\"Epochs-and-Batch-Size-6.2.3.2\"><span class=\"toc-item-num\">6.2.3.2&nbsp;&nbsp;</span>Epochs and Batch Size</a></span></li><li><span><a href=\"#Learning-rate\" data-toc-modified-id=\"Learning-rate-6.2.3.3\"><span class=\"toc-item-num\">6.2.3.3&nbsp;&nbsp;</span>Learning rate</a></span></li><li><span><a href=\"#Decay\" data-toc-modified-id=\"Decay-6.2.3.4\"><span class=\"toc-item-num\">6.2.3.4&nbsp;&nbsp;</span>Decay</a></span></li><li><span><a href=\"#Epsilon\" data-toc-modified-id=\"Epsilon-6.2.3.5\"><span class=\"toc-item-num\">6.2.3.5&nbsp;&nbsp;</span>Epsilon</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-6.2.3.6\"><span class=\"toc-item-num\">6.2.3.6&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Predictions\" data-toc-modified-id=\"Predictions-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Predictions</a></span></li></ul></li></ul></li><li><span><a href=\"#Final-comments\" data-toc-modified-id=\"Final-comments-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Final comments</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Boston Housing Prices Regression Modeling with Keras</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 40%; height: 40%; \" src=\"images/boston.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to build upon the [first](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) write-up involving the Boston housing prices dataset.  \n",
    "\n",
    "Goals include:\n",
    "* Build a predictive regression model via neural networks\n",
    "* Utilize GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source:  [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to build upon the [first](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb) write-up involving the Boston housing prices dataset.  \n",
    "\n",
    "Goals include:\n",
    "* Build a predictive regression model via neural networks\n",
    "* Utilize GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = os.path.join(\".\", \"datasets\", \"housing.csv\")\n",
    "data = read_csv(dataFile, header = 0, delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrTableColors(value):\n",
    "    color = 'black'\n",
    "\n",
    "    if value == 1:\n",
    "        color = 'white'\n",
    "    elif value < -0.7:\n",
    "        color = 'red'\n",
    "    elif value > 0.7:\n",
    "        color = 'green'\n",
    "\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRange(start, stop, step, multi, dec):\n",
    "    vals = []\n",
    "    for i in range(start, stop, step):\n",
    "        vals.append(np.round(multi * i, decimals = dec))\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect and visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please the [first Boston housing data's write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb#Inspect-and-visualize-the-data) details on this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (506, 13)\n",
      "y.shape =  (506,)\n",
      "--------\n",
      "xTrain.shape =  (404, 13)\n",
      "yTrain.shape =  (404,)\n",
      "xVal.shape =  (102, 13)\n",
      "yVal.shape =  (102,)\n"
     ]
    }
   ],
   "source": [
    "# Seperate X and Y values\n",
    "x = data.values[:, 0:len(data.columns) - 1]\n",
    "y = data.values[:, len(data.columns) - 1]\n",
    "\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"y.shape = \", y.shape)\n",
    "\n",
    "# Split out validation set -- 80/20 split\n",
    "seed = 10\n",
    "valSize = 0.2\n",
    "\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, y, test_size = valSize, random_state = seed)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"xTrain.shape = \", xTrain.shape)\n",
    "print(\"yTrain.shape = \", yTrain.shape)\n",
    "print(\"xVal.shape = \", xVal.shape)\n",
    "print(\"yVal.shape = \", yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on the `kernal_initializer`:  https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    opt = None\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "    # bias_initializer -> 'zeros' (default per the docs)\n",
    "    \n",
    "    model.add(Dense(20, input_dim = xTrain.shape[1], kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    if optimizer.lower() == 'adam':\n",
    "        opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "    else:\n",
    "        # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "        # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "        opt = eval(optimizer)()\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first pass an educated guess is taken for what might work well on the dataset.  This provides an initial baseline, and then hyperparameter tuning an occur to refine the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -18.20 (7.33)\n"
     ]
    }
   ],
   "source": [
    "# Define vars and init\n",
    "folds = 10\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn = buildModel, epochs = 200, batch_size = 5, verbose = 0)\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "results = cross_val_score(model, xTrain, yTrain, cv = kFold)\n",
    "\n",
    "print(\"MSE: %.2f (%.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better then what the previous write-up's models accomplished with no tuning as of yet:\n",
    "\n",
    "<pre>\n",
    "         Model    MSE  StdDev\n",
    "3    scaledKNN -20.35   11.87\n",
    "0     scaledLR -21.26    7.11\n",
    "4   scaledCART -22.66    9.31\n",
    "1  scaledLASSO -26.94   10.38\n",
    "5    scaledSVR -28.52   13.98\n",
    "2     scaledEN -28.60   11.65\n",
    "</pre>\n",
    "\n",
    "It does not; however, compare to the results achieved via the ensemble methods:\n",
    "\n",
    "<pre>\n",
    "       Model     MSE  StdDev\n",
    "1  scaledGBM -9.700   5.342 \n",
    "3  scaledET  -10.339  5.399 \n",
    "2  scaledRF  -13.695  7.276 \n",
    "0  scaledAB  -14.176  8.917\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll be using grid search to perform hyperparameter tuning.  We'll consider looking at hyperparameters such as:\n",
    "\n",
    "* Epochs\n",
    "* Batch size\n",
    "* Optimization algorithm\n",
    "* Learning rate\n",
    "* Decay\n",
    "* Epsilon\n",
    "\n",
    "For a production quality model we'd want to test each of the hyperparameters above in combination with the others to find an optimal combination. We'd likely perform the initial search using a randomized parameter optimization procedure.   The results from that initial tuning effort would lead the way to a set of smaller, and smaller grids that would narrow in on whatever parameter permutations showed the most promise. \n",
    "\n",
    "You can see an example of this type of process I worked on previously [here](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/03-ComputerVision-Classification/Classification-03.ipynb).\n",
    "\n",
    "The tuning process could possibly take hours, days, or even weeks depending on the data and model. For the purpose of this write-up; however, we'll consider the hyperparameter options above singly or perhaps in pairs over a small range. This will allow us to observe how each hyperparameter influences the fit of the model, and yet still be able to run this in a reasonable amount of time (i.e. minutes, not hours). \n",
    "\n",
    "We're going to start by importing a function written in a previous write-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneModel(modelName, modelObj, params, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "    \n",
    "    np.random.seed(featureSeed)\n",
    "    \n",
    "    # Use MSE since this is a regression problem\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'Accuracy', 'Best Params'])\n",
    "\n",
    "    # Create feature union\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = GridSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_grid = params,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed)      \n",
    "    ).fit(xTrain, yTrain)\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to ensure everything works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-12.91</td>\n",
       "      <td>{'housingModel__batch_size': 5, 'housingModel__epochs': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                   Best Params\n",
       "0  housingModel -12.91     {'housingModel__batch_size': 5, 'housingModel__epochs': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : [ 200 ],\n",
    "    'housingModel__batch_size' : [ 5 ],\n",
    "}\n",
    "\n",
    "m = tuneModel(modelName, modelObj, params, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be a reasonable outcome considering that the mean of the various features differed quiet a bit.  The `StandardScaler` clearly improved the model's performance.  We can now engage in further tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers\n",
    "\n",
    "The following link provides more information on available optimizers and options for each:  https://keras.io/optimizers/\n",
    "\n",
    "We'll try Adam and SGD for a set number of epochs, and depending on which provides the best fit we'll likely be able to examine some additional optimizer specific options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-15.33</td>\n",
       "      <td>{'housingModel__epochs': 200, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                       Best Params\n",
       "0  housingModel -15.33     {'housingModel__epochs': 200, 'housingModel__optimizer': 'Adam'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify buildModel() signature:\n",
    "# def buildModel(optimizer = 'adam'):\n",
    "\n",
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : [200],\n",
    "    'housingModel__optimizer' : ['SGD', 'Adam']\n",
    "}\n",
    "\n",
    "m = tuneModel(modelName, modelObj, params, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy appears to be worse than the sanity check, but this is because we removed the `batch_size` parameter from the model.  This makes sense of course, because by definition SGD has a batch size of one.  Since Adam outperformed the SGD we can look for an optimal `batch_size` value next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs and Batch Size\n",
    "\n",
    "We'll combine epochs and batch size, since the number of training iterations may have some synergy with the number of training dataset items the model is exposed to at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>{'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                                                       Best Params\n",
       "0  housingModel -13.0      {'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__optimizer': 'Adam'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : makeRange(100, 500, 100, 1, 1),\n",
    "    'housingModel__batch_size' : [4, 16, 32],\n",
    "    'housingModel__optimizer' : ['Adam']\n",
    "}\n",
    "\n",
    "tuneModel(modelName, modelObj, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "\n",
    "We can examine the estimator defaults to give us an idea of what sort of range to test the learning rate over.  According to [this](https://keras.io/optimizers/) link Adam has the following defaults:\n",
    "\n",
    "```python\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "```\n",
    "\n",
    "As such we'll start with the default learning rate of 0.001 and move towards 0.005.  We'll also need to change the `buildModel()` function's signature to accept the additional `lr` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>{'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                                                                                  Best Params\n",
       "0  housingModel -12.8      {'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify buildModel() signature:\n",
    "# def buildModel(optimizer = 'adam', lr = 0.001):\n",
    "\n",
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : [300],\n",
    "    'housingModel__batch_size' : [32],\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__lr' : makeRange(1, 6, 1, .001, 3),\n",
    "}\n",
    "\n",
    "tuneModel(modelName, modelObj, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So some progress, but nothing earthshattering which is perhaps to be expected since we're not tuning the parameters together as a composite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-13.17</td>\n",
       "      <td>{'housingModel__batch_size': 32, 'housingModel__decay': 0.0001, 'housingModel__epochs': 300, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                                                                                                                 Best Params\n",
       "0  housingModel -13.17     {'housingModel__batch_size': 32, 'housingModel__decay': 0.0001, 'housingModel__epochs': 300, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify buildModel() signature:\n",
    "# def buildModel(optimizer = 'adam', lr = 0.001):\n",
    "\n",
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : [300],\n",
    "    'housingModel__batch_size' : [32],\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__lr' : [0.003],\n",
    "    'housingModel__decay' : [0.0001, 0.00001, 0.000001],\n",
    "}\n",
    "\n",
    "tuneModel(modelName, modelObj, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that letting Adam take care of the decay rate is probably the best option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housingModel</td>\n",
       "      <td>-12.84</td>\n",
       "      <td>{'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__epsilon': 1.0, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy                                                                                                                                                Best Params\n",
       "0  housingModel -12.84     {'housingModel__batch_size': 32, 'housingModel__epochs': 300, 'housingModel__epsilon': 1.0, 'housingModel__lr': 0.003, 'housingModel__optimizer': 'Adam'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify buildModel() signature:\n",
    "# def buildModel(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "\n",
    "modelName = \"housingModel\"\n",
    "modelObj =  KerasRegressor(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'housingModel__epochs' : [300],\n",
    "    'housingModel__batch_size' : [32],\n",
    "    'housingModel__optimizer' : ['Adam'],\n",
    "    'housingModel__lr' : [0.003],\n",
    "    'housingModel__epsilon' : makeRange(2, 8, 1, .5, 1),\n",
    "}\n",
    "\n",
    "m = tuneModel(modelName, modelObj, params, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have some improvement with the `epsilon` value set to 1.0.  This also matches with the findings in various literature and postings on-line I reviewed when considering what range to experiment with for this write-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "Again, if we were creating a production quality model we would have started with randomized parameter optimization process.  The results from that process would then lead to a set of smaller grids focusing more and more on whatever parameter option permutations showed the most promise.\n",
    "\n",
    "You can see an example of this type of process I worked on previously [here](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/03-ComputerVision-Classification/Classification-03.ipynb).\n",
    "\n",
    "Also, unless the randomized parameter optimization process were to lead to signifigant improvements from what we've seen so far we'd be better of utilizing the gradient boosting algorithm we utilized in [previous write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb#Initial-pass---Ensemble-methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Hopefully to same some one else some pain down the road:\n",
    "\n",
    "I kept getting the following error when working on this prediction section, which frankly was driving me nuts:\n",
    "    \n",
    "```\n",
    "TypeError: call() missing 1 required positional argument: 'inputs'\n",
    "```\n",
    "\n",
    "After researching the error message I came upon this comment which let me to the resolution:\n",
    "\n",
    "_The thing here is that KerasRegressor expects a callable that builds a model, rather than the model itself. By wrapping your function in this way you can return the build function (without calling it)._  [Source](https://stackoverflow.com/questions/47944463/specify-input-argument-with-kerasregressor)\n",
    "\n",
    "Solution:  I needed to **wrap** the `buildModel()` function!  :(\n",
    "\n",
    "Once I 'wrapped' the `buildModel()` function the prediction code blocks finally started working, and that's why we have the `wrapper()` function implemented below...\n",
    "\n",
    "**END NOTE**\n",
    "\n",
    "And now that that's out of the way we'll take a look at some predictions using the test data set based on the tuning results from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See NOTE above on why we have this new function\n",
    "def wrapper(optimizer = 'Adam', lr = 0.001, decay = 0.0, epsilon = None):\n",
    "    \n",
    "    def buildModel():\n",
    "        opt = None\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # kernel_initializer='normal' -> Initializer capable of adapting its scale to the shape of weights\n",
    "        # bias_initializer -> 'zeros' (default per the docs)\n",
    "\n",
    "        model.add(Dense(20, input_dim = xTrain.shape[1], kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(10, kernel_initializer='normal', activation = 'relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "        if optimizer.lower() == 'adam':\n",
    "            opt = Adam(lr = lr, decay = decay, epsilon = epsilon)\n",
    "        else:\n",
    "            # Please don't ever use eval where you're recieving input from non-trusted sources!\n",
    "            # A Jupyter notebook is OK; a public facing service is certainly not\n",
    "            opt = eval(optimizer)()\n",
    "\n",
    "        model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "\n",
    "        return model\n",
    "\n",
    "    return buildModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  11.93922294223878\n",
      "RMSE =  3.4553180667253747\n"
     ]
    }
   ],
   "source": [
    "# Build the model, and pass the KerasRegressor a callable function to the 'build_fn' argument\n",
    "# Use the parameters we found were most effective during the hyperparameter tuning\n",
    "m =  KerasRegressor(\n",
    "    build_fn = wrapper(optimizer = 'Adam', lr = 0.003, epsilon = 1), \n",
    "    epochs = 300, \n",
    "    batch_size = 32, \n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Now fit the model to the training data ensuring we perform the same sort of pipeline transformations\n",
    "# that occured during the hyperparameter tuning (i.e. feature scaling)\n",
    "xScaled = StandardScaler().fit(xTrain).transform(xTrain)\n",
    "m.fit(xScaled, yTrain)\n",
    "\n",
    "# Now we can finally make some predictions using our trained model on unseen data\n",
    "xScaled = StandardScaler().fit(xTrain).transform(xVal)\n",
    "preds = m.predict(xScaled)\n",
    "mse = mean_squared_error(yVal, preds)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(\"MSE = \", mse)\n",
    "print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comments\n",
    "\n",
    "We have some improvement over the [first write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.ipynb), but nothing orders of magnitude earth shattering.  In fact we could likely explain away the difference as a statistical blip.  In the [next write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-02.Keras.2.ipynb) we'll see what kind of results we can achieve using RandomizedSearchCV.  \n",
    "\n",
    "The results so far for reference:\n",
    "\n",
    "|Model     |Write-up              |Prediction MSE|\n",
    "|----------|------------------------|--------------|\n",
    "|GB        | Model-02.Keras         | 12.24        |\n",
    "|Neural Net| Model-02.Keras.1.ipynb | 11.94        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
