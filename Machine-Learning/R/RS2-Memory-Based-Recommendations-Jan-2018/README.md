# Table of Contents

* [Table of Contents](#table-of-contents)
* [Introduction](#introduction)
* [Data Review](#data-review)
* [Methodology](#methodology)
* [Implementation](#implementation)
  * [Exploring a Sample Data Set](#exploring-a-sample-data-set)
	 * [Euclidean Space](#euclidean-space)
	 * [Binary Matrix](#binary-matrix)
	 * [Predict Recommendations](#predict-recommendations)
  * [Functionize It!](#functionize-it)
	 * [toBinary](#tobinary)
	 * [userMovieInfo](#usermovieinfo)
	 * [similarUsers](#similarusers)
	 * [recommendationScore](#recommendationscore)
  * [MovieLens Application](#movielens-application)
* [Summary](#summary)

# Introduction

In our [last write-up](../RS1-Content-Based-Recommendations-Dec-2017) we explored building a content-based recommendation system.  We took ratings the user had already given to us to make recommendations for new movies they might enjoy.

In this write-up we'll again explore creating a recommendation system, but this time we'll implement a user-based collaborative filtering system.  

> User-based [collaborative filtering] (CF) (Goldberg et al. 1992; Resnick, Iacovou, Suchak, Bergstrom, and Riedl 1994; Shardanand and Maes 1995) is a memory-based algorithm which tries to mimics word-of-mouth by analyzing rating data from many individuals. The assumption is that users with similar preferences will rate items similarly. Thus missing ratings for a user can be predicted by first finding a neighborhood of similar users and then aggregate the ratings of these users to form a prediction.  (https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf)

We'll also continue to utilize the [MovieLens dataset](https://grouplens.org/datasets/movielens/) for developing the system, and you can also find an annotated, full copy of the R script used in this write-up [here](./fullScript.R).

# Data Review

Before we begin let's setup our R environment and take a look at the data.

```R
# Clean up our environment
rm(list=ls(all=TRUE))

# Set seed so our results can be reproduced
set.seed(10)

# Load R libraries
library(ggplot2)

# Load the processed MovieLens dataset
# Assumes we have access to and can load the processed data files from the previous write-up
# (../Machine-Learning-and-AI/R/RS1-Content-Based-Recommendations-Dec-2017)
setwd("SOME_PATH_ON_YOUR_SYSTEM")
movies = read.csv("./data/movies.csv")
genreMatrix = as.matrix(read.table("./data/genreMatrix.txt", as.is = TRUE))
userMatrix = as.matrix(read.table("./data/userMatrix.txt", as.is = TRUE))
colnames(userMatrix) = seq(1, dim(userMatrix)[2], 1)
```

How dense is the dataset?

```R
image(userMatrix, col=topo.colors(12), main="Ratings Matrix Density")
```

![RATINGS-MATRIX-DENSITY](./images/RATINGS-MATRIX-DENSITY.png)

In the image above areas in dark blue indicate no ratings for a particular movie have been given by a user.  The dataset is clearly sparsely populated which will make it harder on our model to predict accurate recommendations.  You can read more about sparse matrices [here](https://en.wikipedia.org/wiki/Sparse_matrix).

How are the ratings that we do have distributed over the 1-to-5 movie rating scale?

```R
qplot(
	userMatrix[userMatrix > 0], binwidth = .5, 
	main = "Ratings Distribution", xlab = "User Rating", ylab = "Count"
)
summary(userMatrix[userMatrix > 0])

#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  0.500   3.000   4.000   3.543   4.000   5.000 
```

![RATINGS-DISTRIBUTION](./images/RATINGS-DISTRIBUTION.png)

The ratings given by the users are skewed to the left, and average out to around 3.5.

Next, how are the mean ratings distributed across the movies?

```R
means = rowMeans(userMatrix, na.rm = TRUE); 
qplot(
  means, binwidth = .3, main = "Movie Rating Mean Distribution", 
  xlab = "Movie Rating Means", ylab = "Number of Movies"
)
```

![MOVIE-RATING-MEAN-DIST](./images/MOVIE-RATING-MEAN-DIST.png)

So almost 2000 movies were rated 3.5 or 4 with much fewer numbers of movies receiving a 1 or 5 rating.

And how active were the users in the dataset about rating movies?

```R
library(matrixStats)
rated = colCounts(userMatrix)
qplot(rated[rated != 0], binwidth = 10, xlab = "Number of Movies Rated", ylab = "Number of Users", main = "Number of Movies Rated by Users")
```

![NUM-MOVIES-RATED-BY-USERS](./images/NUM-MOVIES-RATED-BY-USERS.png)

The graph shows that for anything after about 50 movies using ratings taper off.  Almost 300 different users rated at least one movie, but barely any users at all rated more than 200 movies for example.


# Methodology

In order to build a user-based recommendation system we want to do the following:

* Select a particular user (which we'll refer to as U1)
* Use some method to find a neighborhood of people having similar tastes in movies to U1
* Choose a subset, K, from the neighborhood of the most similar users (or use them all potentially)
* Aggregate the K-nearest neighbors' movie ratings
* Return top N number of movies with the highest user based score that the U1 hasn't seen before

There are two popular similarity measures used when finding K-nearest neighbors in a recommendation system: the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).  In this write-up we'll utilize cosine similarity which is defined by this formula:

![COSINE-FORMULA](./images/COSINE-FORMULA.png)
Image credit:  https://en.wikipedia.org/wiki/Cosine_similarity

Let's get started!

# Implementation

## Exploring a Sample Data Set

Before we begin on the larger MovieLens data let's work through things on a sample data set we've crafted to ensure we understand what is happening, and that our process is sound. 
 
First, load up the sample data:

```R
sampleData = as.matrix(read.csv("./data/knnTesting.csv", header = TRUE, row.names = 1))
sampleData

#      m1 m2 m3 m4 m5 m6 m7 m8 m9 m10 sum
# u1   5  5  5  5  5  5  5  5  5   5  50
# u2   5  5  5  5  5  5  5  5  5   5  50
# u3   3  5  4  2  2  1  1  4  3   2  27
# u4   1  5  2  3  4  1  4  1  1   2  24
# u5   2  2  4  4  2  1  2  2  2   2  23
# u6   3  4  2  4  5  3  4  2  1   5  33
# u7   3  3  4  1  2  4  4  1  5   4  31
# u8   0  0  0  0  0  0  0  0  0   0   0
# u9   1  1  1  1  1  1  1  1  1   1  10
# u10  1  1  1  1  1  1  1  1  1   1  10
```

This gives us a data set of 10 user ratings for 10 movies.  While this data set isn't very realistic it does; however, make it easy to confirm if our process is working as we'd expect.

For example, it's clear that users 1 and 2 are similar, and likewise users 9 and 10 are also similar.  We'd also expect user 8 to be closer in similarity with users 9 and 10 rather than user 1, and users 6 and 7 should fall closer to users 1 and 2 rather than users 9 and 10.  This is also borne out by the values in the "sum" column which was added as an aid to intuition.

Now let's examine some code to verify our intuition of the sample data set: 

```R
# Load the FNN library  (https://cran.r-project.org/web/packages/FNN/)
library(FNN)

# Drop the sum column, which is present for intuition puposes only
sampleData = sampleData[,-11]

# Calculate the k-nearest neighbors for all points where k = 3
nearest = knn.index(sampleData, k=3)
nearest

#         [,1] [,2] [,3]
# [1,]    2    6    7
# [2,]    2    6    7
# [3,]    5    4    7
# [4,]    6    5    3
# [5,]    3   10    9
# [6,]    4    5    7
# [7,]    5    3    6
# [8,]    9   10    5
# [9,]    9    8    5
# [10,]   9    8    5
```

So that lines up nicely with our intuition on how things should work based on our sample data set.  User 1 is a k-nearest neighbor (KNN) with users 2, 6, and 7, while user 10 is a KNN with users 9, 8, and 5.

However, what if we didn't want to constrain ourselves to some value of K?  What if we wanted __all__ the users that were similar based on some threshold value?  In that case we could examine the cosine similarity distance calculations:

```R
# Load the coop library (https://cran.r-project.org/web/packages/coop/)
library(coop)

# Transpose sampleData, because coop wants to calculate by columns
cosine(t(sampleData))

# u1        u2        u3        u4        u5        u6        u7  u8        u9       u10
# u1  1.0000000 1.0000000 0.9050421 0.8593378 0.9312428 0.9333810 0.9221944 NaN 1.0000000 1.0000000
# u2  1.0000000 1.0000000 0.9050421 0.8593378 0.9312428 0.9333810 0.9221944 NaN 1.0000000 1.0000000
# u3  0.9050421 0.9050421 1.0000000 0.7921394 0.8821723 0.7869155 0.8077013 NaN 0.9050421 0.9050421
# u4  0.8593378 0.8593378 0.7921394 1.0000000 0.8263473 0.9215928 0.7562612 NaN 0.8593378 0.8593378
# u5  0.9312428 0.9312428 0.8821723 0.8263473 1.0000000 0.8588975 0.8190394 NaN 0.9312428 0.9312428
# u6  0.9333810 0.9333810 0.7869155 0.9215928 0.8588975 1.0000000 0.8245782 NaN 0.9333810 0.9333810
# u7  0.9221944 0.9221944 0.8077013 0.7562612 0.8190394 0.8245782 1.0000000 NaN 0.9221944 0.9221944
# u8        NaN       NaN       NaN       NaN       NaN       NaN       NaN   1       NaN       NaN
# u9  1.0000000 1.0000000 0.9050421 0.8593378 0.9312428 0.9333810 0.9221944 NaN 1.0000000 1.0000000
# u10 1.0000000 1.0000000 0.9050421 0.8593378 0.9312428 0.9333810 0.9221944 NaN 1.0000000 1.0000000
```

OK, this obviously isn't what we want.  According to coop's cosine similarity outputs users 1, 2, 9, and 10 would be grouped together as KNN.  Using user 9 and 10's ratings to make recommendations for user 1 isn't going to result in optimal results; it's pretty clear that user 1 has complete opposite tastes in movies from users 9 and 10.

If we reduce this to a 2 dimensional space and graph the vectors it becomes clear what is going on:

```R
plot(x=c(0,4), y=c(0,4), pch=19, col="black", cex=1.5, type="b", xlab = "X", ylab= "Y", main="Vector Graph")
points(c(0,2), c(0,2), col="red", type="b", cex=1, pch=22, bg="red")
legend("numeratorleft", legend=c("Vec 1", "Vec 2"), col=c("black", "red"), lty=1, cex=1)
```

# ![VECTOR-GRAPH](./images/VECTOR-GRAPH.png)

So the two vectors when placed on the graph in the standard position are collinear vectors (i.e. they have the same direction despite differing magnitudes).  However, as seen below, the cosine similarity function is looking for the cosine of the angle between them, which is in this case is zero.

![COSINE-GRAPH](./images/COSINE-GRAPH.png)
Image credit:  https://www.safaribooksonline.com

We can also work out the math by hand to verify using the cosine similarity formula:

![COSINE-FORMULA](./images/COSINE-FORMULA.png)
Image credit:  https://en.wikipedia.org/wiki/Cosine_similarity

```R
v1 = sampleData[1,]
v2 = sampleData[2,]
v9 = sampleData[9,]

# User 1 and user 2
numerator = sum(v1 %*% v2)
denominator = sqrt( sum(v1)^2 ) %*% sqrt( sum(v2)^2 )
numerator/denominator
# [,1]
# [1,]  0.1

# User 1 and user 9
numerator = sum(v1 %*% v9)
denominator = sqrt( sum(v1)^2 ) %*% sqrt( sum(v9)^2 )
numerator/denominator
# [,1]
# [1,]  0.1
```

To get around this we can do one of two things:  Calculate the distance between the vectors in Euclidean space, or convert sampleData to a binary matrix, and then compute the cosine similarity.

### Euclidean Space

R already has a function that will compute this for us:

```R
?dist
dist(sampleData)

# u1        u2        u3        u4        u5        u6        u7        u8        u9
# u2   0.000000                                                                                
# u3   8.306624  8.306624                                                                      
# u4   9.380832  9.380832  5.916080                                                            
# u5   9.000000  9.000000  4.472136  5.000000                                                  
# u6   6.708204  6.708204  6.928203  4.582576  6.000000                                        
# u7   7.280110  7.280110  6.324555  7.000000  6.164414  6.480741                              
# u8  15.811388 15.811388  9.433981  8.831761  7.810250 11.180340 10.630146                    
# u9  12.649111 12.649111  6.708204  6.324555  5.000000  8.306624  7.810250  3.162278          
# u10 12.649111 12.649111  6.708204  6.324555  5.000000  8.306624  7.810250  3.162278  0.000000
```

_(Note that smaller values imply a greater similarity.)_

This is much more in line with what we wanted, and would accommodate using a threshold value to filter which users we would consider similar to our target user (i.e. only consider those users where the "dist" value was 8.0 or less as "similar" for example).

### Binary Matrix

Now let's examine what happens when we utilize a binary matrix:

```R
# Convert the sampleData into a binary matrix
sampleDataBinary = sampleData

# We only want to consider ratings that were three or higher
sampleDataBinary[sampleData > 2] = 1
sampleDataBinary[sampleData <= 2] = 0
sampleDataBinary

#      m1 m2 m3 m4 m5 m6 m7 m8 m9 m10
# u1   1  1  1  1  1  1  1  1  1   1
# u2   1  1  1  1  1  1  1  1  1   1
# u3   1  1  1  0  0  0  0  1  1   0
# u4   0  1  0  1  1  0  1  0  0   0
# u5   0  0  1  1  0  0  0  0  0   0
# u6   1  1  0  1  1  1  1  0  0   1
# u7   1  1  1  0  0  1  1  0  1   1
# u8   0  0  0  0  0  0  0  0  0   0
# u9   0  0  0  0  0  0  0  0  0   0
# u10  0  0  0  0  0  0  0  0  0   0

# Let's try the coop::consine function again
coop::cosine(as.matrix(t(sampleDataBinary)))

#     u1        u2        u3        u4        u5        u6        u7        u8  u9  u10
# u1  1.0000000 1.0000000 0.7071068 0.6324555 0.4472136 0.8366600 0.8366600 NaN NaN NaN
# u2  1.0000000 1.0000000 0.7071068 0.6324555 0.4472136 0.8366600 0.8366600 NaN NaN NaN
# u3  0.7071068 0.7071068 1.0000000 0.2236068 0.3162278 0.3380617 0.6761234 NaN NaN NaN
# u4  0.6324555 0.6324555 0.2236068 1.0000000 0.3535534 0.7559289 0.3779645 NaN NaN NaN
# u5  0.4472136 0.4472136 0.3162278 0.3535534 1.0000000 0.2672612 0.2672612 NaN NaN NaN
# u6  0.8366600 0.8366600 0.3380617 0.7559289 0.2672612 1.0000000 0.7142857 NaN NaN NaN
# u7  0.8366600 0.8366600 0.6761234 0.3779645 0.2672612 0.7142857 1.0000000 NaN NaN NaN
# u8        NaN       NaN       NaN       NaN       NaN       NaN       NaN   1 NaN NaN
# u9        NaN       NaN       NaN       NaN       NaN       NaN       NaN NaN   1 NaN
# u10       NaN       NaN       NaN       NaN       NaN       NaN       NaN NaN NaN   1
```

_(Note that larger values imply a greater similarity.)_

This now lines up with the KNN and Euclidean space outputs, and also accommodates filtering by a threshold value (i.e. only consider those users where the cosine similarity value is 8.0 or greater as "similar" for example).
 
### Predict Recommendations

Let's put everything together and predict a movie recommendation based on similar users.  We'll pick user 1, and then predict if we should recommend movie 5 or not based on what other similar users rated the movie.  

_Note:  We'll utilize the "coop" package to make implementing weights easier during the process._

```R
# Calculate cosine similarity using "coop" package for user 1
dist.u1 = (coop::cosine(as.matrix(t(sampleDataBinary))))[,c("u1")]

# Remove user 1 from the results, because we don't want to compare user 1 to themselves
dist.u1 = dist.u1[names(dist.u1) != "u1"]

# Remove NaN results
dist.u1 = na.omit(dist.u1)

# Collect the names of users similar to user 1
similarUsers = names(dist.u1[dist.u1 >= 0.8])

# Define the movie's index
movieIndex = 5

# Collect the ratings that users similar to user 1 gave movie 5 
ratings = sampleData[similarUsers, movieIndex]
```

![RATING-FORMULA-1](./images/RATING-FORMULA-1.png)

```R
# Calculate a recommendation rating for movie 5 using a simple average of ratings that users similar
# to user 1 gave movie 5
ratingNonWeighted = sum(ratings)/length(ratings)
ratingNonWeighted
# [1] 4
```

The result is a 4 which is realistic based on similar users giving movie 5 a rating set of [5,5,2].  In this case we would go ahead and recommend movie 5 to user 1 based on the large predicted recommendation value.

We can also calculate the predicted recommendation rating utilizing a weighted average where the more similar a given user is to user 1 the more weight their rating receives:

```R
# Collect the cosine similarity values which will be used as weights
weights = dist.u1[dist.u1 >= 0.8]
```

![RATING-FORMULA-2](./images/RATING-FORMULA-2.png)

```R
# Calculate the recommendation rating for movie 5 using a weighted average of ratings that users 
# similar to user 1 gave movie 5
ratingWeighted = sum(weights * ratings) / sum(weights)
ratingWeighted
# [1] 4.0611
```

The result is 4.0611 which again lines up with our intuition based on observations of the sample data.
 
## Functionize It! 

Now that we feel comfortable with how things are working based on the sample data set we can develop functions to perform the work we just performed "by hand" above.  Then we can use those functions on the much larger MovieLens data.

### function toBinary

```R
# Convert a given matrix of numerical values into binary form
# Values of the matrix >= the threshold parameter are set to one, otherwise zero
toBinary = function(matrix, threshold) {
  # Convert items less than the threshold to 0
  matrix[matrix < threshold] = 0
  
  # Convert items equal or greater than the threshold to 1
  matrix[matrix >= threshold] = 1
    
  return(matrix)
}
```

### function userMovieInfo

```R
# Provides a quick summary and graph of the ratings that have been recorded for a particular movie.
# Excludes the ratings for a given user, so that the sparsity of a movie's ratings can
# be intuitively observed for similar user comparisons 
userMovieInfo = function(ratingMatrix, userColumnIndex, movieRowIndex) {
  
  m = paste("movie[", movieRowIndex, "]", sep="")
  u = paste("user[", userColumnIndex, "]", sep="")
  
  movieRatings = ratingMatrix[movieRowIndex, -userColumnIndex]
  txt = c(" There are", length(movieRatings), "possible ratings for", m, "\n")
  
  movieRatingsPopulated = movieRatings[movieRatings !=0]
  txt = c(txt, length(movieRatingsPopulated), "non-zero ratings have been recorded for", m, "\n")
  
  txt = c(txt, "   (Note that", u, "has been excluded from these counts)\n")
  txt = c(txt, "Drawing distribution graph of rating values for", m, "\n")
  
  cat(txt)
  
  qplot(movieRatingsPopulated, binwidth = 0.1, boundary = -0.05)
}

# Quick testing
userMovieInfo(userMatrix, 1, 5)
# There are 670 possible ratings for movie[5] 
# 56 non-zero ratings have been recorded for movie[5] 
# (Note that user[1] has been excluded from these counts)
# Drawing distribution graph of rating values for movie[5]
```

![userMovieInfo1](./images/userMovieInfo1.png)

```R
userMovieInfo(userMatrix, 1, 932)
# There are 670 possible ratings for movie[932] 
# 45 non-zero ratings have been recorded for movie[932] 
# (Note that user[1] has been excluded from these counts)
# Drawing distribution graph of rating values for movie[932] 
```

![userMovieInfo2](./images/userMovieInfo2.png)

### function similarUsers

```R
# Takes a given user's movie ratings and then uses cosine similarity to find other users
# who have similar movie rankings.
#
# @param ratingMatrix     A matrix with movie IDs as rows, user IDs as columns, and movie ratings as data points
# @param userIndex        The index of the user that other, similar users should be found for
# @param ratingLimit      Rating values equal to or greater than this value will count as a positive rating
# @param similarityLimit  Threshold value for determining which users are "similar" to the user in question
#
# Returns a list with three components:
# $userNames     The userIds of similar users
# $userWeights   The weights (i.e. distances) between similar users and the specified user
# $output        A narrative summarizing the results of the function's operations
similarUsers = function(ratingMatrix, userIndex, ratingLimit, similarityLimit) {
  similarUsers = list()
  u = paste("user[", userIndex, "]", sep="")
  
  txt = c(" Finding similar users for", u, "...\n")

  # Convert rating matrix to binary format (ratings >= ratingLimit = 1; else 0)
  ratingMatrixBinary = toBinary(ratingMatrix, ratingLimit)
  
  # Calculate cosine similarity using "coop" package, and pull out results for given user
  dist = coop::cosine(ratingMatrixBinary)[,userIndex]
  # Remove given user from the results, because we don't want to compare given user to themselves
  dist = dist[-userIndex]
  # Remove NaN results
  dist = na.omit(dist)
 
  # Collect the names of users similar to given user
  similarUsers$userNames = names(dist[dist >= similarityLimit])
  
  # Collect the cosine similarity values which will be used as weights
  similarUsers$userWeights = dist[dist >= similarityLimit]
  
  txt = c(txt, "The cosine similarity calculations found", length(similarUsers$userNames), "similar users for", u, "\n")
  txt = c(txt, "similar users:", similarUsers, "\n")
  txt = c(txt, "similar user weights:", round(weights, 2), "\n")
  
  similarUsers$output = txt
  
  return(similarUsers)
}

# Quick testing
test = similarUsers(userMatrix, 1, 3, 0.08)
names(test)
test$userNames
round(test$userWeights, 2)
cat(toString(test$output))

# Names:       "userNames"   "userWeights" "output"     
# $userNames:  "35"  "76"  "102" "207" "310" "325" "341" "387" "485" "510" "575" "594" "604" "634"
# $userWeights: 0.13 0.08 0.08 0.09 0.12 0.12 0.08 0.11 0.09 0.10 0.08 0.08 0.11 0.10 
# Finding similar users for, user[1], ...
# The cosine similarity calculations found, 14, similar users for, user[1], 
# Similar users:, c("35", "76", "102", "207", "310", "325", "341", "387", "485", "510", "575", "594", "604", "634"), c(0.133630620956212, 0.0811107105653813, 0.0845154254728517, 0.0883883476483184, 0.125, 0.125, 0.0811107105653813, 0.107384194896889, 0.0883883476483184, 0.098907071009368, 0.0841793787126842, 0.0845154254728517, 0.106600358177805, 0.102062072615966), 
# Similar user weights:, 1, 0.84, 0.84, 
```

### function recommendationScore

```R
# Calculates a predicted user-based recommendation score for a movie based on how 
# similar users have rated that movie
#
# @param movieRow        The row of movie ratings from the userMatrix for a specified movie
# @param similarUsers    A vector of similar user Ids
# @param weights         A vector of similar user weights (i.e. cosine similarity distances)
#
# Returns a list with two components:
# $score      The predicted recommendation rating for a particular movie based on the weighted average of similar user ratings
# $output     A narrative summarizing the results of the function's operations
recommendationScore = function(movieRow, similarUsers, weights) {
  WeightedRatingScore = list()
  
  m = paste("movie[", movieIndex, "]", sep="")
  
  # Collect the ratings that users similar to given user gave given movie
  ratings = movieRow[similarUsers]
  txt = c(" Similar user ratings:", ratings, "\n")
  
  # Calculate the predicted recommendation rating utilizing a weighted average where 
  # the more similar a given user is to given user the more weight their rating receives:
  
  # Perform the weighted rating calculation
  WeightedRatingScore$score = sum(weights * ratings) / sum(weights)
  
  txt = c(txt, "The final user-based recommendation prediction rating for", m, "is", round(WeightedRatingScore$score, digits = 2), "\n")
  
  WeightedRatingScore$output = txt
  
  return(WeightedRatingScore)
}


# Quick test 1: A movie that should score low for user 1 based on their rating history
score = recommendationScore(userMatrix[5, ], test$userNames, test$userWeights)
names(score)
score$score

# cat(toString(score$output))
# [1] "score"  "output"
# [1] 0
# Similar user ratings:, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
# , The final user-based recommendation prediction rating for, movie[5], is, 0,


# Quick test 2: A movie that should score high for user 1 based on their rating history
score = recommendationScore(userMatrix[932, ], test$userNames, test$userWeights)
names(score)
score$score
cat(toString(score$output))

# [1] "score"  "output"
# [1] 1.397736
# Similar user ratings:, 0, 0, 4, 0, 0, 2, 4, 5, 0, 5, 0, 0, 0, 0, 
# , The final user-based recommendation prediction rating for, movie[5], is, 1.4,
```

## MovieLens Application

Now let's use the functions we just wrote to pick a user and find user-based recommendations from a pool of all unrated movies for that user.  Once that's complete we'll return a top 10 list of the highest scoring items:

1. As before, compile a list of similar users
```R
simUsers = similarUsers(userMatrix, 1, 3, 0.08)
```

2. Remove any movies that the user in question has already rated
```R
userRatings = userMatrix[-(which( userMatrix[, 1] != 0 )), ]
```

3. For each movie calculate a user-based recommendation prediction rating
```R
# Prepare a data.frame to record the results
results = data.frame("movieId" = rownames(userRatings), "score" = 0)

# Loop through each movie and record predicted user-based recommendation score
for (id in 1:(nrow(results))) {
  score = recommendationScore(userMatrix[id, ], simUsers$userNames, simUsers$userWeights)
  results[id, "score"] = score$score
}

# Order the results in descending order, so we can pull the top 10
results = results[with(results, order(-score)), ]
```

4. Return the top 10 entries along with movie details
```R
recommended = movies[ which(movies$movieId %in% results[1:10, ]$movieId), ]
recommended$score = results[1:10, ]$score
recommended$title = strtrim(recommended$title, 35)
recommended

#      movieId                               title                        genres    score
# 286      319                Shallow Grave (1994)         Comedy|Drama|Thriller 1.838062
# 537      609 Homeward Bound II: Lost in San Fran            Adventure|Children 1.520299
# 628      753         Month by the Lake, A (1995)          Comedy|Drama|Romance 1.461845
# 697      861 Supercop (Police Story 3: Supercop)  Action|Comedy|Crime|Thriller 1.459531
# 937     1177              Enchanted April (1992)                 Drama|Romance 1.446037
# 983     1226               Quiet Man, The (1952)                 Drama|Romance 1.409902
# 991     1235             Harold and Maude (1971)          Comedy|Drama|Romance 1.397736
# 1066    1320     AlienÂ³ (a.k.a. Alien 3) (1992) Action|Horror|Sci-Fi|Thriller 1.360653
# 1724    2168                Dance with Me (1998)                 Drama|Romance 1.360653
# 2946    3691               Private School (1983)                        Comedy 1.348102
```

5. Examine the movies the selected user has previously rated at 3 or above
```R
  rated = row.names(userMatrix[(which( userMatrix[, 1] != 0 )), ])
  rated = movies[ which (movies$movieId %in% rated), ]
  rated$rating = userMatrix[(which( userMatrix[, 1] != 0 )), ][, 1]
  rated = rated[with(rated, order(-rating)), ]
  rated[which(rated$rating >= 3),]
  
  #      movieId                                         title                            genres rating
  # 932     1172 Cinema Paradiso (Nuovo cinema Paradiso) (1989)                            Drama    4.0
  # 1516    1953                  French Connection, The (1971)            Action|Crime|Thriller    4.0
  # 1666    2105                                    Tron (1982)          Action|Adventure|Sci-Fi    4.0
  # 1084    1339         Dracula (Bram Stoker's Dracula) (1992)  Fantasy|Horror|Romance|Thriller    3.5
  # 834     1029                                   Dumbo (1941) Animation|Children|Drama|Musical    3.0
  # 860     1061                                Sleepers (1996)                         Thriller    3.0
  # 1709    2150                 Gods Must Be Crazy, The (1980)                 Adventure|Comedy    3.0
  # 2926    3671                         Blazing Saddles (1974)                   Comedy|Western    3.0
```
  
# Summary

If we compare the user's movie ratings by genre that we know about against what the model has selected as as a recommendation things look pretty good.   The only item I'm a little dubious about is the movie "Homeward Bound II: Lost in San Francisco (1996)" due to the genre label "Children." However, it would be fascinating to have the user watch this movie and then see how they rated it.  If they liked the movie then it would strengthen the relationship between the user and the similar users the model selected, and if they didn't like it then the model could adjust the similar user weights accordingly.
  
And this brings us to one of the benefits of this model:  As the user base continues to add ratings for the various movies the model will increase in accuracy.  It will be able to "learn" more about what each user like/dislikes, and then find better and better similar user matches.  This in turn will increase the recommendation predictions the model can make for each user.
  
This will also potentially expose the user to new movies they might not have selected for themselves otherwise.  A great example is from the results we already have with the inclusion of the movie "Homeward Bound II: Lost in San Francisco (1996)."  Based on the genres that the user has rated it doesn't appear this would be a good match.  However, obviously enough users with similar tastes to our selected user did enjoy the movie, so there is definitely a chance our selected user might like it too.
