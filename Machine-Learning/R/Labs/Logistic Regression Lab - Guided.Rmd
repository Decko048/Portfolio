---
title: "R Notebook"
output: html_notebook
---

# Definitions

## Linear Combination

In mathematics, a linear combination is an expression constructed from a set of terms by multiplying each term by a constant and adding the results (e.g. a linear combination of x and y would be any expression of the form ax + by, where a and b are constants).  The concept of linear combinations is central to linear algebra and related fields of mathematics.

[Source](https://en.wikipedia.org/wiki/Linear_combination)

## Prior Probability

The prior probability of an event is the probability of the event computed before the collection of new data. One begins with a prior probability of an event and revises it in the light of new data. For example, if 0.01 of a population has schizophrenia then the probability that a person drawn at random would have schizophrenia is 0.01. This is the prior probability. If you then learn that that there score on a personality test suggests the person is schizophrenic, you would adjust your probability accordingly. The adjusted probability is the posterior probability.  [Source](http://onlinestatbook.com/glossary/prior_probability.html)

### Application example:

Bayes' Theorem:  $P(B|E) = \frac{P(E|B) * P(B)}{P(E)}$ 

Variable  Meaning  
--------  -------
P         probability
B         belief
E         evidence
P(B)      probability that B is true (**prior probability**)
P(E)      probability that E is true
P(B|E)    probability of B if E is true
P(E|B)    probability of E if B is true

Suppose that a test for using a particular drug is 99% sensitive and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% true negative results for non-drug users. Suppose that 0.5% of people are users of the drug. What is the probability that a randomly selected individual with a positive test is a drug user?

Variable Example Variable Meaning
-------- ---------------- -------
P(B)     P(User)          0.5% of people are using the drug we are testing for (**prior probability**)
P(E|B)   P(+|User)        The probability of testing positive if you use the drug is 99% 
P(E)     P(+)             The probability of testing positive whether or not you use the drug; includes false positives as well as true positives.

:<math>
\begin{align}
P(\text{User}\mid\text{+}) &= \frac{P(\text{+}\mid\text{User}) P(\text{User})}{P(+)} \\
 &= \frac{P(\text{+}\mid\text{User}) P(\text{User})}{P(\text{+}\mid\text{User}) P(\text{User}) + P(\text{+}\mid\text{Non-user}) P(\text{Non-user})} \\[8pt]
&= \frac{0.99 \times 0.005}{0.99 \times 0.005 + 0.01 \times 0.995} \\[8pt]
&\approx 33.2\%
\end{align}</math>

Even if an individual tests positive, it is more likely that they do not use the drug than that they do. This is because the number of non-users is large compared to the number of users. The number of false positives outweighs the number of true positives. For example, if 1000 individuals are tested, there are expected to be 995 non-users and 5 users. From the 995 non-users, 0.01&nbsp;×&nbsp;995&nbsp;???&nbsp;10 false positives are expected. From the 5 users, 0.99&nbsp;×&nbsp;5&nbsp;???&nbsp;5 true positives are expected. Out of 15 positive results, only 5 are genuine.

The importance of Specificity in this example can be seen by calculating that even if sensitivity is raised to 100% and specificity remains at 99% then the probability of the person being a drug user only rises from 33.2% to 33.4%, but if the sensitivity is held at 99% and the specificity is increased to 99.5% then the probability of the person being a drug user rises to about 49.9%.

[Source](https://en.wikipedia.org/wiki/Bayes%27_theorem)

And another good [reference](https://blogs.scientificamerican.com/cross-check/bayes-s-theorem-what-s-the-big-deal/).

##  Linear Discriminant Analysis for p = 1

Reference:  ISLR Seventh Printing p.138

Process:

* For each observation
  + For each class K
    - Estimate the prior probability that a randomly chosen observation comes from the kth class (i.e. P(B)) ($\pi_k$)
    - Estimate the density function of X for an observation that comes from the kth class (i.e. P(E|B)) ($f_k(x)$)
    - Plug these estimates into the Bayes' Theorem formula for each class K
  + Assign the observation to class K for the Bayes' Theorem formula that gave the largest result (i.e. posterior probability) ($p_k(x)$)
  

The LDA classifier results from assuming that the observations within each class come from a normal distribution with a class-specific mean vector and a common variance $\sigma^2$, and plugging estimates for these parameters into the Bayes classifier.

## Linear Discriminant Analysis for p > 1

We now extend the LDA classifier to the case of multiple predictors. To do this, we will assume that $X = (X_1, X_2,...,X_p)$ is drawn from a multivariate Gaussian (or multivariate normal) distribution, with a class-specific mean vector and a common co-variance matrix. 

The `multivariate Gaussian distribution` assumes that each individual predictor follows a one-dimensional normal distribution, with some correlation between each pair of predictors. 

Once again, we need to estimate the unknown parameters $\mu_1,...,mu_K$, $\pi_1,...,\pi_K$, and $\Sigma$; the formulas are similar to those used in the one dimensional case (see the book for exact details).  The estimates are plugged into the formula, and classifies the observation to the class for which the result of the formula is the largest.

The Bayes classifier works by assigning an observation to the class for which the posterior probability $p_k(X)$ is greatest. In the two-class case, this amounts to assigning an observation to the default class if $Pr(default = Yes|X = x) > 0.5).  Thus, the Bayes classifier, and by extension LDA, uses a threshold of 50% for the posterior probability of default in order to assign an observation to the default class. However, don't forget we can *modify* this threshold value to better suit our needs and reduce/increase the probabilities that an observation will be assigned to a particular class.

If we change the threshold then the Type I and Type II errors will change as well.  We can graph this relationship by utilizing the `ROC` curve.  The ROC curve is a popular graphic for simultaneously displaying the two types of errors for all possible thresholds.  An ideal ROC curve will hug the top left corner, so the larger area under the ROC curve (the `AUC`) the better the classifier.

## Sensitivity and Specificity

Sensitivity and specificity are statistical measures of the performance of a binary classification test, also known in statistics as a classification function, that are widely used in medicine:

* Sensitivity (also called the true positive rate, the recall, or probability of detection in some fields) measures the proportion of actual positives that are correctly identified as such (e.g., the percentage of sick people who are correctly identified as having the condition). 

* Specificity (also called the true negative rate) measures the proportion of actual negatives that are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition).

[Source](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)

## Covariance Matrices

References:
* https://www.theanalysisfactor.com/covariance-matrices/
* https://stattrek.com/matrix-algebra/covariance-matrix.aspx
* https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/anova/supporting-topics/anova-statistics/what-is-the-variance-covariance-matrix/

### Variance

Variance is a measure of the variability or spread in a set of data. Mathematically, it is the average squared deviation from the mean score. We use the following formula to compute variance:

$Var(X) = \sigma^2 = \frac{\Sigma( x - \mu)^2}{N}$

where

* $\sigma$ is the       variance
* $x$ is an individual observation
* $N$ is the total number of observations
* $\mu$ is the mean of the observations


### Covariance

Covariance is a measure of the extent to which corresponding elements from two sets of ordered data move in the same direction. We use the following formula to compute covariance:

$cov(x,y) = \Sigma{ \frac{ (x_i - \bar{x})(y_i - \bar{y})  }{N} }$

where 

* $x_i$ is the i-th individual observation in the first data set
* $\bar{x}$ is the mean of the N scores in the first data set

* $y_i$ is the i-th individual observation in the second data set
* $\bar{y}$ is the mean of the N scores in the second data set

* $N$ is the number of scores in each set of data
* $cov(x,y)$ is the covariance of corresponding scores in the two sets of data

# Stock Market Data

```{r}
library(tidyverse)
library(caret)
```


```{r}
library(ISLR)
attach(Smarket)
```

```{r}
names(Smarket)
```

```{r}
dim(Smarket)
```

```{r}
summary(Smarket)
```

Examine the correlations between the predictors.  Leave out `Direction` since it is a qualitative variable.

```{r}
cor(Smarket[, -9])
```

There doesn't seem to be much correlation in the data, and almost none between the lag variables and `Today`.  The highest correlation value we see is 0.54 between `Volume` and `Year` indicating that volume increases as year increases (which makes sense).  We can observe this visually:

```{r}
plot(Volume, Year)
```

# Logistic Regression

Next, we will fit a logistic regression model in order to predict Direction using Lag1 through Lag5 and Volume. The glm() function fits generalized glm() linear models, a class of models that includes logistic regression. The syntax generalized of the glm() function is similar to that of lm(), except that we must pass in linear model the argument family=binomial in order to tell R to run a logistic regression rather than some other type of generalized linear model.

```{r}
fit = glm(Direction ~ . -Year -Today, data = Smarket, family=binomial)
summary(fit)
```

We note that the coefficient Z-statistic values are small, and the p-values are large (none less than 0.05).  This leads us to accept the null hypothesis and declare that there is no relationship between one or more of the independent variables and the dependent variable.

We can also examine the model's prediction values.  The `type="response"` option tells R to output probabilities of the form $P(Y = 1|X)$, as opposed
to other information such as the logit.  If no data set is supplied to the predict() function, then the probabilities are computed for the training data that was used to fit the logistic regression model.

```{r}
probs = predict(fit, type = 'response')
probs[1:10]
```

Since Direction is a qualitative variable we can examine the dummy values R has created for us:

```{r}
contrasts(Direction)
```

Now we know that the values output from the `predict` function are the correspond to the probability of the market going up rather than down.

Next, we can create a confusion matrix:

```{r}
# Create the vector of Direction predictions from the fitted model
preds = rep("Down", dim(Smarket)[1])
preds[probs > 0.5] = 'Up'

# Create the confusion matrix
{
  print(confusionMatrix(factor(preds), factor(Direction))$table)
  print(confusionMatrix(factor(preds), factor(Direction))$overall)
}
```

This appears to tell us that the model is predicting the market's direction correctly 52% of the time, which is a little better than random guessing.  However, we must remember this is the error rate on the `training` data which always has a lower rate than the `test` data.

What would the accuracy look like if we held out some of the training data as a validation set?

```{r}
# Create a boolean list of indices where Year < 2005 as our training data
trainingIndex = (Year < 2005)
tail(Smarket[trainingIndex,])
```

We now fit a logistic regression model using only the subset of the observations that correspond to dates before 2005, using the subset argument.  We then obtain predicted probabilities of the stock market going up for each of the days in our test set-that is, for the days in 2005.

```{r}
# Fit the model using the training data
fit = glm(Direction ~ . -Year -Today, data = Smarket, subset = trainingIndex, family=binomial)

# Make predictions using the validation data
probs = predict(fit, Smarket[!trainingIndex,], type = 'response')
```


```{r}
# Create the vector of Direction predictions from the fitted model
preds = rep("Down", dim(Smarket)[1])
preds[probs > 0.5] = 'Up'

# Create the confusion matrix
{
  print(confusionMatrix(factor(preds), factor(Direction))$table)
  print(confusionMatrix(factor(preds), factor(Direction))$overall)
}
```

We can now see that the validation error rate on data held out from the model fitting is 52% which is _worse_ than random guessing.

# Linear Discriminant Analysis

Now we will perform LDA on the Smarket data. In R, we fit an LDA model using the lda() function, which is part of the MASS library. We fit the model using only the observations before 2005.

```{r}
fit = lda(Direction ~ + Lag1 + Lag2, data = Smarket, subset = trainingIndex)
fit
```

The LDA output indicates that $\hat{\pi_1} = 0.492$ and $\hat{\pi_2} = 0.508$; in other words, 49.2% of the training observations correspond to days during which the market went down. It also provides the group means; these are the average of each predictor within each class, and are used by LDA as estimates of $\mu_k$. These suggest that there is a tendency for the previous 2 days' returns to be negative on days when the market increases, and a tendency for the previous days' returns to be positive on days when the market declines.

```{r}
plot(fit)
```


  





```{r}
length(probs)
```

```{r}
Direction[1:10]
```

```{r}
preds[1:10]
```

```{r}
?factor
```

```{r}
factor(preds)
```

```{r}
factor(Direction)
```

